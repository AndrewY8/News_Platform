{
  "tavily_Technology News": {
    "success": true,
    "urls_found": 3,
    "urls_scraped": 3,
    "retrieval_time": 1.3958261013031006,
    "scraping_time": 0.59096360206604,
    "total_time": 1.9867897033691406,
    "content_analysis": {
      "successful_scrapes": 3,
      "failed_scrapes": 0,
      "total_content_length": 40806,
      "total_images": 21,
      "relevance_score": 100.0,
      "content_samples": [
        {
          "url": "https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/",
          "title": "Year in review: Google's biggest AI advancements of 2024",
          "content_length": 25929,
          "keyword_matches": 4,
          "sample_content": "Year in review: Google's biggest AI advancements of 2024\n2024: A year of extraordinary progress and advancement in AI\nJan 23, 2025\n\u00b7\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nA look back on a yea..."
        },
        {
          "url": "https://blog.google/technology/ai/google-ai-big-scientific-breakthroughs-2024/",
          "title": "How Google AI is advancing science",
          "content_length": 10007,
          "keyword_matches": 4,
          "sample_content": "How Google AI is advancing science\n9 ways AI is advancing science\nNov 18, 2024\n\u00b7\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nWe\u2019re sharing a recap of some of the biggest scientific breakthroughs in..."
        },
        {
          "url": "https://www.forbes.com/sites/bernardmarr/2024/12/16/6-game-changing-ai-breakthroughs-that-defined-2024/",
          "title": "6 Game-Changing AI Breakthroughs That Defined 2024",
          "content_length": 4870,
          "keyword_matches": 3,
          "sample_content": "6 Game-Changing AI Breakthroughs That Defined 2024\nInnovation\nEnterprise Tech\n6 Game-Changing AI Breakthroughs That Defined 2024\nBy\nBernard Marr\n,\nContributor.\nFollow Author\nDec 16, 2024, 02:09am EST\n..."
        }
      ],
      "titles": [
        "Year in review: Google's biggest AI advancements of 2024",
        "How Google AI is advancing science",
        "6 Game-Changing AI Breakthroughs That Defined 2024"
      ]
    },
    "search_results": [
      {
        "href": "https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/",
        "body": "At the start of 2024, we introduced ImageFX, a new generative AI tool that creates images from text prompts, and MusicFX, a tool for creating up"
      },
      {
        "href": "https://blog.google/technology/ai/google-ai-big-scientific-breakthroughs-2024/",
        "body": "In 2024, Google Research partnered with the U.S. Forest Service to develop FireSat, an AI model and new global satellite constellation designed"
      },
      {
        "href": "https://www.forbes.com/sites/bernardmarr/2024/12/16/6-game-changing-ai-breakthroughs-that-defined-2024/",
        "body": "Here, we explore seven pivotal AI developments, including historic regulatory frameworks and Nobel Prize-winning breakthroughs, that are"
      }
    ],
    "scraped_results": [
      {
        "url": "https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/",
        "raw_content": "Year in review: Google's biggest AI advancements of 2024\n2024: A year of extraordinary progress and advancement in AI\nJan 23, 2025\n\u00b7\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nA look back on a year of breakthroughs, progress and extraordinary accomplishments.\nDemis Hassabis\nCEO Google DeepMind\nJames Manyika\nSenior Vice President, Research, Technology & Society\nJeff Dean\nChief Scientist\nRead AI-generated summary\nBullet points\nThis article summarizes Google's AI advancements in 2024, highlighting their commitment to responsible development.\nGoogle released Gemini 2.0, a powerful AI model designed for the \"agentic era,\" and integrated it into various products.\nThey made significant progress in generative AI, releasing updates to Imagen, Veo, and MusicFX, empowering creativity.\nGoogle also advanced robotics, hardware, and computing, with breakthroughs in quantum computing and chip design.\nThey explored AI's potential in science, biology, and mathematics, with notable achievements in protein structure prediction and geometry.\nSummaries were generated by Google AI. Generative AI is experimental.\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nAs we move into 2025, we wanted to take a moment to recognize the astonishing progress of the last year. From\nnew Gemini models built for the agentic era\nand empowering\ncreativity\n, to an\nAI system\nthat designs novel, high-strength protein binders,\nAI\u2013enabled neuroscience\nand even\nlandmark advances\nin quantum computing, we\u2019ve been boldly and responsibly advancing the frontiers of artificial intelligence and all the ways it can benefit humanity.\nAs we and our colleagues\nwrote\ntwo years ago in an essay titled\nWhy we focus on AI\n:\n\u201c\nOur approach to developing and harnessing the potential of AI is grounded in our founding mission \u2014 to organize the world\u2019s information and make it universally accessible and useful \u2014 and it is shaped by our commitment to improve the lives of as many people as possible\n.\u201d\nThis remains as true today as it was when we first wrote it.\nIn this 2024 Year-in-Review post, we look back on a year's worth of extraordinary progress in AI, made possible by the many incredible teams across Google, that helped deliver on that mission and commitment \u2014 progress that sets the stage for more to come this year.\nRelentless innovation in models, products and technologies\n2024 was a year of experimenting, fast shipping, and putting our latest technologies in the hands of developers.\nIn December 2024, we released the first models in our\nGemini 2.0\nexperimental series \u2014 AI models designed for the agentic era. First out of the gate was Gemini 2.0 Flash, our workhorse model, followed by prototypes from the frontiers of our agentic research including: an updated\nProject Astra\n, which explores the capabilities of a universal AI assistant;\nProject Mariner\n, an early prototype capable of taking actions in Chrome as an experimental extension; and\nJules\n, an AI-powered code agent. We're looking forward to bringing Gemini 2.0\u2019s powerful capabilities to our flagship products \u2014 in Search, we\u2019ve already started testing in\nAI Overviews\n, which are now used by over a billion people to ask new types of questions.\nWe also released\nDeep Research\n, a new agentic feature in Gemini Advanced that saves people hours of research work by creating and executing multi-step plans for finding answers to complicated questions; and introduced\nGemini 2.0 Flash Thinking Experimental\n, an experimental model that explicitly shows its thoughts.\nThese advances followed swift progress earlier in the year, from incorporating\nGemini\u2019s capabilities into more Google products\nto the release of\nGemini 1.5 Pro\nand\nGemini 1.5 Flash\n\u2014 a model optimized for speed and efficiency. 1.5 Flash\u2019s compact size made it more cost-efficient to serve, and in 2024 it became our most popular model for developers.\nAnd we improved and updated\nAI Studio\n, which provides a host of resources for developers. It is now available as a progressive web app (PWA) that can be installed on desktop, iOS and Android.\nNotably, it\u2019s been exciting to see the public reception to several\nnew features\nfor NotebookLM, such as Audio Overviews, which can take uploaded source material and produce a\n\u201cdeep dive\u201d discussion\nbetween\ntwo AI hosts\n.\nYour browser does not support the audio element.\nNotebookLM Audio Overview\nIn this Audio Overview, two AI hosts dive into the world of NotebookLM updates.\nMore natural and intuitive handling of speech input and output remains at the core of several of our products:\nGemini Live\n,\nProject Astra\n,\nJourney Voices\nand\nYouTube\u2019s auto dubbing\n.\nContinuing our long history of contributing innovations to the open community \u2014\u00a0such as with\nTransformers\n,\nTensorFlow\n,\nBERT\n,\nT5\n,\nJAX\n,\nAlphaFold\nand\nAlphaCode\n\u2014 we released two new models from\nGemma\n, our state-of-the-art open model built from the same research and technology used to create the Gemini models. Gemma\noutperformed\nsimilarly sized open models on capabilities like question answering, reasoning, math / science and coding. And we released\nGemma Scope\n, which provides tools that help researchers understand the inner workings of Gemma 2.\nWe also continued to improve the factuality of our models and minimize hallucinations. In December, for example, we published\nFACTS Grounding\n, a new benchmark \u2014 based on collaboration between Google DeepMind, Google Research and Kaggle \u2014 for evaluating how accurately large language models ground their responses in provided source material and avoid hallucinations.\nThe FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.\nWe tested leading LLMs using FACTS Grounding, launched the\nFACTS leaderboard\non Kaggle and are proud that Gemini 2.0 Flash Experimental, Gemini 1.5 Flash and Gemini 1.5 Pro currently have the three highest factuality scores, with gemini-2.0-flash-exp at 83.6%.\nMoreover, we improved underlying ML efficiency through pioneering\ntechniques\nlike\nblockwise parallel decoding\n,\nimproved confidence-based deferral\nand\nspeculative decoding\nthat reduce the inference times of LLMs, allowing them to generate responses more quickly. These improvements are used across Google products and set a standard throughout the industry.\nCombining AI with sport, in March we released\nTacticAI\n, an AI system for football tactics that can provide experts with tactical insights, particularly on corner kicks.\nUnderlying all of our models and products is our ongoing commitment to research leadership. Indeed, in a\n2010-2023 WIPO survey of citations for papers on Generative AI\n, Google including Google Research and Google DeepMind\u2019s citations were more than double the second-most cited institution.\nThis WIPO graph, based on January 2024 data from The Lens, illustrates more than a decade\u2019s worth of Alphabet\u2019s generative AI scientific publication efforts.\nFinally, progress was made with Project Starline, our \u201cmagic window\u201d technology project that enables friends, families and coworkers to feel like they\u2019re together from any distance. We\npartnered with HP\nto start commercialization, with the goal of enabling it directly from video conferencing services like Google Meet and Zoom.\nEmpowering creative vision with generative AI\nWe believe AI holds great potential to enable new forms of creativity, democratize creative output and help people express their artistic visions. This is why last year we introduced a series of updates across our generative media tools, covering images, music and video.\nAt the start of 2024, we\nintroduced\nImageFX, a new generative AI tool that creates images from text prompts, and MusicFX, a tool for creating up-to-70-second audio clips also based on text prompts. At I/O, we\nshared an early preview\nof MusicFX DJ, a tool that helps bring the joy of live music creation to more people. In October, we collaborated with\nJacob Collier\non making MusicFX DJ simpler to use, especially for new or aspiring musicians. And we updated our music AI toolkit\nMusic AI Sandbox\n, and evolved our\nDream Track experiment\nwhich allowed U.S. creators to explore a range of genres and prompts that generate instrumental soundtracks with powerful text-to-music models.\nLater in 2024, we released state-of-the-art updates to our image and video models:\nVeo 2\nand\nImagen 3\n. As our highest quality text-to-image model, Imagen 3 is capable of generating images with even better detail, richer lighting and fewer distracting artifacts than our previous models; while Veo demonstrated an improved understanding of real-world physics and the nuances of human movement and expression alongside its overall attention-to-detail and realism.\nVeo represents a significant step forward in high-quality video generation.\nResearch in this field continued apace. We explored ways to use AI to improve editing, for example by\nusing it\nto control of attributes like transparency, roughness or other physical properties of objects:\nIn these examples of AI editing with synthetic data generation, Input shows a novel, held-out image the model has never seen before. Output shows the model output, which successfully edits material properties.\nIn the field of\naudio generation\n, we announced improvements to video-to-audio (V2A) technology, which can generate dynamic soundscapes through natural language text prompts based on on-screen action. This technology is pairable with AI-created video through\nVeo\n.\nGames are an ideal environment for creative exploration of new worlds, as well as training and evaluating embodied agents. In 2024, we introduced\nGenie 2\n, a foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents. This followed the\nintroduction of SIMA\n, a Scalable Instructable Multiworld Agent that can follow natural-language instructions to carry out tasks in a variety of video game settings.\nThe architecture of intelligence: advances in robotics, hardware and computing\nAs our multimodal models become more capable and gain a better understanding of the world and its physics, they are making possible incredible new advances in robotics and bringing us closer to our goal of ever-more capable and helpful robots.\nWith ALOHA Unleashed, our robot learned to tie a shoelace, hang a shirt, repair another robot, insert a gear and even clean a kitchen.\nAt the beginning of the year, we\nintroduced\nAutoRT, SARA-RT and RT-Trajectory, extensions of our\nRobotics Transformers\nwork intended to help robots better understand and navigate their environments, and make decisions faster. We also published\nALOHA Unleashed\n, a breakthrough in teaching robots on how to use two robotic arms in coordination, and\nDemoStart\n, which uses a reinforcement learning algorithm to improve real-world performance on a multi-fingered robotic hand by using simulations.\nRobotic Transformer 2 (RT-2) is a novel vision-language-action model that learns from both web and robotics data.\nBeyond robotics, our\nAlphaChip\nreinforcement learning method for accelerating and improving chip floorplanning is transforming the design process for chips found in data centers, smartphones and more. To accelerate adoption of these techniques, we released a\npre-trained checkpoint\nto enable external parties to more easily make use of the\nAlphaChip open source release\nfor their own chip designs. And we made\nTrillium\n, our sixth-generation and most performant TPU to date, generally available to Google Cloud customers. Advances in computer chips have accelerated AI. And now, AI can return the favor.\nAlphaChip can learn the relationships between interconnected chip components and generalize across chips, letting AlphaChip improve with each layout it designs.\nOur research also focused on correcting the errors in the physical hardware of today's quantum computers. In November, we launched\nAlphaQubit\n, an AI-based decoder that identifies quantum computing errors with state-of-the-art accuracy. This collaborative work brought together Google DeepMind\u2019s ML knowledge and Google Research\u2019s error correction expertise to accelerate progress on building a reliable quantum computer. In tests, it made 6% fewer errors than tensor network methods and 30% fewer errors than correlated matching.\nThen in December, the Google Quantum AI team, part of Google Research, announced\nWillow\n, our latest quantum chip which can perform in under five minutes a benchmark computation that would take one of today\u2019s fastest supercomputers 10 septillion years. Willow can reduce errors exponentially as it scales up using more qubits. In fact, it used our quantum error correction to cut the error rate in half, solving a 30+ year challenge known in the field as \u201cbelow threshold.\u201d This leap forward won the\nPhysics Breakthrough of the Year\naward.\nWillow has state-of-the-art performance across a number of metrics.\nUncovering new solutions: progress in science, biology and mathematics\nWe continued to push the envelope on accelerating scientific progress with AI-based approaches, releasing a series of tools and papers this year that showed just how useful and powerful a tool AI is for advancing science and mathematics. We're sharing a few highlights.\nIn January, we introduced\nAlphaGeometry\n, an AI system engineered to solve complex geometry problems. Our updated version, AlphaGeometry 2, and AlphaProof, a reinforcement-learning-based system for formal math reasoning,\nachieved the same level as a silver medalist\nin July 2024\u2019s\nInternational Mathematical Olympiad\n.\nAlphaGeometry 2 solved Problem 4 in July 2024\u2019s International Mathematical Olympiad within 19 seconds after receiving its formalization. Problem 4 asked to prove the sum of \u2220KIL and \u2220XPY equals 180\u00b0.\nIn collaboration with Isomorphic Labs, we introduced\nAlphaFold 3\n, our latest model which predicts the structure and interactions of all of life\u2019s molecules. By accurately predicting the structure of proteins, DNA, RNA, ligands and more, and how they interact, we hope it will transform our understanding of the biological world and drug discovery.\nAlphaFold 3\u2019s capabilities come from its next-generation architecture and training that now covers all of life\u2019s molecules.\nWe made several key developments in protein-shaping. We announced\nAlphaProteo\n, an AI system for designing novel, high-strength protein binders. AlphaProteo can lead to the discovery of new drugs, the development of biosensors and improve our understanding of biological processes.\nAlphaProteo can generate new protein binders for diverse target proteins.\nIn collaboration with Harvard\u2019s Lichtman Lab and others, we\nproduced\na nano-scale mapping of a piece of the human brain at a level of detail never previously achieved, and made it publicly available for researchers to build on. This follows\na decade of working to advance our understanding of connectomics\n, with earlier work on fly brain and mouse brain connectomics now giving way to the larger scale and more complex human brain connectomics.\nIn the deepest layer of the cortex, clusters of cells tend to occur in mirror-image orientation to one another, as shown in this brain mapping project.\nThen in late November, as part of a\nbroader effort\nto expand and deepen public dialogue around science and AI, we co-hosted\nthe AI for Science Forum\nwith the Royal Society, which convened\nscientists\n, researchers, governmental leaders and executives to discuss\nkey topics\nlike cracking the protein structure prediction challenge, mapping the human brain and saving lives through accurate forecasting and spotting wildfires. We hosted a Q&A with the four Nobel Laureates in attendance at the forum, Sir Paul Nurse, Jennifer Doudna, Demis Hassabis and John Jumper, which is available to listen to via the Google DeepMind\npodcast\n.\nThis was also a landmark year for another reason: Demis Hassabis and John Jumper, along with David Baker, were awarded the\n2024 Nobel Prize\u00ae in Chemistry\nfor their work on AlphaFold 2. As the Nobel committee\nrecognized\n, their work:\n\"[H]as opened up completely new possibilities to design proteins that have never been seen before, and we now have access to predicted structures of all 200 million known proteins. These are truly great achievements.\"\nIt was also exciting to see the\n2024 Nobel Prize\u00ae in Physics\nawarded to recently retired long-time Googler Geoffrey Hinton (along with John Hopfield), \"for foundational discoveries and inventions that enable machine learning with artificial neural networks.\u201d\nThe Nobels followed additional recognitions for Google including the\nNeurIPS 2024 Test of Time Paper Awards\nfor\nSequence to Sequence Learning with Neural Networks\nand\nGenerative Adversarial Nets\n, and the\nBeale\u2014Orchard-Hays Prize\n, which was awarded to a collaborative team of educators and Google professionals for groundbreaking work on\nPrimal-Dual Linear Programming (PDLP)\n. (PDLP, now part of\nGoogle OR Tools\n, helps solve large-scale linear programming problems with real-world applications from\ndata center network traffic engineering\nto\ncontainer shipping optimization\n.)\nAI for the benefit of humanity\nThis year, we made a number of product advances and published research that showed how AI can benefit people directly and immediately, ranging from preventative and diagnostic medicine to disaster readiness and recovery to learning.\nIn healthcare, AI holds the promise of democratizing quality of care in key areas, such as early\ndetection of cardiovascular disease\n. Our\nresearch\ndemonstrated how using a simple fingertip device that measures variations in blood flow, combined with basic metadata, can predict heart health risks. We built on previous AI-enabled diagnostic research for tuberculosis,\ndemonstrating\nhow AI models can be used for accurate TB screenings in populations with high rates of TB and HIV. This is important to reducing the prevalence of TB (more than\n10 million people\nfall ill with it each year), as roughly 40% of people with TB go\nundiagnosed\n.\nOn the MedQA (USMLE-style) benchmark, Med-Gemini attains a new state-of-the-art score, surpassing our prior best (\nMed-PaLM 2\n) by a significant margin of 4.6%.\nOur Gemini model is a powerful tool for professionals generally, but our teams are also working to create fine-tuned models for other domains. For example, we introduced\nMed-Gemini\n, a new family of next-generation models that combine training on de-identified medical data with Gemini\u2019s reasoning, multimodal and long-context abilities. On the MedQA US Medical Licensing Exam (USMLE)-style question benchmark, Med-Gemini\nachieves\na state-of-the-art performance of 91.1% accuracy, surpassing our prior best of Med-PaLM 2 by 4.6% (shown above).\nWe are exploring how machine learning can help medical fields struggling with access to imaging expertise, such as\nradiology, dermatology and pathology\n. In the past year, we\nreleased\ntwo research tools,\nDerm Foundation\nand\nPath Foundation\n, that can help develop models for diagnostic tasks, image indexing and curation and biomarker discovery and validation. We collaborated with physicians at Stanford Medicine on an open-access, inclusive\nSkin Condition Image Network (SCIN) dataset\n. And we unveiled\nCT Foundation\n, a medical imaging embedding tool used for rapidly training models for research.\nWith regard to learning, we explored new generative AI tools to support educators and learners. We introduced\nLearnLM\n, our new family of models fine-tuned for learning and used it to enhance learning experiences in products like Search, YouTube and Gemini; a recent report showed LearnLM\noutperformed\nother leading AI models. We also\nmade it available\nto developers as an experimental model in AI Studio. Our new conversational learning companion,\nLearnAbout\n, uses AI to help you dive deeper into any topic you\u2019re curious about, while\nIlluminate\nlets you turn content into engaging AI-generated audio discussions.\nIn the fields of disaster forecasting and preparedness, we announced several breakthroughs. We introduced\nGenCast\n, our new high-resolution AI ensemble model, which improves day-to-day weather and extreme events forecasting across all possible weather trajectories. We also introduced our\nNeuralGCM model\n, able to simulate over 70,000 days of the atmosphere in the time it would take a physics-based model to simulate only 19 days. And\nGraphCast\nwon the\n2024 MacRobert Award\nfor engineering innovation.\nThis selection of GraphCast\u2019s predictions rolling across 10 days shows specific humidity at 700 hectopascals (about 3 kilometers above surface), surface temperature and surface wind speed.\nWe also improved our\nflood forecasting model\nto predict flooding seven days in advance (up from five) and expanded our riverine flood forecasting coverage to 100 countries and 700 million people. This marks a significant milestone in a multi-year initiative that Google Research embarked on in 2018.\nOur flood forecasting model is now available in over 100 countries (left), and we now have \u201cvirtual gauges\u201d for experts and researchers in more than 150 countries, including countries where physical gauges are not available.\nAI can also help with wildfire detection and mitigation, which is especially top of mind given the devastation in California. Our\nWildfire Boundary Maps capabilities\nare now available in 22 countries. Alongside leading wildfire authorities, Google Research also created\nFireSat\n, a constellation of satellites that can detect and track wildfires as small as a classroom (roughly 5x5 meters) within 20 minutes.\nAnd we continued building on our commitment to making more information more accessible to more people,\nexpanding Google Translate\nwith 110 new languages, including Cantonese, Papua New Guinea\u2019s Tok Pisin, N\u2019Ko from West Africa and Manx from the Isle of Man. Google Translate \u2014 which now supports over 240 languages \u2014 can help people overcome barriers to information, knowledge and opportunity.\nThese new languages in Google Translate represent more than 614 million speakers, opening up translations for around 8% of the world\u2019s population.\nHelping set the standard in responsible AI\nWe furthered our industry-leading research in AI safety, developing new tools and techniques and integrating these advances into our latest models. We\u2019re committed to working with others to address risks.\nWe continued\nresearching\nmisuse, conducting a study that found the two most common types of misuse were deep fakes and jailbreaks. In May, we introduced\nThe Frontier Safety Framework\n, which established protocols for identifying the emerging capabilities of our most advanced AI models, and launched our\nAI Responsibility Lifecycle framework\nto the public. In October, we\nexpanded\nour\nResponsible GenAI Toolkit\nto work with any LLM, giving developers more tools to build AI responsibly.\nAnd, among our other efforts, we released a paper this year on\nThe Ethics of Advanced AI Assistants\nthat examined and mapped the new technical and moral landscape of a future populated by AI assistants, and characterized the opportunities and risks society might face.\nWe expanded\nSynthID\u2019s capabilities\nto watermarking AI-generated text in the\nGemini app and web experience\n, and video in\nVeo\n. To help increase overall transparency online, not just with content created by Google gen AI tools, we also\njoined\nthe Coalition for Content Provenance and Authenticity (C2PA) as a steering committee member and\ncollaborated\non a new, more secure version of the technical standard, Content Credentials.\nWhen there\u2019s a range of different tokens to choose from, SynthID can adjust the probability score of each predicted token, in cases where it won\u2019t compromise the quality, accuracy and creativity of the output.\nBeyond LLMs, we shared our approach to\nbiosecurity\nfor\nAlphaFold 3\n. We also worked with industry partners to launch the\nCoalition for Secure AI\n(CoSAI), and we participated in the\nAI Seoul Summit\n, as a way of building and contributing to an international consensus and a common, coordinated approach to governance.\nAs we develop new technologies like AI agents, we\u2019ll continue to encounter new questions around safety, security and privacy. Guided by our\nAI Principles\n, we are\ndeliberately taking\nan exploratory and gradual approach to development, conducting research on multiple prototypes, iteratively implementing safety training, working with trusted testers and external experts and performing extensive risk assessments and safety and assurance evaluations.\nLooking ahead to 2025\n2024 was a productive year, and a very exciting time for groundbreaking new products and research in AI. We made a great deal of progress and we\u2019re even more excited about the year ahead.\nAs we continue to produce groundbreaking AI research in the fields of products, science, health, creativity and more, it becomes increasingly important to think deeply about how and when it should be deployed. By continuing to prioritize responsible AI practices and fostering collaboration, we\u2019ll play an important role in building a future where AI benefits humanity.\nPOSTED IN:\nRelated stories\nGoogle Workspace\nHow AI made Meet\u2019s language translation possible\nBy\nMolly McHugh-Johnson\nSep 11, 2025\nAI\nThe latest AI news we announced in August\nBy\nKeyword Team\nSep 10, 2025\nLearning & Education\nAI Quests: Bringing AI literacy to the classroom\nBy\nRonit Levavi Morad\nSep 09, 2025\nAI\nThe latest Google AI literacy resources all in one place\nBy\nJennie Magiera\nResearch\nGoogle Quantum AI has been selected for the DARPA Quantum Benchmarking Initiative.\nBy\nHartmut Neven\nSep 09, 2025\nSearch\nGoogle Doodles show how AI Mode can help you learn.\nSep 08, 2025\n.\nJump to position 1\nJump to position 2\nJump to position 3\nJump to position 4\nJump to position 5\nJump to position 6\nLet\u2019s stay in touch. Get the latest news from Google in your inbox.\nSubscribe\nNo thanks",
        "image_urls": [
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Demis_headshot.max-244x184.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2024_Headshot_for_James_Manyika.max-244x184.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Jeff_Dean_Photo_1.max-244x184.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FACTS_system_instruction2x.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/EOY-2024-Figure-250114-r01.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Fig_1.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Social_03.width-100.format-webp_GDqJDqv.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AF_hero_2_crop.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Med-Gemini-2b-MedQA.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Flood-Forecasting.width-100.format-webp.webp",
            "score": 0
          }
        ],
        "title": "Year in review: Google's biggest AI advancements of 2024"
      },
      {
        "url": "https://blog.google/technology/ai/google-ai-big-scientific-breakthroughs-2024/",
        "raw_content": "How Google AI is advancing science\n9 ways AI is advancing science\nNov 18, 2024\n\u00b7\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nWe\u2019re sharing a recap of some of the biggest scientific breakthroughs in recent years brought about by AI.\nKeyword Team\nRead AI-generated summary\nGeneral summary\nAI is rapidly advancing science, with breakthroughs in fields like protein structure prediction, brain mapping, and flood forecasting. These advancements are built on collaborations between researchers, technologists, and policymakers, and they offer a blueprint for how AI can improve human life. The Royal Society and Google DeepMind are hosting the first AI for Science Forum to discuss the transformative potential of AI and the role of public-private partnerships in innovation.\nSummaries were generated by Google AI. Generative AI is experimental.\nBullet points\nAI is rapidly advancing science, leading to breakthroughs in fields like healthcare, energy, and materials science.\nAI models like AlphaFold are predicting protein structures, accelerating drug development and tackling environmental issues.\nAI is helping us understand the human brain in unprecedented detail, aiding in health research and treatment development.\nAI is improving weather forecasting, enabling more accurate predictions and better preparedness for extreme events.\nAI is being used to develop new materials, potentially leading to more efficient solar cells, batteries, and superconductors.\nSummaries were generated by Google AI. Generative AI is experimental.\nExplore other styles:\nGeneral summary\nBullet points\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nLast updated: November 22, 2024\nWe\u2019re living in a time when applied science, human ingenuity and new technologies are offering deep insights into some of humanity\u2019s biggest (and oldest) questions. While we often think of scientific progress as fast and unrelenting, for many decades, progress has\nactually slowed\n. While the scientific community continues to debate the cause of this slowdown, much of today's technology \u2014 from jets to manufacturing processes \u2014 is not significantly different than half a century ago.\nBut in just the past few years, breakthroughs in formerly nascent fields like artificial intelligence and quantum computing have dramatically accelerated the pace of scientific discovery. And from healthcare advances to finding plastic-eating enzymes, we\u2019re already benefiting from it.\nThese breakthroughs are built on decades of collaboration between researchers, technologists, policymakers, civil organizations and many people from across society. And they offer a blueprint for how applying AI to science can dramatically improve human life.\nIt\u2019s with this in mind that today The Royal Society in partnership with Google DeepMind is cohosting the first AI for Science Forum. This event in London brings together the scientific community, policymakers, and industry leaders to look at the transformative potential of AI to accelerate science and the role of public-private partnerships in innovation.\nTo explore how we got here and where we can go next, here\u2019s a look at nine recent moments that have set the stage for so much of the scientific progress on the horizon:\n1. Cracking the 50-year \u201cgrand challenge\u201d of protein structure prediction\nExperts have described demystifying protein folding as a \"grand challenge\" for decades. In 2022, Google DeepMind shared the predicted structures of 200 million proteins from their\nAlphaFold 2 model\n. Previously, determining the 3D structure of a single protein typically took a year or more \u2014 AlphaFold can predict these shapes with remarkable accuracy in minutes. By releasing the protein structure predictions in\na free database\n, this has enabled scientists around the world to accelerate progress in areas like developing\nnew medicines\n,\nfighting antibiotic resistance\nand\ntackling plastic pollution\n. As a next step,\nthe AlphaFold 3 model builds on AlphaFold 2 to predict the structure and interaction\nof all of life\u2019s molecules.\n2. Showing the human brain in unprecedented detail, to support health research\nFew things have held more mystery throughout time than the human brain. Developed over 10 years of\nconnectomics\nresearch,\nGoogle partnered with others, including the the Lichtman Lab at Harvard\n, to map a tiny piece of the human brain to a level of detail never previously achieved. This project, released in 2024, revealed never-before-seen structures within the human brain. And the full dataset, including AI-generated annotations for each cell, has been made publicly available to help accelerate research.\n3. Saving lives with accurate flood forecasting\nWhen Google\u2019s flood forecasting project\nbegan in 2018\n, many believed it was impossible to accurately deliver flood forecasting at scale, given the scarcity of data. But researchers were able to develop an AI model that achieves reliability in predicting extreme riverine events in ungauged watersheds at up to a five-day lead time with reliability matching or exceeding that of nowcasts (zero-day lead time). In 2024, Google Research expanded this coverage to\n100 countries and 700 million people worldwide\n\u2014 and improved the AI model so it offers the same accuracy at a seven-day lead time as the previous model had at five.\n4. Spotting wildfires earlier to help firefighters stop them faster\nWildfires are increasingly upending communities around the world due to hotter and drier climates. In 2024,\nGoogle Research partnered with the U.S. Forest Service to develop FireSat\n, an AI model and new global satellite constellation designed specifically to detect and track wildfires the size of a classroom by providing higher-resolution imagery within 20 minutes. This will allow fire authorities to respond more quickly, potentially saving lives, property and natural resources.\n5. Predicting weather faster and with more accuracy\nIn 2023, Google DeepMind launched and open sourced the model code for\nGraphCast\n, a machine learning research model that predicts weather conditions up to 10 days in advance more accurately and much faster than the industry gold-standard weather simulation system (HRES). GraphCast can also predict the tracks of cyclones (and associated risks like flooding) with greater accuracy,\nand accurately predicted Hurricane Lee\nwould hit Nova Scotia three days before traditional models.\n6. Advancing the frontier of mathematical reasoning\nAI has always struggled with complex math due to a lack of data and reasoning skills. Then, in 2024, Google DeepMind announced\nAlphaGeometry\n, an AI system that solved complex geometry problems at a level approaching a human Olympiad gold-medalist \u2014 a breakthrough in AI performance and the pursuit of more advanced general AI systems. The subsequent Gemini-trained model,\nAlphaGeometry 2, was then combined with a new model AlphaProof\n, and together they solved 83% of all historical International Mathematical Olympiad (IMO) geometry problems from the past 25 years. In demonstrating AI\u2019s growing ability to reason, and potentially solve problems beyond current human abilities, this moved us closer to systems that can discover and verify new knowledge.\n7. Using quantum computing to accurately predict chemical reactivity and kinetics\nGoogle researchers worked with UC Berkeley and Columbia University to perform the largest chemistry simulations to date on a quantum computer. The results,\npublished in 2022\n, were not only competitive with classical methods, but they also did not require the burdensome error mitigation typically associated with quantum computing. The ability to conduct these simulations will offer even more accurate predictions of chemical reactivity and kinetics, which is a precursor for applying chemistry in new ways to help solve real-world challenges.\n8. Accelerating materials science and the potential for more sustainable solar cells, batteries and superconductors\nIn 2023, Google DeepMind announced Graph Networks for Materials Exploration (\nGNoME)\n, a new AI tool that has already discovered 380,000 materials that are stable at low temperatures, according to simulations. At a time when our world is looking for new approaches to energy, processing power and materials science, this work could pave the way to\nbetter solar cells, batteries\nand potential superconductors. Plus, to help this technology benefit everyone, Google DeepMind made GNoME\u2019s most stable predictions available via the Materials Project on their open database.\n9. Taking a meaningful step toward nuclear fusion \u2014 and abundant clean energy\nAs the old joke goes, \u201cFusion is the energy of the future \u2014 and it always will be.\u201d Controlling and using the energy that fuels stars (including our own sun) has been beyond the realm of science. In 2022,\nGoogle DeepMind announced\nthat it developed AI that can\ncontrol the plasma inside a nuclear fusion reactor\nautonomously. By collaborating with the Swiss Plasma Center at EPFL, Google DeepMind built the first Reinforcement Learned system capable of autonomously stabilizing and shaping the plasma within an operational fusion reactor, opening up new pathways toward stable fusion and abundant clean energy for everyone.\nPOSTED IN:\nRelated stories\nGoogle Workspace\nHow AI made Meet\u2019s language translation possible\nBy\nMolly McHugh-Johnson\nSep 11, 2025\nAI\nThe latest AI news we announced in August\nBy\nKeyword Team\nSep 10, 2025\nSustainability\nGoogle is fighting water leaks in Belgium.\nBy\nBen Townsend\nSep 10, 2025\nLearning & Education\nAI Quests: Bringing AI literacy to the classroom\nBy\nRonit Levavi Morad\nSep 09, 2025\nAI\nThe latest Google AI literacy resources all in one place\nBy\nJennie Magiera\nResearch\nGoogle Quantum AI has been selected for the DARPA Quantum Benchmarking Initiative.\nBy\nHartmut Neven\nSep 09, 2025\n.\nJump to position 1\nJump to position 2\nJump to position 3\nJump to position 4\nJump to position 5\nJump to position 6\nLet\u2019s stay in touch. Get the latest news from Google in your inbox.\nSubscribe\nNo thanks",
        "image_urls": [
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/superG_v3.max-244x184.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Meet_Speech_Translate_with_AI.png",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/August_latest_AI_News.width-300.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/image_7_dHwLXVL.png",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/03-ai-literacy-social-sharing-192.width-300.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/122-B2S-EDU-AI-Literacy-Blog-Head.width-300.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/QuantumChip_Social.width-300.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://blog.google/static/blogv2/images/newsletter_toast.svg?version=pr20250903-2044",
            "score": 0
          }
        ],
        "title": "How Google AI is advancing science"
      },
      {
        "url": "https://www.forbes.com/sites/bernardmarr/2024/12/16/6-game-changing-ai-breakthroughs-that-defined-2024/",
        "raw_content": "6 Game-Changing AI Breakthroughs That Defined 2024\nInnovation\nEnterprise Tech\n6 Game-Changing AI Breakthroughs That Defined 2024\nBy\nBernard Marr\n,\nContributor.\nFollow Author\nDec 16, 2024, 02:09am EST\nShare\nSave\nComment\nFrom Apple\u2019s entry into generative AI to unprecedented achievements in robotics and art, 2024 marked a transformative year in artificial intelligence innovation.\nAdobe Stock\nWithout a doubt, 2024 will go down as a year in which we saw much groundbreaking progress and many giant leaps forward in the development of artificial intelligence.\nWith companies racing to build AI features and functionalities into products, we\u2019re increasingly getting used to automation in the workplace, and AI is becoming integrated across all aspects of our everyday lives.\nSo, with the AI revolution well underway, here\u2019s my overview of the year\u2019s AI highlights \u2013 including the game-changing breakthroughs and discoveries setting the stage for an even more momentous 2025.\nThe Continuing Evolution And Advancement Of Generative AI Chatbots\nWhen ChatGPT emerged two years ago (was that all it was?), it was clear that what we were seeing was just the beginning. Since then, we\u2019ve seen rival chatbots emerging from established tech leaders, including Google and Meta, fellow AI startups such as Anthropic, and many\nopen-source\ncollaborations and projects. New features like memory and multimodal capabilities have broken new ground in terms of what we expect from AI. And the most exciting thing is we\u2019re still clearly only just getting started.\nApple Enters The Generative AI Arena With Apple Intelligence\nIf there\u2019s one thing that Apple does really well, it\u2019s taking a great idea and launching it into the mainstream. This is why the\n2024 arrival of Apple Intelligence\ncould well go down as a watershed moment in consumer adoption of AI. By integrating OpenAI-powered generative language and graphics functionality across its product ecosystem, it created a typically refined, Apple-shaped gateway into the world of day-to-day AI for millions of non-techy people.\nMORE FROM\nFORBES ADVISOR\nBest High-Yield Savings Accounts Of 2024\nBy\nKevin Payne\nContributor\nBest 5% Interest Savings Accounts of 2024\nBy\nCassidy Horton\nContributor\nHead Of Google AI Wins The Nobel Prize For Chemistry\nDemis Hassabis has said that the most important effect of the AI revolution is that it will act as an accelerator in many other fields of science. In 2024, he demonstrated this when he was made\njoint winner\nof the Nobel Prize for chemistry, thanks to the AI model AlphaFold 2 being integral to the task of creating new proteins. By predicting the complex amino acid sequences needed, it is thought that this breakthrough will lead to new developments in medicines, vaccines and material sciences.\nThe EU AI Act \u2013 AI Legislation Begins To Take Shape\nIn August 2024, the EU\u2019s Artificial Intelligence Act\ncame into force\n, marking a significant step by an international regulator to implement a framework and safeguards around AI. Rather than conferring rights on individuals (as is the case with the union\u2019s data protection regulation, GDPR), it aims to impose controls on providers of AI services. This is done by categorizing applications according to their potential for causing harm, regulating some while outright banning those classed as \u201cunacceptable.\u201d This highest-risk category includes applications that enable facial recognition technology to be used in public places or for social scoring.\nOptimus Breaks New Ground For Humanoid Robots\nTesla\ndemonstrated\nthe latest iteration of its humanoid robot, codenamed Optimus after the Transformers character, in front of a stunned audience at its We Robot event in October. Despite controversy over how much of its operation was automated and how much was simply remote-controlled via telepresence, experts agreed that it showed impressive progress toward the development of bipedal robots that could eventually assist with many tasks in homes and industry.\nPainting Created By AI Robot Sells For $1 Million\nThe last couple of years have seen an explosion in AI art \u2013 but perhaps the most mind-blowing milestone was passed when Ai-Da became the first humanoid robot to sell a piece of artwork at auction.\nThe painting, titled AI God, was estimated to sell for between $120,000 and $180,000, but\nbidding\nsoared to a final $1,084,000 at the historic Sotheby's auction house in London in February this year.\nAs we reflect on 2024's remarkable AI achievements, it's clear that we're witnessing not just technological advancement but a fundamental transformation in how AI integrates into our lives and work. As we look toward 2025, these developments suggest we're entering an era where AI's impact will continue to expand and evolve in ways that promise to reshape every aspect of human endeavor.\nEditorial Standards\nReprints & Permissions",
        "image_urls": [
          {
            "url": "https://specials-images.forbesimg.com/imageserve/675fd1ce122216c83e2c53fc/From-Apple-s-entry-into-generative-AI-to-unprecedented-achievements-in-robotics-and/960x0.jpg?fit=scale",
            "score": 0
          },
          {
            "url": "https://thumbor.forbes.com/thumbor/fit-in/1290x/https://www.forbes.com/advisor/wp-content/uploads/2020/12/getty_1-best-online-savings-thumbnail_101920pm.jpg",
            "score": 0
          },
          {
            "url": "https://thumbor.forbes.com/thumbor/fit-in/900x510/https://www.forbes.com/advisor/wp-content/uploads/2023/09/Saving-Rates-2.jpg",
            "score": 0
          }
        ],
        "title": "6 Game-Changing AI Breakthroughs That Defined 2024"
      }
    ]
  },
  "tavily_Climate Research": {
    "success": true,
    "urls_found": 3,
    "urls_scraped": 2,
    "retrieval_time": 1.7765560150146484,
    "scraping_time": 1.3124897480010986,
    "total_time": 3.089045763015747,
    "content_analysis": {
      "successful_scrapes": 2,
      "failed_scrapes": 0,
      "total_content_length": 7585,
      "total_images": 10,
      "relevance_score": 50.0,
      "content_samples": [
        {
          "url": "https://www.nature.com/subjects/climate-change",
          "title": "Climate change - Latest research and news | Nature",
          "content_length": 7356,
          "keyword_matches": 5,
          "sample_content": "Climate change - Latest research and news | Nature\nSkip to main content\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, ..."
        },
        {
          "url": "https://www.sciencedirect.com/science/article/pii/S2590332225001113",
          "title": "ScienceDirect",
          "content_length": 229,
          "keyword_matches": 0,
          "sample_content": "ScienceDirect\nSkip to main content\nAre you a robot?\nPlease confirm you are a human by completing the captcha challenge below.\nEnable JavaScript and cookies to continue\nReference number:\n97daaedceb2c9b..."
        }
      ],
      "titles": [
        "Climate change - Latest research and news | Nature",
        "ScienceDirect"
      ]
    },
    "search_results": [
      {
        "href": "https://www.un.org/en/climatechange/reports",
        "body": "Climate change is widespread, rapid and intensifying. That is the key finding of the latest scientific report from the Intergovernmental Panel on Climate Change"
      },
      {
        "href": "https://www.nature.com/subjects/climate-change",
        "body": "Latest Research and Reviews. Neglecting land\u2013atmosphere feedbacks overestimates climate-driven increases in evapotranspiration."
      },
      {
        "href": "https://www.sciencedirect.com/science/article/pii/S2590332225001113",
        "body": "by R Schaeffer \u00b7 2025 \u00b7 Cited by 6 \u2014 10 key advances in climate-change research with high policy relevance. The insights span a wide range of areas, from changes in methane and aerosol emissions."
      }
    ],
    "scraped_results": [
      {
        "url": "https://www.nature.com/subjects/climate-change",
        "raw_content": "Climate change - Latest research and news | Nature\nSkip to main content\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.\nAdvertisement\nClimate change articles from across Nature Portfolio\nAtom\nRSS Feed\nDefinition\nClimate change refers to a statistically defined change in the average and/or variability of the climate system, this includes the atmosphere, the water cycle, the land surface, ice and the living components of Earth. The definition does not usually require the causes of change to be attributed, for example to human activity, but there are exceptions.\nFeatured\nHeatwaves linked to emissions of individual fossil-fuel and cement producers\nThe emissions of leading fossil-fuel and cement producers have been systematically linked to particular heatwaves. Three scientists discuss the methodology behind the result and its potential impact on climate-liability court cases.\nKarsten Haustein\nMichael B. Gerrard\nJessica A. Wentz\nNews & Views\n10 Sept 2025\nNature\nVolume: 645, P: 319-320\nClosing emission gaps in border carbon adjustments for chemicals and plastics\nMajor greenhouse gas emissions from chemicals and plastics are overlooked under the current design of the European Union\u2019s Carbon Border Adjustment Mechanism. To close these important gaps in coverage, policymakers should include fossil-based feedstocks and raise country-specific default emissions values to ensure fair and comprehensive carbon accounting.\nHannah Minten\nJulian Hausweiler\nAndr\u00e9 Bardow\nNews & Views\n10 Sept 2025\nNature Sustainability\nP: 1-2\nPainting humid cities cool\nPassive radiative paints cool buildings without energy input, but do not perform well in humid environments and on vertical surfaces. Now, researchers report a durable cement-based paint that integrates radiative cooling and evaporative cooling mechanisms, achieving effective cooling on vertical surfaces in humid climates while maintaining the mechanical strength and substrate adhesion required for real-world building applications.\nYing Liu\nDangyuan Lei\nNews & Views\n09 Sept 2025\nNature Energy\nP: 1-2\nRelated Subjects\nAttribution\nClimate and Earth system modelling\nClimate-change impacts\nClimate-change mitigation\nProjection and prediction\nLatest Research and Reviews\nNeglecting land\u2013atmosphere feedbacks overestimates climate-driven increases in evapotranspiration\nHow evapotranspiration changes with warming is not well understood. Here the authors show that when often-neglected land\u2013atmosphere feedbacks are considered, evapotranspiration increases less than currently projected by offline models.\nSha Zhou\nBofu Yu\nResearch\n11 Sept 2025\nNature Climate Change\nP: 1-8\nSystematic attribution of heatwaves to the emissions of carbon majors\nClimate change made 213 historical heatwaves reported over 2000\u20132023 more likely and more intense, to which each of the 180 carbon majors (fossil fuel and cement producers) substantially contributed.\nYann Quilcaille\nLukas Gudmundsson\nSonia I. Seneviratne\nResearch\nOpen Access\n10 Sept 2025\nNature\nVolume: 645, P: 392-398\nCausal inference unveils how forest coverage mitigates excess snakebite cases during rainfall seasons in Colombia\nJuan David Guti\u00e9rrez\nCarlos Bravo-Vega\nJuan Manuel Cordovez\nResearch\nOpen Access\n10 Sept 2025\nScientific Reports\nVolume: 15, P: 32401\nHysteresis and reversibility of agroecological droughts in response to carbon dioxide removal\nUsing an idealized multi-model experiment and a new hysteresis quantification method, this study shows that equivalent carbon dioxide removal fails to symmetrically reverse CO\n2\n-emissions-induced agroecological droughts, revealing irreversible impacts in hotspots in the Mediterranean, northern Central America, southern Africa and southern Australia, necessitating urgent adaptation planning.\nLaibao Liu\nMathias Hauser\nSonia I. Seneviratne\nResearch\nOpen Access\n10 Sept 2025\nNature Water\nP: 1-8\nPleistocene terrestrial warming trend in East Asia linked to Antarctic ice sheets growth\nThe authors quantify terrestrial temperature evolution over the past 2 million years by fossil lipids preserved in an ancient lake in East Asia. They showed a long-term warming trend that diverges from the contemporaneous global sea surface cooling.\nHuanye Wang\nWeiguo Liu\nZhisheng An\nResearch\nOpen Access\n10 Sept 2025\nNature Communications\nVolume: 16, P: 8258\nEmbodied emissions of chemicals within the EU Carbon Border Adjustment Mechanism\nThe effects of including the chemical industry in the existing Carbon Border Adjustment Mechanism of the European Union are unclear. A study finds that the current framework covers only half of key chemical emissions, urging the addition of fossil feedstocks and tougher default rules to boost efficacy.\nHannah Minten\nJulian Hausweiler\nAndr\u00e9 Bardow\nResearch\nOpen Access\n10 Sept 2025\nNature Sustainability\nP: 1-10\nAll Research & Reviews\nNews and Comment\nTrump team disbands controversial US climate panel\nA report by the panel downplays the ills of global warming and was key to White House efforts to revoke federal authority to regulate climate.\nJeff Tollefson\nNews\n11 Sept 2025\nNature\nFeeling the heat: fossil-fuel producers linked to dozens of heatwaves\nAttribution study suggests major energy producers play an outsized role in causing extreme heatwaves \u2014 plus, the scientists fighting back against US funding cuts.\nBenjamin Thompson\nShamini Bundell\nNews\n10 Sept 2025\nNature\nClimate impacts are real \u2014 denying this is self-defeating\nThe US administration is attempting to undermine efforts to curb greenhouse-gas emissions. It will ultimately leave that country, and the world, worse off.\nEditorial\n10 Sept 2025\nNature\nVolume: 645, P: 284\nHeatwaves linked to emissions of individual fossil-fuel and cement producers\nThe emissions of leading fossil-fuel and cement producers have been systematically linked to particular heatwaves. Three scientists discuss the methodology behind the result and its potential impact on climate-liability court cases.\nKarsten Haustein\nMichael B. Gerrard\nJessica A. Wentz\nNews & Views\n10 Sept 2025\nNature\nVolume: 645, P: 319-320\nClosing emission gaps in border carbon adjustments for chemicals and plastics\nMajor greenhouse gas emissions from chemicals and plastics are overlooked under the current design of the European Union\u2019s Carbon Border Adjustment Mechanism. To close these important gaps in coverage, policymakers should include fossil-based feedstocks and raise country-specific default emissions values to ensure fair and comprehensive carbon accounting.\nHannah Minten\nJulian Hausweiler\nAndr\u00e9 Bardow\nNews & Views\n10 Sept 2025\nNature Sustainability\nP: 1-2\nHeatwaves linked to carbon emissions from specific companies\nNearly one-quarter of heatwaves would have been \u2018virtually impossible\u2019 without global warming \u2014 and can be attributed to the emissions of individual energy producers.\nJeff Tollefson\nNews\n10 Sept 2025\nNature\nAll News & Comment\nSearch\nSearch articles by subject, keyword or author\nShow results from\nAll journals\nSearch\nAdvanced search\nQuick links\nExplore articles by subject\nFind a job\nGuide to authors\nEditorial policies",
        "image_urls": [
          {
            "url": "https://pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/about&sz=728x90&pos=top;type=about;path=/subjects/climate-change",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/magazine-assets/d41586-025-02596-6/d41586-025-02596-6_51433842.jpg",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs41893-025-01622-9/MediaObjects/41893_2025_1622_Fig1_HTML.png",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs41560-025-01858-x/MediaObjects/41560_2025_1858_Fig1_HTML.png",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs41558-025-02428-5/MediaObjects/41558_2025_2428_Fig1_HTML.png",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs41586-025-09450-9/MediaObjects/41586_2025_9450_Fig1_HTML.png",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs41598-025-17405-3/MediaObjects/41598_2025_17405_Fig1_HTML.png",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs44221-025-00487-8/MediaObjects/44221_2025_487_Fig1_HTML.png",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs41467-025-63331-3/MediaObjects/41467_2025_63331_Fig1_HTML.png",
            "score": 0
          },
          {
            "url": "https://media.springernature.com/w290h158/springer-static/image/art%3A10.1038%2Fs41893-025-01618-5/MediaObjects/41893_2025_1618_Fig1_HTML.png",
            "score": 0
          }
        ],
        "title": "Climate change - Latest research and news | Nature"
      },
      {
        "url": "https://www.sciencedirect.com/science/article/pii/S2590332225001113",
        "raw_content": "ScienceDirect\nSkip to main content\nAre you a robot?\nPlease confirm you are a human by completing the captcha challenge below.\nEnable JavaScript and cookies to continue\nReference number:\n97daaedceb2c9bb4\nIP Address:\n199.79.156.164",
        "image_urls": [],
        "title": "ScienceDirect"
      }
    ]
  },
  "tavily_Programming Tutorials": {
    "success": true,
    "urls_found": 3,
    "urls_scraped": 2,
    "retrieval_time": 1.6579747200012207,
    "scraping_time": 0.9469764232635498,
    "total_time": 2.6049511432647705,
    "content_analysis": {
      "successful_scrapes": 2,
      "failed_scrapes": 0,
      "total_content_length": 50551,
      "total_images": 10,
      "relevance_score": 100.0,
      "content_samples": [
        {
          "url": "https://realpython.com/python-web-scraping-practical-introduction/",
          "title": "A Practical Introduction to Web Scraping in Python \u2013 Real Python",
          "content_length": 50310,
          "keyword_matches": 5,
          "sample_content": "A Practical Introduction to Web Scraping in Python \u2013 Real Python\n\u2014 FREE Email Series \u2014\n\ud83d\udc0d Python Tricks \ud83d\udc8c\nGet Python Tricks \u00bb\n\ud83d\udd12 No spam. Unsubscribe any time.\nBrowse Topics\nGuided Learning Paths\nBasics..."
        },
        {
          "url": "https://www.youtube.com/watch?v=DcI_AZqfZVc",
          "title": "Advanced Web Scraping Tutorial! (w/ Python Beautiful Soup Library) - YouTube",
          "content_length": 241,
          "keyword_matches": 4,
          "sample_content": "Advanced Web Scraping Tutorial! (w/ Python Beautiful Soup Library) - YouTube\nAbout\nPress\nCopyright\nContact us\nCreators\nAdvertise\nDevelopers\nTerms\nPrivacy\nPolicy & Safety\nHow YouTube works\nTest new fea..."
        }
      ],
      "titles": [
        "A Practical Introduction to Web Scraping in Python \u2013 Real Python",
        "Advanced Web Scraping Tutorial! (w/ Python Beautiful Soup Library) - YouTube"
      ]
    },
    "search_results": [
      {
        "href": "https://realpython.com/python-web-scraping-practical-introduction/",
        "body": "This tutorial guides you through extracting data from websites using string methods, regular expressions, and HTML parsers."
      },
      {
        "href": "https://www.youtube.com/watch?v=DcI_AZqfZVc",
        "body": "Advanced Web Scraping Tutorial! (w/ Python Beautiful Soup Library)\nKeith Galli\n249000 subscribers\n1491 likes\n50938 views\n8 Jun 2024\nGet started w/ Bright Data + $15 free credit using this link!\nhttps://brdta.com/keithgalli\n\nIn this video, we're diving into advanced web scraping techniques with Python. If you haven't seen my overview of the Beautiful Soup library, check it out first for some foundational knowledge. Web scraping is a highly valuable skill, especially for freelance work. This tutorial will take you through sophisticated scraping methods, using Walmart as an example.\n\nBefore we start, a big thank you to our sponsor, Bright Data. They offer proxy tools that make advanced web scraping much easier, allowing you to bypass restrictions set by websites. Check out their data sets marketplace for quick access to various data.\n\nIn this video, we'll cover:\n- Setting up and understanding the HTML structure of a web page\n- Extracting data using Beautiful Soup and handling dynamic content\n- Implementing headers to avoid detection\n- Parsing JSON data for efficient scraping\n- Using proxies with Bright Data to bypass IP blocking\n- Error handling and retries in scraping\n- Storing scraped data and handling multiple search queries\n\nIf you need help getting started with web scraping, check out my original tutorial on BeautifulSoup:\nhttps://youtu.be/GjKQ6V_ViQE?si=f9Xo0ING4fNLhLx2\n\nHelpful Links:\nGitHub Repository with Code Examples: https://github.com/KeithGalli/advanced-scraping\n\nVideo Timeline!\n0:00 - Intro & Overview\n1:30 - Identifying HTML Structure for Scraping (from Walmart)\n4:26 - Writing Python BeautifulSoup Code to Extract Info from Walmart.com\n7:22 - Implementing modified request headers to avoid detection\n6:10 - Handling Dynamic Content\n8:00 - Implementing Modified Request Headers to Avoid Detection (look more human when scraping)\n9:30 - Parsing Complicated JSON Data (Using LLMs to help)\n15:28 - Extending our Code to Collect Info on Many Products (Automating Search)\n24:45 - Improving our Code (avoiding duplicates, multiple search terms, using a queue, etc.)\n27:20 - Setting Up Proxies with Bright Data (Get around IP Address blocks)\n36:35 - Error Handling and Retries\n39:36  - Automating actions on pages with Selenium \n41:42 - Conclusion & Next Steps\n\nI hope you find this tutorial useful. If you did, please give it a thumbs up and subscribe to the channel for more tutorials. Let me know in the comments how you plan to use these web scraping techniques in your projects. Enjoy scraping!\n\n-------------------------\nFollow me on social media!\nInstagram | https://www.instagram.com/keithgalli/\nTwitter | https://twitter.com/keithgalli\nTikTok | https://tiktok.com/@keithgalli\n\n-------------------------\nPractice your Python Pandas data science skills with problems on StrataScratch!\nhttps://stratascratch.com/?via=keith\n\nJoin the Python Army to get access to perks!\nYouTube - https://www.youtube.com/channel/UCq6XkhO5SZ66N04IcPbqNcw/join\nPatreon - https://www.patreon.com/keithgalli\n\n*I use affiliate links on the products that I recommend. I may earn a purchase commission or a referral bonus from the usage of these links.\n74 comments\n"
      },
      {
        "href": "https://www.geeksforgeeks.org/python-web-scraping-tutorial/",
        "body": "In this tutorial, you'll learn how to use these Python tools to scrape data from websites and understand why Python 3 is a popular choice for web scraping tasks. In this example, we'll extract all paragraph (<p>) text from the main content section of the GeeksforGeeks Python Tutorial page. To handle this, we use Selenium that can automate browsers like Chrome or Firefox, wait for content to load, click buttons, scroll and extract fully rendered web pages just like a real user. The urllib module in Python is a built-in library that provides functions for working with URLs. It allows you to interact with web pages by fetching URLs (Uniform Resource Locators), opening and reading data from them and performing other URL-related tasks like encoding and parsing."
      }
    ],
    "scraped_results": [
      {
        "url": "https://realpython.com/python-web-scraping-practical-introduction/",
        "raw_content": "A Practical Introduction to Web Scraping in Python \u2013 Real Python\n\u2014 FREE Email Series \u2014\n\ud83d\udc0d Python Tricks \ud83d\udc8c\nGet Python Tricks \u00bb\n\ud83d\udd12 No spam. Unsubscribe any time.\nBrowse Topics\nGuided Learning Paths\nBasics\nIntermediate\nAdvanced\nai\napi\nbest-practices\ncareer\ncommunity\ndatabases\ndata-science\ndata-structures\ndata-viz\ndevops\ndjango\ndocker\neditors\nflask\nfront-end\ngamedev\ngui\nmachine-learning\nnews\nnumpy\nprojects\npython\ntesting\ntools\nweb-dev\nweb-scraping\nTable of Contents\nScrape and Parse Text From Websites\nBuild Your First Web Scraper\nExtract Text From HTML With String Methods\nGet to Know Regular Expressions\nExtract Text From HTML With Regular Expressions\nCheck Your Understanding\nUse an HTML Parser for Web Scraping in Python\nInstall Beautiful Soup\nCreate a BeautifulSoup Object\nUse a BeautifulSoup Object\nCheck Your Understanding\nInteract With HTML Forms\nInstall MechanicalSoup\nCreate a Browser Object\nSubmit a Form With MechanicalSoup\nCheck Your Understanding\nInteract With Websites in Real Time\nConclusion\nAdditional Resources\nFrequently Asked Questions\nMark as Completed\nShare\nRecommended Video Course\nIntroduction to Web Scraping With Python\nA Practical Introduction to Web Scraping in Python\nby\nDavid Amos\nPublication date\nDec 21, 2024\nReading time estimate\n38m\nintermediate\nweb-scraping\nMark as Completed\nShare\nTable of Contents\nScrape and Parse Text From Websites\nBuild Your First Web Scraper\nExtract Text From HTML With String Methods\nGet to Know Regular Expressions\nExtract Text From HTML With Regular Expressions\nCheck Your Understanding\nUse an HTML Parser for Web Scraping in Python\nInstall Beautiful Soup\nCreate a BeautifulSoup Object\nUse a BeautifulSoup Object\nCheck Your Understanding\nInteract With HTML Forms\nInstall MechanicalSoup\nCreate a Browser Object\nSubmit a Form With MechanicalSoup\nCheck Your Understanding\nInteract With Websites in Real Time\nConclusion\nAdditional Resources\nFrequently Asked Questions\nRemove ads\nWatch Now\nThis tutorial has a related video course created by the Real Python team. Watch it together with the written tutorial to deepen your understanding:\nIntroduction to Web Scraping With Python\nPython web scraping allows you to collect and parse data from websites programmatically. With powerful libraries like\nurllib\n, Beautiful Soup, and MechanicalSoup, you can fetch and manipulate HTML content effortlessly. By automating data collection tasks, Python makes web scraping both efficient and effective.\nBy the end of this tutorial, you\u2019ll understand that:\nPython is\nwell-suited for web scraping\ndue to its\nextensive libraries\n, such as Beautiful Soup and MechanicalSoup.\nYou can scrape websites with Python by\nfetching HTML content\nusing\nurllib\nand\nextracting data\nusing string methods or parsers like Beautiful Soup.\nBeautiful Soup\nis a great choice for\nparsing HTML\ndocuments with Python effectively.\nData scraping may be illegal\nif it violates a website\u2019s terms of use, so always review the website\u2019s acceptable use policy.\nThis tutorial guides you through extracting data from websites using string methods, regular expressions, and HTML parsers.\nNote:\nThis tutorial is adapted from the chapter \u201cInteracting With the Web\u201d in\nPython Basics: A Practical Introduction to Python 3\n.\nThe book uses Python\u2019s built-in\nIDLE\neditor to create and edit Python files and interact with the Python shell, so you\u2019ll see occasional references to IDLE throughout this tutorial. However, you should have no problems running the example code from the\neditor\nand\nenvironment\nof your choice.\nSource Code:\nClick here to download the free source code\nthat you\u2019ll use to collect and parse data from the Web.\nTake the Quiz:\nTest your knowledge with our interactive \u201cA Practical Introduction to Web Scraping in Python\u201d quiz. You\u2019ll receive a score upon completion to help you track your learning progress:\nInteractive Quiz\nA Practical Introduction to Web Scraping in Python\nIn this quiz, you'll test your understanding of web scraping in Python. Web scraping is a powerful tool for data collection and analysis. By working through this quiz, you'll revisit how to parse website data using string methods, regular expressions, and HTML parsers, as well as how to interact with forms and other website components.\nScrape and Parse Text From Websites\nCollecting data from websites using an automated process is known as web scraping. Some websites explicitly forbid users from scraping their data with automated tools like the ones that you\u2019ll create in this tutorial. Websites do this for two possible reasons:\nThe site has a good reason to protect its data. For instance, Google Maps doesn\u2019t let you request too many results too quickly.\nMaking many repeated requests to a website\u2019s server may use up bandwidth, slowing down the website for other users and potentially overloading the server such that the website stops responding entirely.\nBefore using your Python skills for web scraping, you should always check your target website\u2019s acceptable use policy to see if accessing the website with automated tools is a violation of its terms of use. Legally, web scraping against the wishes of a website is very much a gray area.\nImportant:\nPlease be aware that the following techniques\nmay be illegal\nwhen used on websites that prohibit web scraping.\nFor this tutorial, you\u2019ll use a page that\u2019s hosted on Real Python\u2019s server. The page that you\u2019ll access has been set up for use with this tutorial.\nNow that you\u2019ve read the disclaimer, you can get to the fun stuff. In the next section, you\u2019ll start grabbing all the HTML code from a single web page.\nRemove ads\nBuild Your First Web Scraper\nOne useful package for web scraping that you can find in Python\u2019s\nstandard library\nis\nurllib\n, which contains tools for working with URLs. In particular, the\nurllib.request\nmodule contains a function called\nurlopen()\nthat you can use to open a URL within a program.\nIn IDLE\u2019s interactive window, type the following to import\nurlopen()\n:\nPython\n>>>\nfrom\nurllib.request\nimport\nurlopen\nThe web page that you\u2019ll open is at the following URL:\nPython\n>>>\nurl\n=\n\"http://olympus.realpython.org/profiles/aphrodite\"\nTo open the web page, pass\nurl\nto\nurlopen()\n:\nPython\n>>>\npage\n=\nurlopen\n(\nurl\n)\nurlopen()\nreturns an\nHTTPResponse\nobject:\nPython\n>>>\npage\n<http.client.HTTPResponse object at 0x105fef820>\nTo extract the HTML from the page, first use the\nHTTPResponse\nobject\u2019s\n.read()\nmethod, which returns a sequence of bytes. Then use\n.decode()\nto decode the bytes to a string using\nUTF-8\n:\nPython\n>>>\nhtml_bytes\n=\npage\n.\nread\n()\n>>>\nhtml\n=\nhtml_bytes\n.\ndecode\n(\n\"utf-8\"\n)\nNow you can\nprint\nthe HTML to see the contents of the web page:\nPython\n>>>\nprint\n(\nhtml\n)\n<html>\n<head>\n<title>Profile: Aphrodite</title>\n</head>\n<body bgcolor=\"yellow\">\n<center>\n<br><br>\n<img src=\"/static/aphrodite.gif\" />\n<h2>Name: Aphrodite</h2>\n<br><br>\nFavorite animal: Dove\n<br><br>\nFavorite color: Red\n<br><br>\nHometown: Mount Olympus\n</center>\n</body>\n</html>\nThe output that you\u2019re seeing is the\nHTML code\nof the website, which your browser renders when you visit\nhttp://olympus.realpython.org/profiles/aphrodite\n:\nWith\nurllib\n, you accessed the website similarly to how you would in your browser. However, instead of rendering the content visually, you grabbed the source code as text. Now that you have the HTML as text, you can extract information from it in a couple of different ways.\nExtract Text From HTML With String Methods\nOne way to extract information from a web page\u2019s HTML is to use\nstring methods\n. For instance, you can use\n.find()\nto search through the text of the HTML for the\n<title>\ntags and extract the title of the web page.\nTo start, you\u2019ll extract the title of the web page that you requested in the previous example. If you know the index of the first character of the title and the index of the first character of the closing\n</title>\ntag, then you can use a\nstring slice\nto extract the title.\nBecause\n.find()\nreturns the index of the first occurrence of a\nsubstring\n, you can get the index of the opening\n<title>\ntag by passing the string\n\"<title>\"\nto\n.find()\n:\nPython\n>>>\ntitle_index\n=\nhtml\n.\nfind\n(\n\"<title>\"\n)\n>>>\ntitle_index\n14\nYou don\u2019t want the index of the\n<title>\ntag, though. You want the index of the title itself. To get the index of the first letter in the title, you can add the length of the string\n\"<title>\"\nto\ntitle_index\n:\nPython\n>>>\nstart_index\n=\ntitle_index\n+\nlen\n(\n\"<title>\"\n)\n>>>\nstart_index\n21\nNow get the index of the closing\n</title>\ntag by passing the string\n\"</title>\"\nto\n.find()\n:\nPython\n>>>\nend_index\n=\nhtml\n.\nfind\n(\n\"</title>\"\n)\n>>>\nend_index\n39\nFinally, you can extract the title by slicing the\nhtml\nstring:\nPython\n>>>\ntitle\n=\nhtml\n[\nstart_index\n:\nend_index\n]\n>>>\ntitle\n'Profile: Aphrodite'\nReal-world HTML can be much more complicated and far less predictable than the HTML on the Aphrodite profile page. Here\u2019s\nanother profile page\nwith some messier HTML that you can scrape:\nPython\n>>>\nurl\n=\n\"http://olympus.realpython.org/profiles/poseidon\"\nTry extracting the title from this new URL using the same method as in the previous example:\nPython\n>>>\nurl\n=\n\"http://olympus.realpython.org/profiles/poseidon\"\n>>>\npage\n=\nurlopen\n(\nurl\n)\n>>>\nhtml\n=\npage\n.\nread\n()\n.\ndecode\n(\n\"utf-8\"\n)\n>>>\nstart_index\n=\nhtml\n.\nfind\n(\n\"<title>\"\n)\n+\nlen\n(\n\"<title>\"\n)\n>>>\nend_index\n=\nhtml\n.\nfind\n(\n\"</title>\"\n)\n>>>\ntitle\n=\nhtml\n[\nstart_index\n:\nend_index\n]\n>>>\ntitle\n'\\n<head>\\n<title >Profile: Poseidon'\nWhoops! There\u2019s a bit of HTML mixed in with the title. Why\u2019s that?\nThe HTML for the\n/profiles/poseidon\npage looks similar to the\n/profiles/aphrodite\npage, but there\u2019s a small difference. The opening\n<title>\ntag has an extra space before the closing angle bracket (\n>\n), rendering it as\n<title >\n.\nhtml.find(\"<title>\")\nreturns\n-1\nbecause the exact substring\n\"<title>\"\ndoesn\u2019t exist. When\n-1\nis added to\nlen(\"<title>\")\n, which is\n7\n, the\nstart_index\nvariable is assigned the value\n6\n.\nThe character at index\n6\nof the string\nhtml\nis a newline character (\n\\n\n) right before the opening angle bracket (\n<\n) of the\n<head>\ntag. This means that\nhtml[start_index:end_index]\nreturns all the HTML starting with that newline and ending just before the\n</title>\ntag.\nThese sorts of problems can occur in countless unpredictable ways. You need a more reliable way to extract text from HTML.\nRemove ads\nGet to Know Regular Expressions\nRegular expressions\n\u2014or\nregexes\nfor short\u2014are patterns that you can use to search for text within a string. Python supports regular expressions through the standard library\u2019s\nre\nmodule.\nNote:\nRegular expressions aren\u2019t particular to Python. They\u2019re a general programming concept and are supported in many programming languages.\nTo work with regular expressions, the first thing that you need to do is import the\nre\nmodule:\nPython\n>>>\nimport\nre\nRegular expressions use special characters called\nmetacharacters\nto denote different patterns. For instance, the asterisk character (\n*\n) stands for zero or more instances of whatever comes just before the asterisk.\nIn the following example, you use\n.findall()\nto find any text within a string that matches a given regular expression:\nPython\n>>>\nre\n.\nfindall\n(\n\"ab*c\"\n,\n\"ac\"\n)\n['ac']\nThe first argument of\nre.findall()\nis the regular expression that you want to match, and the second argument is the string to test. In the above example, you search for the pattern\n\"ab*c\"\nin the string\n\"ac\"\n.\nThe regular expression\n\"ab*c\"\nmatches any part of the string that begins with\n\"a\"\n, ends with\n\"c\"\n, and has zero or more instances of\n\"b\"\nbetween the two.\nre.findall()\nreturns a\nlist\nof all matches. The string\n\"ac\"\nmatches this pattern, so it\u2019s returned in the list.\nHere\u2019s the same pattern applied to different strings:\nPython\n>>>\nre\n.\nfindall\n(\n\"ab*c\"\n,\n\"abcd\"\n)\n['abc']\n>>>\nre\n.\nfindall\n(\n\"ab*c\"\n,\n\"acc\"\n)\n['ac']\n>>>\nre\n.\nfindall\n(\n\"ab*c\"\n,\n\"abcac\"\n)\n['abc', 'ac']\n>>>\nre\n.\nfindall\n(\n\"ab*c\"\n,\n\"abdc\"\n)\n[]\nNotice that if no match is found, then\n.findall()\nreturns an empty list.\nPattern matching is case sensitive. If you want to match this pattern regardless of the case, then you can pass a third argument with the value\nre.IGNORECASE\n:\nPython\n>>>\nre\n.\nfindall\n(\n\"ab*c\"\n,\n\"ABC\"\n)\n[]\n>>>\nre\n.\nfindall\n(\n\"ab*c\"\n,\n\"ABC\"\n,\nre\n.\nIGNORECASE\n)\n['ABC']\nYou can use a period (\n.\n) to stand for any single character in a regular expression. For instance, you could find all the strings that contain the letters\n\"a\"\nand\n\"c\"\nseparated by a single character as follows:\nPython\n>>>\nre\n.\nfindall\n(\n\"a.c\"\n,\n\"abc\"\n)\n['abc']\n>>>\nre\n.\nfindall\n(\n\"a.c\"\n,\n\"abbc\"\n)\n[]\n>>>\nre\n.\nfindall\n(\n\"a.c\"\n,\n\"ac\"\n)\n[]\n>>>\nre\n.\nfindall\n(\n\"a.c\"\n,\n\"acc\"\n)\n['acc']\nThe pattern\n.*\ninside a regular expression stands for any character repeated any number of times. For instance, you can use\n\"a.*c\"\nto find every substring that starts with\n\"a\"\nand ends with\n\"c\"\n, regardless of which letter\u2014or letters\u2014are in between:\nPython\n>>>\nre\n.\nfindall\n(\n\"a.*c\"\n,\n\"abc\"\n)\n['abc']\n>>>\nre\n.\nfindall\n(\n\"a.*c\"\n,\n\"abbc\"\n)\n['abbc']\n>>>\nre\n.\nfindall\n(\n\"a.*c\"\n,\n\"ac\"\n)\n['ac']\n>>>\nre\n.\nfindall\n(\n\"a.*c\"\n,\n\"acc\"\n)\n['acc']\nOften, you use\nre.search()\nto search for a particular pattern inside a string. This function is somewhat more complicated than\nre.findall()\nbecause it returns an object called\nMatchObject\nthat stores different groups of data. This is because there might be matches inside other matches, and\nre.search()\nreturns every possible result.\nThe details of\nMatchObject\nare irrelevant here. For now, just know that calling\n.group()\non\nMatchObject\nwill return the first and most inclusive result, which in most cases is just what you want:\nPython\n>>>\nmatch_results\n=\nre\n.\nsearch\n(\n\"ab*c\"\n,\n\"ABC\"\n,\nre\n.\nIGNORECASE\n)\n>>>\nmatch_results\n.\ngroup\n()\n'ABC'\nThere\u2019s one more function in the\nre\nmodule that\u2019s useful for parsing out text.\nre.sub()\n, which is short for\nsubstitute\n, allows you to replace the text in a string that matches a regular expression with new text. It behaves sort of like the\n.replace()\nstring method.\nThe arguments passed to\nre.sub()\nare the regular expression, followed by the replacement text, followed by the string. Here\u2019s an example:\nPython\n>>>\nstring\n=\n\"Everything is <replaced> if it's in <tags>.\"\n>>>\nstring\n=\nre\n.\nsub\n(\n\"<.*>\"\n,\n\"ELEPHANTS\"\n,\nstring\n)\n>>>\nstring\n'Everything is ELEPHANTS.'\nPerhaps that wasn\u2019t quite what you expected to happen.\nre.sub()\nuses the regular expression\n\"<.*>\"\nto find and replace everything between the first\n<\nand the last\n>\n, which spans from the beginning of\n<replaced>\nto the end of\n<tags>\n. This is because Python\u2019s regular expressions are\ngreedy\n, meaning they try to find the longest possible match when characters like\n*\nare used.\nAlternatively, you can use the non-greedy matching pattern\n*?\n, which works the same way as\n*\nexcept that it matches the shortest possible string of text:\nPython\n>>>\nstring\n=\n\"Everything is <replaced> if it's in <tags>.\"\n>>>\nstring\n=\nre\n.\nsub\n(\n\"<.*?>\"\n,\n\"ELEPHANTS\"\n,\nstring\n)\n>>>\nstring\n\"Everything is ELEPHANTS if it's in ELEPHANTS.\"\nThis time,\nre.sub()\nfinds two matches,\n<replaced>\nand\n<tags>\n, and substitutes the string\n\"ELEPHANTS\"\nfor both matches.\nRemove ads\nExtract Text From HTML With Regular Expressions\nEquipped with all this knowledge, now try to parse out the title from\nanother profile page\n, which includes this rather carelessly written line of HTML:\nHTML\n<\nTITLE\n>\nProfile: Dionysus\n<\n/title / >\nThe\n.find()\nmethod would have a difficult time dealing with the inconsistencies here, but with the clever use of regular expressions, you can handle this code quickly and efficiently:\nPython\nregex_soup.py\nimport\nre\nfrom\nurllib.request\nimport\nurlopen\nurl\n=\n\"http://olympus.realpython.org/profiles/dionysus\"\npage\n=\nurlopen\n(\nurl\n)\nhtml\n=\npage\n.\nread\n()\n.\ndecode\n(\n\"utf-8\"\n)\npattern\n=\n\"<title.*?>.*?</title.*?>\"\nmatch_results\n=\nre\n.\nsearch\n(\npattern\n,\nhtml\n,\nre\n.\nIGNORECASE\n)\ntitle\n=\nmatch_results\n.\ngroup\n()\ntitle\n=\nre\n.\nsub\n(\n\"<.*?>\"\n,\n\"\"\n,\ntitle\n)\n# Remove HTML tags\nprint\n(\ntitle\n)\nTake a closer look at the first regular expression in the\npattern\nstring by breaking it down into three parts:\n<title.*?>\nmatches the opening\n<TITLE >\ntag in\nhtml\n. The\n<title\npart of the pattern matches with\n<TITLE\nbecause\nre.search()\nis called with\nre.IGNORECASE\n, and\n.*?>\nmatches any text after\n<TITLE\nup to the first instance of\n>\n.\n.*?\nnon-greedily matches all text after the opening\n<TITLE >\n, stopping at the first match for\n</title.*?>\n.\n</title.*?>\ndiffers from the first pattern only in its use of the\n/\ncharacter, so it matches the closing\n</title / >\ntag in\nhtml\n.\nThe second regular expression, the string\n\"<.*?>\"\n, also uses the non-greedy\n.*?\nto match all the HTML tags in the\ntitle\nstring. By replacing any matches with\n\"\"\n,\nre.sub()\nremoves all the tags and returns only the text.\nNote:\nWeb scraping in Python or any other language can be tedious. No two websites are organized the same way, and HTML is often messy. Moreover, websites change over time. Web scrapers that work today aren\u2019t guaranteed to work next year\u2014or next week, for that matter!\nRegular expressions are a powerful tool when used correctly. In this introduction, you\u2019ve barely scratched the surface. For more about regular expressions and how to use them, check out the two-part series\nRegular Expressions: Regexes in Python\n.\nCheck Your Understanding\nExpand the block below to check your understanding.\nExercise: Scrape Data From a Website\nShow/Hide\nWrite a program that grabs the full HTML from the following URL:\nPython\n>>>\nurl\n=\n\"http://olympus.realpython.org/profiles/dionysus\"\nThen use\n.find()\nto display the text following\nName:\nand\nFavorite Color:\n(not including any leading spaces or trailing HTML tags that might appear on the same line).\nYou can expand the block below to see a solution.\nSolution: Scrape Data From a Website\nShow/Hide\nFirst, import the\nurlopen\nfunction from the\nurlib.request\nmodule:\nPython\nfrom\nurllib.request\nimport\nurlopen\nThen open the URL and use the\n.read()\nmethod of the\nHTTPResponse\nobject returned by\nurlopen()\nto read the page\u2019s HTML:\nPython\nurl\n=\n\"http://olympus.realpython.org/profiles/dionysus\"\nhtml_page\n=\nurlopen\n(\nurl\n)\nhtml_text\n=\nhtml_page\n.\nread\n()\n.\ndecode\n(\n\"utf-8\"\n)\nThe\n.read()\nmethod returns a byte string, so you use\n.decode()\nto decode the bytes using the UTF-8 encoding.\nNow that you have the HTML source of the web page as a string assigned to the\nhtml_text\nvariable, you can extract Dionysus\u2019s name and favorite color from his profile. The structure of the HTML for Dionysus\u2019s profile is the same as for Aphrodite\u2019s profile, which you saw earlier.\nYou can get the name by finding the string\n\"Name:\"\nin the text and extracting everything that comes after the first occurence of the string and before the next HTML tag. That is, you need to extract everything after the colon (\n:\n) and before the first angle bracket (\n<\n). You can use the same technique to extract the favorite color.\nThe following\nfor\nloop\nextracts this text for both the name and favorite color:\nPython\nfor\nstring\nin\n[\n\"Name: \"\n,\n\"Favorite Color:\"\n]:\nstring_start_idx\n=\nhtml_text\n.\nfind\n(\nstring\n)\ntext_start_idx\n=\nstring_start_idx\n+\nlen\n(\nstring\n)\nnext_html_tag_offset\n=\nhtml_text\n[\ntext_start_idx\n:]\n.\nfind\n(\n\"<\"\n)\ntext_end_idx\n=\ntext_start_idx\n+\nnext_html_tag_offset\nraw_text\n=\nhtml_text\n[\ntext_start_idx\n:\ntext_end_idx\n]\nclean_text\n=\nraw_text\n.\nstrip\n(\n\"\n\\r\\n\\t\n\"\n)\nprint\n(\nclean_text\n)\nIt looks like there\u2019s a lot going on in this\nfor\nloop, but it\u2019s just a little bit of arithmetic to calculate the right indices for extracting the desired text. Go ahead and break it down:\nYou use\nhtml_text.find()\nto find the starting index of the string, either\n\"Name:\"\nor\n\"Favorite Color:\"\n, and then assign the index to\nstring_start_idx\n.\nSince the text to extract starts just after the colon in\n\"Name:\"\nor\n\"Favorite Color:\"\n, you get the index of the character immediately after the colon by adding the length of the string to\nstart_string_idx\n, and then assign the result to\ntext_start_idx\n.\nYou calculate the ending index of the text to extract by determining the index of the first angle bracket (\n<\n) relative to\ntext_start_idx\nand assign this value to\nnext_html_tag_offset\n. Then you add that value to\ntext_start_idx\nand assign the result to\ntext_end_idx\n.\nYou extract the text by slicing\nhtml_text\nfrom\ntext_start_idx\nto\ntext_end_idx\nand assign this string to\nraw_text\n.\nYou remove any whitespace from the beginning and end of\nraw_text\nusing\n.strip()\nand assign the result to\nclean_text\n.\nAt the end of the loop, you use\nprint()\nto display the extracted text. The final output looks like this:\nShell\nDionysus\nWine\nThis solution is one of many that solves this problem, so if you got the same output with a different solution, then you did great!\nWhen you\u2019re ready, you can move on to the next section.\nUse an HTML Parser for Web Scraping in Python\nAlthough regular expressions are great for pattern matching in general, sometimes it\u2019s easier to use an HTML parser that\u2019s explicitly designed for parsing out HTML pages. There are many Python tools written for this purpose, but the\nBeautiful Soup\nlibrary is a good one to start with.\nInstall Beautiful Soup\nTo install Beautiful Soup, you can run the following in your\nterminal\n:\nShell\n$\npython\n-m\npip\ninstall\nbeautifulsoup4\nWith this command, you\u2019re installing the latest version of Beautiful Soup into your global Python environment.\nRemove ads\nCreate a\nBeautifulSoup\nObject\nType the following program into a new editor window:\nPython\nbeauty_soup.py\nfrom\nbs4\nimport\nBeautifulSoup\nfrom\nurllib.request\nimport\nurlopen\nurl\n=\n\"http://olympus.realpython.org/profiles/dionysus\"\npage\n=\nurlopen\n(\nurl\n)\nhtml\n=\npage\n.\nread\n()\n.\ndecode\n(\n\"utf-8\"\n)\nsoup\n=\nBeautifulSoup\n(\nhtml\n,\n\"html.parser\"\n)\nThis program does three things:\nOpens the URL\nhttp://olympus.realpython.org/profiles/dionysus\nby using\nurlopen()\nfrom the\nurllib.request\nmodule\nReads the HTML from the page as a string and assigns it to the\nhtml\nvariable\nCreates a\nBeautifulSoup\nobject and assigns it to the\nsoup\nvariable\nThe\nBeautifulSoup\nobject assigned to\nsoup\nis created with two arguments. The first argument is the HTML to be parsed, and the second argument, the string\n\"html.parser\"\n, tells the object which parser to use behind the scenes.\n\"html.parser\"\nrepresents Python\u2019s built-in HTML parser.\nUse a\nBeautifulSoup\nObject\nSave and run the above program. When it\u2019s finished running, you can use the\nsoup\nvariable in the interactive window to parse the content of\nhtml\nin various ways.\nNote:\nIf you\u2019re not using IDLE, then you can run your program with the\n-i\nflag to enter interactive mode. Something like\npython -i beauty_soup.py\nwill first run your program and then leave you in a REPL where you can explore your objects.\nFor example,\nBeautifulSoup\nobjects have a\n.get_text()\nmethod that you can use to extract all the text from the document and automatically remove any HTML tags.\nType the following code into IDLE\u2019s interactive window or at the end of the code in your editor:\nPython\n>>>\nprint\n(\nsoup\n.\nget_text\n())\nProfile: Dionysus\nName: Dionysus\nHometown: Mount Olympus\nFavorite animal: Leopard\nFavorite Color: Wine\nThere are a lot of blank lines in this output. These are the result of newline characters in the HTML document\u2019s text. You can remove them with the\n.replace()\nstring method if you need to.\nOften, you need to get only specific text from an HTML document. Using Beautiful Soup first to extract the text and then using the\n.find()\nstring method is sometimes easier than working with regular expressions.\nHowever, other times the HTML tags themselves are the elements that point out the data you want to retrieve. For instance, perhaps you want to retrieve the URLs for all the images on the page. These links are contained in the\nsrc\nattribute of\n<img>\nHTML tags.\nIn this case, you can use\nfind_all()\nto return a list of all instances of that particular tag:\nPython\n>>>\nsoup\n.\nfind_all\n(\n\"img\"\n)\n[<img src=\"/static/dionysus.jpg\"/>, <img src=\"/static/grapes.png\"/>]\nThis returns a list of all\n<img>\ntags in the HTML document. The objects in the list look like they might be strings representing the tags, but they\u2019re actually instances of the\nTag\nobject provided by Beautiful Soup.\nTag\nobjects provide a simple interface for working with the information they contain.\nYou can explore this a little by first unpacking the\nTag\nobjects from the list:\nPython\n>>>\nimage1\n,\nimage2\n=\nsoup\n.\nfind_all\n(\n\"img\"\n)\nEach\nTag\nobject has a\n.name\nproperty that returns a string containing the HTML tag type:\nPython\n>>>\nimage1\n.\nname\n'img'\nYou can access the HTML attributes of the\nTag\nobject by putting their names between square brackets, just as if the attributes were keys in a dictionary.\nFor example, the\n<img src=\"/static/dionysus.jpg\"/>\ntag has a single attribute,\nsrc\n, with the value\n\"/static/dionysus.jpg\"\n. Likewise, an HTML tag such as the link\n<a href=\"https://realpython.com\" target=\"_blank\">\nhas two attributes,\nhref\nand\ntarget\n.\nTo get the source of the images in the Dionysus profile page, you access the\nsrc\nattribute using the dictionary notation mentioned above:\nPython\n>>>\nimage1\n[\n\"src\"\n]\n'/static/dionysus.jpg'\n>>>\nimage2\n[\n\"src\"\n]\n'/static/grapes.png'\nCertain tags in HTML documents can be accessed by properties of the\nTag\nobject. For example, to get the\n<title>\ntag in a document, you can use the\n.title\nproperty:\nPython\n>>>\nsoup\n.\ntitle\n<title>Profile: Dionysus</title>\nIf you look at the source of the Dionysus profile by navigating to the\nprofile page\n, right-clicking on the page, and selecting\nView page source\n, then you\u2019ll notice that the\n<title>\ntag is written in all caps with spaces:\nBeautiful Soup automatically cleans up the tags for you by removing the extra space in the opening tag and the extraneous forward slash (\n/\n) in the closing tag.\nYou can also retrieve just the string between the title tags with the\n.string\nproperty of the\nTag\nobject:\nPython\n>>>\nsoup\n.\ntitle\n.\nstring\n'Profile: Dionysus'\nOne of the features of Beautiful Soup is the ability to search for specific kinds of tags whose attributes match certain values. For example, if you want to find all the\n<img>\ntags that have a\nsrc\nattribute equal to the value\n/static/dionysus.jpg\n, then you can provide the following additional argument to\n.find_all()\n:\nPython\n>>>\nsoup\n.\nfind_all\n(\n\"img\"\n,\nsrc\n=\n\"/static/dionysus.jpg\"\n)\n[<img src=\"/static/dionysus.jpg\"/>]\nThis example is somewhat arbitrary, and the usefulness of this technique may not be apparent from the example. If you spend some time browsing various websites and viewing their page sources, then you\u2019ll notice that many websites have extremely complicated HTML structures.\nWhen scraping data from websites with Python, you\u2019re often interested in particular parts of the page. By spending some time looking through the HTML document, you can identify tags with unique attributes that you can use to extract the data you need.\nThen, instead of relying on complicated regular expressions or using\n.find()\nto search through the document, you can directly access the particular tag that you\u2019re interested in and extract the data you need.\nIn some cases, you may find that Beautiful Soup doesn\u2019t offer the functionality you need. The\nlxml\nlibrary is somewhat trickier to get started with but offers far more flexibility than Beautiful Soup for parsing HTML documents. You may want to check it out once you\u2019re comfortable using Beautiful Soup.\nNote:\nHTML parsers like Beautiful Soup can save you a lot of time and effort when it comes to locating specific data in web pages. However, sometimes HTML is so poorly written and disorganized that even a sophisticated parser like Beautiful Soup can\u2019t interpret the HTML tags properly.\nIn this case, you\u2019re often left with using\n.find()\nand regular expression techniques to try to parse out the information that you need.\nBeautiful Soup is great for scraping data from a website\u2019s HTML, but it doesn\u2019t provide any way to work with HTML forms. For example, if you need to search a website for some query and then scrape the results, then Beautiful Soup alone won\u2019t get you very far.\nRemove ads\nCheck Your Understanding\nExpand the block below to check your understanding.\nExercise: Parse HTML With Beautiful Soup\nShow/Hide\nWrite a program that grabs the full HTML from the\npage\nat the URL\nhttp://olympus.realpython.org/profiles\n.\nUsing Beautiful Soup, print out a list of all the links on the page by looking for HTML tags with the name\na\nand retrieving the value taken on by the\nhref\nattribute of each tag.\nThe final output should look like this:\nShell\nhttp://olympus.realpython.org/profiles/aphrodite\nhttp://olympus.realpython.org/profiles/poseidon\nhttp://olympus.realpython.org/profiles/dionysus\nMake sure that you only have one slash (\n/\n) between the base URL and the relative URL.\nYou can expand the block below to see a solution:\nSolution: Parse HTML With Beautiful Soup\nShow/Hide\nFirst, import the\nurlopen\nfunction from the\nurlib.request\nmodule and the\nBeautifulSoup\nclass from the\nbs4\npackage:\nPython\nfrom\nurllib.request\nimport\nurlopen\nfrom\nbs4\nimport\nBeautifulSoup\nEach link URL on the\n/profiles\npage is a\nrelative URL\n, so create a\nbase_url\nvariable with the base URL of the website:\nPython\nbase_url\n=\n\"http://olympus.realpython.org\"\nYou can build a full URL by concatenating\nbase_url\nwith a relative URL.\nNow open the\n/profiles\npage with\nurlopen()\nand use\n.read()\nto get the HTML source:\nPython\nhtml_page\n=\nurlopen\n(\nbase_url\n+\n\"/profiles\"\n)\nhtml_text\n=\nhtml_page\n.\nread\n()\n.\ndecode\n(\n\"utf-8\"\n)\nWith the HTML source downloaded and decoded, you can create a new\nBeautifulSoup\nobject to parse the HTML:\nPython\nsoup\n=\nBeautifulSoup\n(\nhtml_text\n,\n\"html.parser\"\n)\nsoup.find_all(\"a\")\nreturns a list of all the links in the HTML source. You can loop over this list to print out all the links on the web page:\nPython\nfor\nlink\nin\nsoup\n.\nfind_all\n(\n\"a\"\n):\nlink_url\n=\nbase_url\n+\nlink\n[\n\"href\"\n]\nprint\n(\nlink_url\n)\nYou can access the relative URL for each link through the\n\"href\"\nsubscript. Concatenate this value with\nbase_url\nto create the full\nlink_url\n.\nWhen you\u2019re ready, you can move on to the next section.\nInteract With HTML Forms\nThe\nurllib\nmodule that you\u2019ve been working with so far in this tutorial is well suited for requesting the contents of a web page. Sometimes, though, you need to interact with a web page to obtain the content you need. For example, you might need to submit a form or click a button to display hidden content.\nNote:\nThis tutorial is adapted from the chapter \u201cInteracting With the Web\u201d in\nPython Basics: A Practical Introduction to Python 3\n. If you enjoy what you\u2019re reading, then be sure to check out\nthe rest of the book\n.\nThe Python standard library doesn\u2019t provide a built-in means for working with web pages interactively, but many third-party packages are available from\nPyPI\n. Among these,\nMechanicalSoup\nis a popular and relatively straightforward package to use.\nIn essence, MechanicalSoup installs what\u2019s known as a\nheadless browser\n, which is a web browser with no graphical user interface. This browser is controlled programmatically via a Python program.\nInstall MechanicalSoup\nYou can install MechanicalSoup with\npip\nin your terminal:\nShell\n$\npython\n-m\npip\ninstall\nMechanicalSoup\nYou\u2019ll need to close and restart your IDLE session for MechanicalSoup to load and be recognized after it\u2019s been installed.\nCreate a\nBrowser\nObject\nType the following into IDLE\u2019s interactive window:\nPython\n>>>\nimport\nmechanicalsoup\n>>>\nbrowser\n=\nmechanicalsoup\n.\nBrowser\n()\nBrowser\nobjects represent the headless web browser. You can use them to request a page from the Internet by passing a URL to their\n.get()\nmethod:\nPython\n>>>\nurl\n=\n\"http://olympus.realpython.org/login\"\n>>>\npage\n=\nbrowser\n.\nget\n(\nurl\n)\npage\nis a\nResponse\nobject that stores the response from requesting the URL from the browser:\nPython\n>>>\npage\n<Response [200]>\nThe number\n200\nrepresents the\nstatus code\nreturned by the request. A status code of\n200\nmeans that the request was successful. An unsuccessful request might show a status code of\n404\nif the URL doesn\u2019t exist or\n500\nif there\u2019s a server error when making the request.\nMechanicalSoup uses Beautiful Soup to parse the HTML from the request, and\npage\nhas a\n.soup\nattribute that represents a\nBeautifulSoup\nobject:\nPython\n>>>\ntype\n(\npage\n.\nsoup\n)\n<class 'bs4.BeautifulSoup'>\nYou can view the HTML by inspecting the\n.soup\nattribute:\nPython\n>>>\npage\n.\nsoup\n<html>\n<head>\n<title>Log In</title>\n</head>\n<body bgcolor=\"yellow\">\n<center>\n<br/><br/>\n<h2>Please log in to access Mount Olympus:</h2>\n<br/><br/>\n<form action=\"/login\" method=\"post\" name=\"login\">\nUsername: <input name=\"user\" type=\"text\"/><br/>\nPassword: <input name=\"pwd\" type=\"password\"/><br/><br/>\n<input type=\"submit\" value=\"Submit\"/>\n</form>\n</center>\n</body>\n</html>\nNotice this page has a\n<form>\non it with\n<input>\nelements for a username and a password.\nRemove ads\nSubmit a Form With MechanicalSoup\nOpen the\n/login\npage from the previous example in a browser and look at it yourself before moving on:\nTry typing in a random username and password combination. If you guess incorrectly, then the message\nWrong username or password!\nis displayed at the bottom of the page.\nHowever, if you provide the correct login credentials, then you\u2019re redirected to the\n/profiles\npage:\nUsername\nPassword\nzeus\nThunderDude\nIn the next example, you\u2019ll see how to use MechanicalSoup to fill out and submit this form using Python!\nThe important section of HTML code is the login form\u2014that is, everything inside the\n<form>\ntags. The\n<form>\non this page has the\nname\nattribute set to\nlogin\n. This form contains two\n<input>\nelements, one named\nuser\nand the other named\npwd\n. The third\n<input>\nelement is the\nSubmit\nbutton.\nNow that you know the underlying structure of the login form, as well as the credentials needed to log in, take a look at a program that fills the form out and submits it.\nIn a new editor window, type in the following program:\nPython\nimport\nmechanicalsoup\n# 1\nbrowser\n=\nmechanicalsoup\n.\nBrowser\n()\nurl\n=\n\"http://olympus.realpython.org/login\"\nlogin_page\n=\nbrowser\n.\nget\n(\nurl\n)\nlogin_html\n=\nlogin_page\n.\nsoup\n# 2\nform\n=\nlogin_html\n.\nselect\n(\n\"form\"\n)[\n0\n]\nform\n.\nselect\n(\n\"input\"\n)[\n0\n][\n\"value\"\n]\n=\n\"zeus\"\nform\n.\nselect\n(\n\"input\"\n)[\n1\n][\n\"value\"\n]\n=\n\"ThunderDude\"\n# 3\nprofiles_page\n=\nbrowser\n.\nsubmit\n(\nform\n,\nlogin_page\n.\nurl\n)\nSave the file and press\nF5\nto run it. To confirm that you\u2019ve successfully logged in, type the following into the interactive window:\nPython\n>>>\nprofiles_page\n.\nurl\n'http://olympus.realpython.org/profiles'\nNow break down the above example:\nYou create a\nBrowser\ninstance and use it to request the URL\nhttp://olympus.realpython.org/login\n. You assign the HTML content of the page to the\nlogin_html\nvariable using the\n.soup\nproperty.\nlogin_html.select(\"form\")\nreturns a list of all\n<form>\nelements on the page. Because the page has only one\n<form>\nelement, you can access the form by retrieving the element at index\n0\nof the list. When there is only one form on a page, you may also use\nlogin_html.form\n. The next two lines select the username and password inputs and set their value to\n\"zeus\"\nand\n\"ThunderDude\"\n, respectively.\nYou submit the form with\nbrowser.submit()\n. Notice that you pass two arguments to this method, the\nform\nobject and the URL of the\nlogin_page\n, which you access via\nlogin_page.url\n.\nIn the interactive window, you confirm that the submission successfully redirected to the\n/profiles\npage. If something had gone wrong, then the value of\nprofiles_page.url\nwould still be\n\"http://olympus.realpython.org/login\"\n.\nNote:\nHackers can use automated programs like the one above to\nbrute force\nlogins by rapidly trying many different usernames and passwords until they find a working combination.\nBesides this being highly illegal, almost all websites these days lock you out and report your IP address if they see you making too many failed requests, so don\u2019t try it!\nNow that you have the\nprofiles_page\nvariable set, it\u2019s time to programmatically obtain the URL for each link on the\n/profiles\npage.\nTo do this, you use\n.select()\nagain, this time passing the string\n\"a\"\nto select all the\n<a>\nanchor elements on the page:\nPython\n>>>\nlinks\n=\nprofiles_page\n.\nsoup\n.\nselect\n(\n\"a\"\n)\nNow you can iterate over each link and print the\nhref\nattribute:\nPython\n>>>\nfor\nlink\nin\nlinks\n:\n...\naddress\n=\nlink\n[\n\"href\"\n]\n...\ntext\n=\nlink\n.\ntext\n...\nprint\n(\nf\n\"\n{\ntext\n}\n:\n{\naddress\n}\n\"\n)\n...\nAphrodite: /profiles/aphrodite\nPoseidon: /profiles/poseidon\nDionysus: /profiles/dionysus\nThe URLs contained in each\nhref\nattribute are relative URLs, which aren\u2019t very helpful if you want to navigate to them later using MechanicalSoup. If you happen to know the full URL, then you can assign the portion needed to construct a full URL.\nIn this case, the base URL is just\nhttp://olympus.realpython.org\n. Then you can concatenate the base URL with the relative URLs found in the\nsrc\nattribute:\nPython\n>>>\nbase_url\n=\n\"http://olympus.realpython.org\"\n>>>\nfor\nlink\nin\nlinks\n:\n...\naddress\n=\nbase_url\n+\nlink\n[\n\"href\"\n]\n...\ntext\n=\nlink\n.\ntext\n...\nprint\n(\nf\n\"\n{\ntext\n}\n:\n{\naddress\n}\n\"\n)\n...\nAphrodite: http://olympus.realpython.org/profiles/aphrodite\nPoseidon: http://olympus.realpython.org/profiles/poseidon\nDionysus: http://olympus.realpython.org/profiles/dionysus\nYou can do a lot with just\n.get()\n,\n.select()\n, and\n.submit()\n. That said, MechanicalSoup is capable of much more. To learn more about MechanicalSoup, check out the\nofficial docs\n.\nRemove ads\nCheck Your Understanding\nExpand the block below to check your understanding\nExercise: Submit a Form With MechanicalSoup\nShow/Hide\nUse MechanicalSoup to provide the correct username (\nzeus\n) and password (\nThunderDude\n) to the\nlogin form\nlocated at the URL\nhttp://olympus.realpython.org/login\n.\nOnce the form is submitted, display the title of the current page to determine that you\u2019ve been redirected to the\n/profiles\npage.\nYour program should print the text\n<title>All Profiles</title>\n.\nYou can expand the block below to see a solution.\nSolution: Submit a Form With MechanicalSoup\nShow/Hide\nFirst, import the\nmechanicalsoup\npackage and create a\nBroswer\nobject:\nPython\nimport\nmechanicalsoup\nbrowser\n=\nmechanicalsoup\n.\nBrowser\n()\nPoint the browser to the login page by passing the URL to\nbrowser.get()\nand grab the HTML with the\n.soup\nattribute:\nPython\nlogin_url\n=\n\"http://olympus.realpython.org/login\"\nlogin_page\n=\nbrowser\n.\nget\n(\nlogin_url\n)\nlogin_html\n=\nlogin_page\n.\nsoup\nlogin_html\nis a\nBeautifulSoup\ninstance. Because the page has only a single form on it, you can access the form via\nlogin_html.form\n. Using\n.select()\n, select the username and password inputs and fill them with the username\n\"zeus\"\nand the password\n\"ThunderDude\"\n:\nPython\nform\n=\nlogin_html\n.\nform\nform\n.\nselect\n(\n\"input\"\n)[\n0\n][\n\"value\"\n]\n=\n\"zeus\"\nform\n.\nselect\n(\n\"input\"\n)[\n1\n][\n\"value\"\n]\n=\n\"ThunderDude\"\nNow that the form is filled out, you can submit it with\nbrowser.submit()\n:\nPython\nprofiles_page\n=\nbrowser\n.\nsubmit\n(\nform\n,\nlogin_page\n.\nurl\n)\nIf you filled the form with the correct username and password, then\nprofiles_page\nshould actually point to the\n/profiles\npage. You can confirm this by printing the title of the page assigned to\nprofiles_page:\nPython\nprint\n(\nprofiles_page\n.\nsoup\n.\ntitle\n)\nYou should see the following text displayed:\nShell\n<title>All Profiles</title>\nIf instead you see the text\nLog In\nor something else, then the form submission failed.\nWhen you\u2019re ready, you can move on to the next section.\nInteract With Websites in Real Time\nSometimes you want to be able to fetch real-time data from a website that offers continually updated information.\nIn the dark days before you learned Python programming, you had to sit in front of a browser, clicking the\nRefresh\nbutton to reload the page each time you wanted to check if updated content was available. But now you can automate this process using the\n.get()\nmethod of the MechanicalSoup\nBrowser\nobject.\nOpen your browser of choice and navigate to the URL\nhttp://olympus.realpython.org/dice\n:\nThis\n/dice\npage simulates a roll of a six-sided die, updating the result each time you refresh the browser. Below, you\u2019ll write a program that repeatedly scrapes the page for a new result.\nThe first thing you need to do is determine which element on the page contains the result of the die roll. Do this now by right-clicking anywhere on the page and selecting\nView page source\n. A little more than halfway down the HTML code is an\n<h2>\ntag that looks like this:\nHTML\n<\nh2\nid\n=\n\"result\"\n>\n3\n</\nh2\n>\nThe text of the\n<h2>\ntag might be different for you, but this is the page element you need for scraping the result.\nNote:\nFor this example, you can easily check that there\u2019s only one element on the page with\nid=\"result\"\n. Although the\nid\nattribute is supposed to be unique, in practice you should always check that the element you\u2019re interested in is uniquely identified.\nNow start by writing a simple program that opens the\n/dice\npage, scrapes the result, and prints it to the console:\nPython\nmech_soup.py\nimport\nmechanicalsoup\nbrowser\n=\nmechanicalsoup\n.\nBrowser\n()\npage\n=\nbrowser\n.\nget\n(\n\"http://olympus.realpython.org/dice\"\n)\ntag\n=\npage\n.\nsoup\n.\nselect\n(\n\"#result\"\n)[\n0\n]\nresult\n=\ntag\n.\ntext\nprint\n(\nf\n\"The result of your dice roll is:\n{\nresult\n}\n\"\n)\nThis example uses the\nBeautifulSoup\nobject\u2019s\n.select()\nmethod to find the element with\nid=result\n. The string\n\"#result\"\n, which you pass to\n.select()\n, uses the\nCSS ID selector\n#\nto indicate that\nresult\nis an\nid\nvalue.\nTo periodically get a new result, you\u2019ll need to create a loop that loads the page at each step. So everything below the line\nbrowser = mechanicalsoup.Browser()\nin the above code needs to go in the body of the loop.\nFor this example, you want four rolls of the dice at ten-second intervals. To do that, the last line of your code needs to tell Python to pause running for ten seconds. You can do this with\n.sleep()\nfrom Python\u2019s\ntime\nmodule\n. The\n.sleep()\nmethod takes a single argument that represents the amount of time to sleep in seconds.\nHere\u2019s an example that illustrates how\nsleep()\nworks:\nPython\nimport\ntime\nprint\n(\n\"I'm about to wait for five seconds...\"\n)\ntime\n.\nsleep\n(\n5\n)\nprint\n(\n\"Done waiting!\"\n)\nWhen you run this code, you\u2019ll see that the\n\"Done waiting!\"\nmessage isn\u2019t displayed until five seconds have passed from when the first\nprint()\nfunction was executed.\nFor the die roll example, you\u2019ll need to pass the number\n10\nto\nsleep()\n. Here\u2019s the updated program:\nPython\nmech_soup.py\nimport\ntime\nimport\nmechanicalsoup\nbrowser\n=\nmechanicalsoup\n.\nBrowser\n()\nfor\ni\nin\nrange\n(\n4\n):\npage\n=\nbrowser\n.\nget\n(\n\"http://olympus.realpython.org/dice\"\n)\ntag\n=\npage\n.\nsoup\n.\nselect\n(\n\"#result\"\n)[\n0\n]\nresult\n=\ntag\n.\ntext\nprint\n(\nf\n\"The result of your dice roll is:\n{\nresult\n}\n\"\n)\ntime\n.\nsleep\n(\n10\n)\nWhen you run the program, you\u2019ll immediately see the first result printed to the console. After ten seconds, the second result is displayed, then the third, and finally the fourth. What happens after the fourth result is printed?\nThe program continues running for another ten seconds before it finally stops. That\u2019s kind of a waste of time! You can stop it from doing this by using an\nif\nstatement\nto run\ntime.sleep()\nfor only the first three requests:\nPython\nmech_soup.py\nimport\ntime\nimport\nmechanicalsoup\nbrowser\n=\nmechanicalsoup\n.\nBrowser\n()\nfor\ni\nin\nrange\n(\n4\n):\npage\n=\nbrowser\n.\nget\n(\n\"http://olympus.realpython.org/dice\"\n)\ntag\n=\npage\n.\nsoup\n.\nselect\n(\n\"#result\"\n)[\n0\n]\nresult\n=\ntag\n.\ntext\nprint\n(\nf\n\"The result of your dice roll is:\n{\nresult\n}\n\"\n)\n# Wait 10 seconds if this isn't the last request\nif\ni\n<\n3\n:\ntime\n.\nsleep\n(\n10\n)\nWith techniques like this, you can scrape data from websites that periodically update their data. However, you should be aware that requesting a page multiple times in rapid succession can be seen as suspicious, or even malicious, use of a website.\nImportant:\nMost websites publish a Terms of Use document. You can often find a link to it in the website\u2019s footer.\nAlways read this document before attempting to scrape data from a website. If you can\u2019t find the Terms of Use, then try to contact the website owner and ask them if they have any policies regarding request volume.\nFailure to comply with the Terms of Use could result in your IP being blocked, so be careful!\nIt\u2019s even possible to crash a server with an excessive number of requests, so you can imagine that many websites are concerned about the volume of requests to their server! Always check the Terms of Use and be respectful when sending multiple requests to a website.\nRemove ads\nConclusion\nAlthough it\u2019s possible to parse data from the Web using tools in Python\u2019s standard library, there are many tools on PyPI that can help simplify the process.\nIn this tutorial, you learned how to:\nRequest a web page using Python\u2019s built-in\nurllib\nmodule\nParse HTML using\nBeautiful Soup\nInteract with web forms using\nMechanicalSoup\nRepeatedly request data from a website to\ncheck for updates\nWriting automated web scraping programs is fun, and the Internet has no shortage of content that can lead to all sorts of exciting projects.\nJust remember, not everyone wants you pulling data from their web servers. Always check a website\u2019s Terms of Use before you start scraping, and be respectful about how you time your web requests so that you don\u2019t flood a server with traffic.\nSource Code:\nClick here to download the free source code\nthat you\u2019ll use to collect and parse data from the Web.\nAdditional Resources\nFor more information on web scraping with Python, check out the following resources:\nBeautiful Soup: Build a Web Scraper With Python\nAPI Integration in Python\nPython & APIs: A Winning Combo for Reading Public Data\nNote:\nIf you enjoyed what you learned in this sample from\nPython Basics: A Practical Introduction to Python 3\n, then be sure to check out\nthe rest of the book\n.\nTake the Quiz:\nTest your knowledge with our interactive \u201cA Practical Introduction to Web Scraping in Python\u201d quiz. You\u2019ll receive a score upon completion to help you track your learning progress:\nInteractive Quiz\nA Practical Introduction to Web Scraping in Python\nIn this quiz, you'll test your understanding of web scraping in Python. Web scraping is a powerful tool for data collection and analysis. By working through this quiz, you'll revisit how to parse website data using string methods, regular expressions, and HTML parsers, as well as how to interact with forms and other website components.\nFrequently Asked Questions\nNow that you have some experience with web scraping in Python, you can use the questions and answers below to check your understanding and recap what you\u2019ve learned.\nThese FAQs are related to the most important concepts you\u2019ve covered in this tutorial. Click the\nShow/Hide\ntoggle beside each question to reveal the answer.\nIs Python good for web scraping?\nShow/Hide\nYes, Python is a popular choice for web scraping due to its ease of use and the availability of powerful libraries like Beautiful Soup and MechanicalSoup that simplify the process.\nHow can you scrape websites with Python?\nShow/Hide\nYou can scrape websites with Python by using libraries like\nurllib\nto fetch HTML, Beautiful Soup to parse HTML, and MechanicalSoup to interact with web forms.\nIs data scraping illegal?\nShow/Hide\nData scraping can be illegal if it violates a website\u2019s terms of service or involves accessing data without permission. Always check the website\u2019s acceptable use policy before scraping.\nWhat tools can you use for parsing HTML in Python?\nShow/Hide\nYou can use tools such as Beautiful Soup and\nlxml\nto parse HTML in Python. These libraries make it easy to navigate and extract data from HTML documents.\nHow can you handle forms in web scraping?\nShow/Hide\nYou can handle forms in web scraping using MechanicalSoup, which allows you to fill out and submit forms programmatically within a headless browser session.\nMark as Completed\nShare\nWatch Now\nThis tutorial has a related video course created by the Real Python team. Watch it together with the written tutorial to deepen your understanding:\nIntroduction to Web Scraping With Python\n\ud83d\udc0d Python Tricks \ud83d\udc8c\nGet a short & sweet\nPython Trick\ndelivered to your inbox every couple of days. No spam ever. Unsubscribe any time. Curated by the Real Python team.\nSend Me Python Tricks \u00bb\nAbout\nDavid Amos\nDavid is a writer, programmer, and mathematician passionate about exploring mathematics through code.\n\u00bb More about David\nEach tutorial at Real Python is created by a team of developers so that it meets our high quality standards. The team members who worked on this tutorial are:\nAldren\nGeir Arne\nJoanna\nJacob\nKate\nMartin\nPhilipp\nMaster\nReal-World Python Skills\nWith Unlimited Access to Real\u00a0Python\nJoin us and get access to thousands of tutorials, hands-on video courses, and a community of expert\u00a0Pythonistas:\nLevel Up Your Python Skills \u00bb\nMaster\nReal-World Python Skills\nWith Unlimited Access to Real\u00a0Python\nJoin us and get access to thousands of tutorials, hands-on video courses, and a community of expert Pythonistas:\nLevel Up Your Python Skills \u00bb\nWhat Do You Think?\nRate this article:\nLinkedIn\nTwitter\nBluesky\nFacebook\nEmail\nWhat\u2019s your #1 takeaway or favorite thing you learned? How are you going to put your newfound skills to use? Leave a comment below and let us know.\nCommenting Tips:\nThe most useful comments are those written with the goal of learning from or helping out other students.\nGet tips for asking good questions\nand\nget answers to common questions in our support portal\n.\nLooking for a real-time conversation? Visit the\nReal Python Community Chat\nor join the next\n\u201cOffice\u00a0Hours\u201d Live Q&A Session\n. Happy Pythoning!\nKeep Learning\nRelated Topics:\nintermediate\nweb-scraping\nRecommended Video Course:\nIntroduction to Web Scraping With Python\nRelated Tutorials:\nBeautiful Soup: Build a Web Scraper With Python\nModern Web Automation With Python and Selenium\nPython & APIs: A Winning Combo for Reading Public Data\nWeb Scraping With Scrapy and MongoDB\nHow to Download Files From URLs With Python\nKeep reading Real\u00a0Python by creating a free account or signing\u00a0in:\nContinue \u00bb\nAlready have an account?\nSign-In\nAlmost there! Complete this form and click the button below to gain instant\u00a0access:\n\u00d7\nA Practical Introduction to Web Scraping in Python (Source Code)\nSend Code \u00bb\n\ud83d\udd12 No spam. We take your privacy seriously.",
        "image_urls": [
          {
            "url": "https://files.realpython.com/media/Python-Basics-Chapter-on-Web-Scraping_Watermarked.f8d56f56c22c.jpg",
            "score": 2
          },
          {
            "url": "https://files.realpython.com/media/Python-Basics-Chapter-on-Web-Scraping_Watermarked.f8d56f56c22c.jpg",
            "score": 2
          },
          {
            "url": "https://files.realpython.com/media/website_aphrodite.10b67047ebc2.png",
            "score": 2
          },
          {
            "url": "https://files.realpython.com/media/website_dionysos_page.8d7be251d9a0.png",
            "score": 2
          },
          {
            "url": "https://files.realpython.com/media/website_login.739f488fbe74.png",
            "score": 2
          },
          {
            "url": "https://files.realpython.com/media/website_dice.3cdd09061f55.png",
            "score": 2
          },
          {
            "url": "https://files.realpython.com/media/Python-Basics-Chapter-on-Web-Scraping_Watermarked.f8d56f56c22c.jpg",
            "score": 2
          },
          {
            "url": "https://realpython.com/cdn-cgi/image/width=800,height=800,fit=crop,gravity=auto,format=auto/https://files.realpython.com/media/gahjelle.470149ee709e.jpg",
            "score": 2
          },
          {
            "url": "https://realpython.com/cdn-cgi/image/width=800,height=800,fit=crop,gravity=auto,format=auto/https://files.realpython.com/media/jjablonksi-avatar.e37c4f83308e.jpg",
            "score": 2
          },
          {
            "url": "https://files.realpython.com/media/Python-Basics-Chapter-on-Web-Scraping_Watermarked.f8d56f56c22c.jpg",
            "score": 2
          }
        ],
        "title": "A Practical Introduction to Web Scraping in Python \u2013 Real Python"
      },
      {
        "url": "https://www.youtube.com/watch?v=DcI_AZqfZVc",
        "raw_content": "Advanced Web Scraping Tutorial! (w/ Python Beautiful Soup Library) - YouTube\nAbout\nPress\nCopyright\nContact us\nCreators\nAdvertise\nDevelopers\nTerms\nPrivacy\nPolicy & Safety\nHow YouTube works\nTest new features\nNFL Sunday Ticket\n\u00a9 2025 Google LLC",
        "image_urls": [],
        "title": "Advanced Web Scraping Tutorial! (w/ Python Beautiful Soup Library) - YouTube"
      }
    ]
  },
  "duckduckgo_Technology News": {
    "success": true,
    "urls_found": 3,
    "urls_scraped": 3,
    "retrieval_time": 1.052483081817627,
    "scraping_time": 0.7257859706878662,
    "total_time": 1.7782690525054932,
    "content_analysis": {
      "successful_scrapes": 3,
      "failed_scrapes": 0,
      "total_content_length": 47242,
      "total_images": 23,
      "relevance_score": 100.0,
      "content_samples": [
        {
          "url": "https://www.ironhack.com/us/blog/artificial-intelligence-breakthroughs-a-look-ahead-to-2024",
          "title": "Artificial Intelligence Breakthroughs: Key Developments to Expect in 2025 | Ironhack Blog",
          "content_length": 16443,
          "keyword_matches": 3,
          "sample_content": "Artificial Intelligence Breakthroughs: Key Developments to Expect in 2025 | Ironhack Blog\nArtificial intelligence (AI) has been a transformative force in our world, reshaping industries, economies, an..."
        },
        {
          "url": "https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/",
          "title": "Year in review: Google's biggest AI advancements of 2024",
          "content_length": 25929,
          "keyword_matches": 4,
          "sample_content": "Year in review: Google's biggest AI advancements of 2024\n2024: A year of extraordinary progress and advancement in AI\nJan 23, 2025\n\u00b7\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nA look back on a yea..."
        },
        {
          "url": "https://www.forbes.com/sites/bernardmarr/2024/12/16/6-game-changing-ai-breakthroughs-that-defined-2024/",
          "title": "6 Game-Changing AI Breakthroughs That Defined 2024",
          "content_length": 4870,
          "keyword_matches": 3,
          "sample_content": "6 Game-Changing AI Breakthroughs That Defined 2024\nInnovation\nEnterprise Tech\n6 Game-Changing AI Breakthroughs That Defined 2024\nBy\nBernard Marr\n,\nContributor.\nFollow Author\nDec 16, 2024, 02:09am EST\n..."
        }
      ],
      "titles": [
        "Artificial Intelligence Breakthroughs: Key Developments to Expect in 2025 | Ironhack Blog",
        "Year in review: Google's biggest AI advancements of 2024",
        "6 Game-Changing AI Breakthroughs That Defined 2024"
      ]
    },
    "search_results": [
      {
        "title": "Artificial Intelligence Breakthroughs: Key Developments to ...",
        "href": "https://www.ironhack.com/us/blog/artificial-intelligence-breakthroughs-a-look-ahead-to-2024",
        "body": "Dec 30, 2024 \u2014 Key AI Breakthroughs to Watch in 2025 \u00b7 1. Deep Learning Advancements \u00b7 2. Next-Gen Natural Language Processing (NLP) \u00b7 3. Healthcare ..."
      },
      {
        "title": "Year in review: Google's biggest AI advancements of 2024",
        "href": "https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/",
        "body": "Jan 23, 2025 \u2014 At the start of 2024, we introduced ImageFX, a new generative AI tool that creates images from text prompts, and MusicFX, a tool for creating up ..."
      },
      {
        "title": "6 Game-Changing AI Breakthroughs That Defined 2024",
        "href": "https://www.forbes.com/sites/bernardmarr/2024/12/16/6-game-changing-ai-breakthroughs-that-defined-2024/",
        "body": "Dec 16, 2024 \u2014 Here, we explore seven pivotal AI developments , including historic regulatory frameworks and Nobel Prize-winning breakthroughs, that are ..."
      }
    ],
    "scraped_results": [
      {
        "url": "https://www.ironhack.com/us/blog/artificial-intelligence-breakthroughs-a-look-ahead-to-2024",
        "raw_content": "Artificial Intelligence Breakthroughs: Key Developments to Expect in 2025 | Ironhack Blog\nArtificial intelligence (AI) has been a transformative force in our world, reshaping industries, economies, and our daily lives. As we approach 2025, the AI landscape is poised for significant breakthroughs that promise to further accelerate its integration into society. So strap in as we explore what AI is, its evolving role in society, and predictions for its future.\nArtificial intelligence (AI) is rapidly advancing, impacting various industries. For example, in healthcare, AI-powered diagnostics are achieving accuracy levels comparable to human doctors, significantly improving early detection of diseases such as cancer. AI-driven robots are revolutionizing supply chain management in logistics by optimizing routes and improving efficiency, which companies like Amazon are currently leveraging.\nBy 2030, AI is projected to add an impressive $13 trillion to the global economy, driving a 1.2% annual boost in GDP, according to McKinsey\n. As we move into 2025,\nGartner anticipates that 75% of enterprises will transition from AI pilots to full-scale operations\n, sparking a massive increase in streaming data and analytics infrastructures. The future of AI is here\u2014are you ready?\nUnderstanding Artificial Intelligence\nArtificial intelligence, often abbreviated as AI, refers to the simulation of human intelligence in\nmachines that are programmed to think and learn like humans\n. AI systems are designed to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and problem-solving. These systems are powered by advanced algorithms and massive datasets, enabling them to analyze, predict, and adapt to various situations. Before we get into the latest advancements, let's first understand the key components that make AI function and the process that brings AI to life.\nMachine learning algorithms\nAt the heart of AI development are machine learning algorithms. These are the building blocks that\nenable AI systems to learn from data, make predictions, and adapt to new information.\nHere\u2019s a brief overview of the primary types of machine learning algorithms:\nSupervised learning:\nthis approach trains the AI system on labeled data. By providing the input and the desired output, the algorithm\nlearns to map inputs to outputs,\nmaking predictions based on patterns it discovers during training. An example of this is spam email classification, where the algorithm learns a pattern from labeled examples to decide which messages to filter out.\nUnsupervised learning:\nthis approach involves teaching AI systems on unlabeled data, with the goal of the algorithm being to\ndiscover hidden patterns or structures\nwithin the data. Clustering and dimensionality reduction are common tasks in unsupervised learning.\nReinforcement learning:\nthis approach works to train AI agents to make sequences of decisions in an environment to maximize a reward. These agents learn through trial and error,\nmaking decisions and receiving feedback\nto improve their performance. Reinforcement learning is crucial in developing autonomous systems such as self-driving cars and game-playing AI.\nSemi-supervised learning:\nthis approach combines elements of both supervised and unsupervised learning. It uses a small amount of labeled data and a large amount of unlabeled data to train the AI system. This approach is particularly\nuseful when obtaining labeled data is expensive or time-consuming.\nDeep learning:\nthis approach is a subset of machine learning that focuses on neural networks with multiple layers (deep neural networks). These networks can\nlearn complex representations from data,\nenabling them to excel in tasks like image and speech recognition. Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) and examples of deep learning architectures.\nData collection and preprocessing\nTo create robust AI systems, high-quality data is essential, leading to more accurate and highly developed algorithms. The process typically involves the following:\nData collection:\ngathering a diverse and representative dataset is crucial. For image recognition, this might involve collecting thousands of images with various objects and backgrounds.\nData labeling:\nannotating data with the correct output is necessary for supervised learning algorithms. This looks like labeling audio clips with transcriptions or matching images with their corresponding objects.\nData preprocessing:\nmaking data ready for training is often compulsory, and may include normalization, data cleaning, and feature extraction.\nTraining and model development\nOnce data is collected and preprocessed, the AI model is trained through the following processes:\nModel selection:\nchoosing an appropriate machine learning model or neural network architecture for the task at hand.\nTraining loop:\niteratively presenting the data to the model, adjusting model parameters, and evaluating its performance on a validation dataset.\nHyperparameter tuning:\nfine-tuning hyperparameters, such as learning rates or network infrastructures, to refine the model\u2019s performance.\nRegularization:\napplying techniques like dropout or L1/L2 regularization to prevent overfitting, where the model performs well on the training data but poorly on new, unseen data.\nOptimization:\nusing algorithms like stochastic gradient descent (SGD) to adjust the model\u2019s parameters for better performance.\nPhoto by\nGoogle DeepMind\non\nUnsplash\nInference and deployment\nOnce the AI model is trained, it\u2019s ready for deployment. Inference is the process of using the trained model to make predictions on new or unfamiliar data. These phases involve:\nScalability:\nensuring that the AI system can handle large volumes of data and make predictions quickly and efficiently.\nReal-time inference:\ndeveloping AI systems with the ability with the capacity for real-time inference. This is a hefty requirement for infrastructures that control autonomous vehicles, as decisions must be made within milliseconds.\nMonitoring and maintenance:\ncontinuously monitoring the AI system\u2019s performance, considering user-feedback, and making updates as necessary is vital for the consistency and reliability of the application.\nThe Future of Machine Learning\nKey AI Breakthroughs to Watch in 2025\nAs we approach 2025, AI continues to transform industries at an unprecedented pace. Let\u2019s explore some of the latest advancements shaping our world:\n1. Deep Learning Advancements\nDeep learning, inspired by the human brain, is driving breakthroughs in AI. With models like CNNs and RNNs, applications in\nimage and speech recognition are achieving human-level accuracy\n, revolutionizing fields like media, security, and accessibility.\n2. Next-Gen Natural Language Processing (NLP)\nNLP is evolving rapidly, thanks to transformer-based models. BERT redefined language understanding, and\nOpenAI\u2019s GPT-4 now pushes the boundaries of human-like text generation\n. These advancements are driving innovations in customer service, search engines, and content creation.\n3. Healthcare Transformation\nAI is saving lives by\ndetecting diseases like cancer and diabetes earlier and with higher accuracy\n. It\u2019s also accelerating drug discovery and improving patient care, ensuring more personalized and effective treatments.\n4. Climate Change Solutions\nAI-powered climate models are\noffering more precise predictions\n, aiding policymakers and scientists in developing informed strategies for tackling global challenges.\n5. Finance and Investment Revolution\nAI is reshaping finance with\nalgorithms that execute trades in milliseconds\n, analyze massive datasets, and uncover profitable opportunities faster than ever.\n6. Autonomous Systems Progress\nSelf-driving cars and drones are advancing toward reliability and efficiency, with\nAI reducing human error and making autonomous transportation a safer and more viable reality.\nSource:\nSemrush\nIs AI the Future? Predictions for AI in 2025\nAs we step into 2025,\nAI\u2019s influence on our lives continues to deepen\n. From reshaping industries to redefining creativity and ethics, here\u2019s what to expect as AI becomes even more integral to our human future:\n1. Tackling AI Bias\nAddressing bias in AI systems will remain a critical focus. Advances in fairness-aware machine learning algorithms and diversified datasets will help reduce inequities,\nensuring AI solutions are inclusive and reliable.\n2. Strengthening AI Regulation\nGovernments and regulatory bodies are expected to adopt\nstricter measures addressing algorithm transparency, job displacement, and ethical risks\n. Clearer frameworks will emerge to balance innovation with safety and fairness.\n3. AI-Driven Creativity\nAI\u2019s role in generating art, music, and literature will expand, producing creations indistinguishable from human-made works. As AI becomes a routine collaborator,\nnew debates around artistic ownership, copyright, and creativity will take center stage.\n4. Quantum AI Synergy\nThe integration of quantum computing with\nAI will supercharge problem-solving capabilities\n. Breakthroughs in healthcare, materials science, cryptography, and finance are anticipated as AI leverages quantum systems to tackle complex challenges at lightning speed.\n5. Personalized Education with AI\nAI-powered platforms will deliver\nhighly personalized learning experiences, adapting to individual student needs.\nCoupled with VR, students could explore interactive worlds to understand historical events, scientific phenomena, or abstract concepts in immersive ways.\n7. Expanding AI Career Opportunities\nThe demand for AI professionals will skyrocket, with companies seeking data scientists, machine learning engineers, and AI developers to lead innovation. Additionally,\nAI ethicists will play a vital role in ensuring ethical, transparent, and bias-free AI development.\nEthics & Bias in Artificial Intelligence\nSteps to Prepare for AI Implementation\nAssessment\n: Evaluate your organization's readiness for AI.\nPilot Projects\n: Start with small-scale AI projects to test feasibility.\nTool Selection\n: Choose the right AI tools and platforms for your needs.\nTraining\n: Train your team on AI technologies and their applications.\nImplementation\n: Scale up successful pilot projects and integrate AI into core business processes.\nAs we stand on the cusp of 2025, the trajectory of AI is undeniably upward, with breakthroughs waiting to be unlocked and horizons waiting to be expanded. The question isn\u2019t whether AI is part of your future, but rather\nhow you can be a part of shaping its future\n. If you\u2019re eager to be at the forefront of this technological revolution, there\u2019s no better time to take action. Check out our bootcamps and become a catalyst for change in the world of artificial intelligence.\nAbout the Author:\nJuliette Carreiro\nis a tech writer, with two years of experience writing in-depth articles for Ironhack. Covering everything from career advice and navigating the job ladder, to the future impact of AI in the global tech space, Juliette is the go-to for Ironhack\u2019s community of aspiring tech professionals.\nDiscover Ironhack's Bootcamp in AI\nArtificial Intelligence Engineering with Ironhack\nGain all of the skills you need to launch your career in Artificial Intelligence. Play with AI models like OpenAI's ChatGPT and roll out your own AI chatbot.\nI accept the\nTerms and Conditions\nand\nPrivacy Policy\nSend me more free content about tech & Ironhack services\nRequest Syllabus\nRelated Articles\n9 minutes\nHow AI is Reshaping Entry-Level Tech Roles\nIronhack - 2025-08-14\nAI is rapidly changing entry-level tech jobs. Learn how to stay ahead with the right skills, tools, and mindset.\nRead article\n8 minutes\nAI video generator tools: The future of visual storytelling is here\nIronhack - 2025-07-29\nAI video tools are transforming how developers, designers, and marketers create dynamic, professional video content with just a script and a few clicks.\nRead article\n10 minutes\nHow AI voice generators are transforming content creation\nIronhack - 2025-07-15\nFrom product demos to personalized voiceovers, AI voice generators are helping creators and companies produce powerful audio content, fast and at scale.\nRead article\n5 minutes\nAI Skills Every Developer Needs in 2025\nJuliette Carreiro - 2025-06-24\nDiscover exactly what you can do to up your game as a web developer.\nRead article\n4 minutes\nThe Best AI Chatbots for 2025: A Comprehensive Comparison\nTala Sammar - 2025-06-24\nExploring the Top AI Chatbots for 2025: Features, Strengths, Limitations, and Use Cases Compared.\nRead article\n7 minutes\nAI-Generated Code: Should You Worry About Your Job?\nIronhack - 2025-06-24\nWhy AI Isn\u2019t the End of the Road for Developers \u2014 and What You Should Do to Stay Ahead\nRead article\n10 minutes\nTop 15 Artificial Intelligence Apps\nIronhack - 2025-05-11\nDiscover the 15 best free artificial intelligence software programs, perfect for getting started or honing your AI skills. AI tools for students, developers, and entrepreneurs!\nRead article\n6 minutes\nAI Skills Every Startup Employee Needs in 2025\nJuliette Carreiro - 2025-03-11\nDiscover how your startup can benefit from artificial intelligence tools in 2025.\nRead article\n6 minutes\nAI Skills Every Product Manager Needs in 2025\nJuliette Carreiro - 2025-02-11\nLearn how to kickstart your career as an AI product manager.\nRead article\n7 minutes\nAI Skills EVERY Professional Needs in 2025\nJuliette Carreiro - 2025-02-10\nDiscover the AI skills that any professional in any sector can use.\nRead article\n8 minutes\nAI Job Interviews: Myths vs. Realities\nIronhack - 2025-01-21\nSeparating Fact from Fiction in AI Job Interviews\nRead article\n7 minutes\nAI Trends in 2025: Emerging Technologies, Skills\nJuliette Carreiro - 2024-12-31\nHere\u2019s what we can look forward to in 2025 in the field of AI.\nRead article\nRecommended for you\n7 minutes\nLearn Data Science and Machine Learning with Ironhack\u2019s New Bootcamp\nWhitney van der Zanden - 2023-11-14\nLearn tech\u2019s most versatile skill set, and launch your new career.\nRead article\n5 minutes\n11 Great Jobs in Tech for Creative People\nJuliette Carreiro - 2023-07-08\nDiscover jobs in tech that don't require math!\nRead article\n9 minutes\nWhat is a Tech Lead? Responsibilities, Skills, and Career Path\nJuliette Carreiro - 2023-06-17\nLet\u2019s fight some common misconceptions about a key member in the software development team.\nRead article\n7 minutes\nGoogle Bard: What it Means for You\nIronhack - 2023-06-02\nYou\u2019ve heard of ChatGPT, but do you know what Google Bard can do for you?\nRead article\n7 minutes\n10 Best Tech Companies To Work For And Why\nJuliette Carreiro - 2024-04-02\nA look into what it's like to work for the companies making the biggest impact in the world of tech.\nRead article\n9 minutes\nHow to Begin a Career in Cybersecurity Without Previous Knowledge\nJuliette Carreiro - 2023-12-14\nLand your first job in cybersecurity, without sweating your lack of experience!\nRead article\nData Analytics Is Changing The World - Here\u2019s Why You Should Care\nMarta Aguilar - 2023-07-05\nData Analytics isn't just good for business. It's good for the planet, and it's doing great things for YOU! Yes YOU! Let's see how Data is being used to change the world, and why you should be paying attention.\nRead article\n5 minutes\nWhat Does a Career in Web3 Look Like?\nIronhack - 2022-11-11\nMad about Meta? Curious about Crypto? Maybe you need a career in Web3...\nRead article\n8 minutes\nCommon Misconceptions About Tech Bootcamps\nIronhack - 2023-04-27\nThey\u2019re expensive, time-consuming, and who knows if you will get a job, right? Not quite.\nRead article\n7 minutes\nA Day in the Life of a Tech Bootcamp Student\nJuliette Carreiro - 2023-10-22\nDiscover what it\u2019s really like to be an Ironhacker\nRead article\n26 minutes\nThe Gender Gap in Tech\u2026Let\u2019s Talk About It\nJuliette Carreiro - 2023-03-09\nTech\u2019s gender gap is quite pervasive and requires societal and personal efforts to resolve.\nRead article\n8 minutes\nTop Coding Languages to Learn in 2025: Stay Ahead in Tech\nJuliette Carreiro - 2024-12-30\nDiscover the best programming languages to learn in 2025.\nRead article\nReady to join?\nMore than 10,000 career changers and entrepreneurs launched their careers in the tech industry with Ironhack's bootcamps. Start your new career journey, and join the tech revolution!\nEmail\n*\nSign up free!\nI accept the\nTerms and Conditions\nand\nPrivacy Policy",
        "image_urls": [
          {
            "url": "https://www.datocms-assets.com/14946/1724974664-minh-pham-hi6gy-p-wbi-unsplash.jpg?auto=format&fit=max&w=864",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1724974688-google-deepmind-oy2yxvl1wlg-unsplash.jpg?auto=format&fit=max&w=864",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1724974730-original.png?auto=format&fit=max&w=864",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1709215796-dall-e-2024-02-29-15-09-18-an-organized-ai-engineer-s-desk-featuring-a-sleek-setup-with-a-single-monitor-displaying-clean-efficient-code-a-high-performance-laptop-with-a-minim.webp?auto=format&fit=crop&h=145&q=45&w=296",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1755171475-blog_entry-roles-with-ai.png?auto=format&crop=left&fit=crop&h=160&q=45&w=363",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1753799833-artificial-intelligence-1.png?auto=format&crop=left&fit=crop&h=160&q=45&w=363",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1752575782-voice-generator-blog-post.png?auto=format&crop=left&fit=crop&h=160&q=45&w=363",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1709637269-ai3.png?auto=format&crop=left&fit=crop&h=160&q=45&w=363",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1733221036-ai_chatbots_2025_720.png?auto=format&crop=left&fit=crop&h=160&q=45&w=363",
            "score": 0
          },
          {
            "url": "https://www.datocms-assets.com/14946/1750694158-artificial-intelligence.png?auto=format&crop=left&fit=crop&h=160&q=45&w=363",
            "score": 0
          }
        ],
        "title": "Artificial Intelligence Breakthroughs: Key Developments to Expect in 2025 | Ironhack Blog"
      },
      {
        "url": "https://blog.google/technology/ai/2024-ai-extraordinary-progress-advancement/",
        "raw_content": "Year in review: Google's biggest AI advancements of 2024\n2024: A year of extraordinary progress and advancement in AI\nJan 23, 2025\n\u00b7\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nA look back on a year of breakthroughs, progress and extraordinary accomplishments.\nDemis Hassabis\nCEO Google DeepMind\nJames Manyika\nSenior Vice President, Research, Technology & Society\nJeff Dean\nChief Scientist\nRead AI-generated summary\nBullet points\nThis article summarizes Google's AI advancements in 2024, highlighting their commitment to responsible development.\nGoogle released Gemini 2.0, a powerful AI model designed for the \"agentic era,\" and integrated it into various products.\nThey made significant progress in generative AI, releasing updates to Imagen, Veo, and MusicFX, empowering creativity.\nGoogle also advanced robotics, hardware, and computing, with breakthroughs in quantum computing and chip design.\nThey explored AI's potential in science, biology, and mathematics, with notable achievements in protein structure prediction and geometry.\nSummaries were generated by Google AI. Generative AI is experimental.\nShare\nTwitter\nFacebook\nLinkedIn\nMail\nCopy link\nAs we move into 2025, we wanted to take a moment to recognize the astonishing progress of the last year. From\nnew Gemini models built for the agentic era\nand empowering\ncreativity\n, to an\nAI system\nthat designs novel, high-strength protein binders,\nAI\u2013enabled neuroscience\nand even\nlandmark advances\nin quantum computing, we\u2019ve been boldly and responsibly advancing the frontiers of artificial intelligence and all the ways it can benefit humanity.\nAs we and our colleagues\nwrote\ntwo years ago in an essay titled\nWhy we focus on AI\n:\n\u201c\nOur approach to developing and harnessing the potential of AI is grounded in our founding mission \u2014 to organize the world\u2019s information and make it universally accessible and useful \u2014 and it is shaped by our commitment to improve the lives of as many people as possible\n.\u201d\nThis remains as true today as it was when we first wrote it.\nIn this 2024 Year-in-Review post, we look back on a year's worth of extraordinary progress in AI, made possible by the many incredible teams across Google, that helped deliver on that mission and commitment \u2014 progress that sets the stage for more to come this year.\nRelentless innovation in models, products and technologies\n2024 was a year of experimenting, fast shipping, and putting our latest technologies in the hands of developers.\nIn December 2024, we released the first models in our\nGemini 2.0\nexperimental series \u2014 AI models designed for the agentic era. First out of the gate was Gemini 2.0 Flash, our workhorse model, followed by prototypes from the frontiers of our agentic research including: an updated\nProject Astra\n, which explores the capabilities of a universal AI assistant;\nProject Mariner\n, an early prototype capable of taking actions in Chrome as an experimental extension; and\nJules\n, an AI-powered code agent. We're looking forward to bringing Gemini 2.0\u2019s powerful capabilities to our flagship products \u2014 in Search, we\u2019ve already started testing in\nAI Overviews\n, which are now used by over a billion people to ask new types of questions.\nWe also released\nDeep Research\n, a new agentic feature in Gemini Advanced that saves people hours of research work by creating and executing multi-step plans for finding answers to complicated questions; and introduced\nGemini 2.0 Flash Thinking Experimental\n, an experimental model that explicitly shows its thoughts.\nThese advances followed swift progress earlier in the year, from incorporating\nGemini\u2019s capabilities into more Google products\nto the release of\nGemini 1.5 Pro\nand\nGemini 1.5 Flash\n\u2014 a model optimized for speed and efficiency. 1.5 Flash\u2019s compact size made it more cost-efficient to serve, and in 2024 it became our most popular model for developers.\nAnd we improved and updated\nAI Studio\n, which provides a host of resources for developers. It is now available as a progressive web app (PWA) that can be installed on desktop, iOS and Android.\nNotably, it\u2019s been exciting to see the public reception to several\nnew features\nfor NotebookLM, such as Audio Overviews, which can take uploaded source material and produce a\n\u201cdeep dive\u201d discussion\nbetween\ntwo AI hosts\n.\nYour browser does not support the audio element.\nNotebookLM Audio Overview\nIn this Audio Overview, two AI hosts dive into the world of NotebookLM updates.\nMore natural and intuitive handling of speech input and output remains at the core of several of our products:\nGemini Live\n,\nProject Astra\n,\nJourney Voices\nand\nYouTube\u2019s auto dubbing\n.\nContinuing our long history of contributing innovations to the open community \u2014\u00a0such as with\nTransformers\n,\nTensorFlow\n,\nBERT\n,\nT5\n,\nJAX\n,\nAlphaFold\nand\nAlphaCode\n\u2014 we released two new models from\nGemma\n, our state-of-the-art open model built from the same research and technology used to create the Gemini models. Gemma\noutperformed\nsimilarly sized open models on capabilities like question answering, reasoning, math / science and coding. And we released\nGemma Scope\n, which provides tools that help researchers understand the inner workings of Gemma 2.\nWe also continued to improve the factuality of our models and minimize hallucinations. In December, for example, we published\nFACTS Grounding\n, a new benchmark \u2014 based on collaboration between Google DeepMind, Google Research and Kaggle \u2014 for evaluating how accurately large language models ground their responses in provided source material and avoid hallucinations.\nThe FACTS Grounding dataset comprises 1,719 examples, each carefully crafted to require long-form responses grounded in the context document provided.\nWe tested leading LLMs using FACTS Grounding, launched the\nFACTS leaderboard\non Kaggle and are proud that Gemini 2.0 Flash Experimental, Gemini 1.5 Flash and Gemini 1.5 Pro currently have the three highest factuality scores, with gemini-2.0-flash-exp at 83.6%.\nMoreover, we improved underlying ML efficiency through pioneering\ntechniques\nlike\nblockwise parallel decoding\n,\nimproved confidence-based deferral\nand\nspeculative decoding\nthat reduce the inference times of LLMs, allowing them to generate responses more quickly. These improvements are used across Google products and set a standard throughout the industry.\nCombining AI with sport, in March we released\nTacticAI\n, an AI system for football tactics that can provide experts with tactical insights, particularly on corner kicks.\nUnderlying all of our models and products is our ongoing commitment to research leadership. Indeed, in a\n2010-2023 WIPO survey of citations for papers on Generative AI\n, Google including Google Research and Google DeepMind\u2019s citations were more than double the second-most cited institution.\nThis WIPO graph, based on January 2024 data from The Lens, illustrates more than a decade\u2019s worth of Alphabet\u2019s generative AI scientific publication efforts.\nFinally, progress was made with Project Starline, our \u201cmagic window\u201d technology project that enables friends, families and coworkers to feel like they\u2019re together from any distance. We\npartnered with HP\nto start commercialization, with the goal of enabling it directly from video conferencing services like Google Meet and Zoom.\nEmpowering creative vision with generative AI\nWe believe AI holds great potential to enable new forms of creativity, democratize creative output and help people express their artistic visions. This is why last year we introduced a series of updates across our generative media tools, covering images, music and video.\nAt the start of 2024, we\nintroduced\nImageFX, a new generative AI tool that creates images from text prompts, and MusicFX, a tool for creating up-to-70-second audio clips also based on text prompts. At I/O, we\nshared an early preview\nof MusicFX DJ, a tool that helps bring the joy of live music creation to more people. In October, we collaborated with\nJacob Collier\non making MusicFX DJ simpler to use, especially for new or aspiring musicians. And we updated our music AI toolkit\nMusic AI Sandbox\n, and evolved our\nDream Track experiment\nwhich allowed U.S. creators to explore a range of genres and prompts that generate instrumental soundtracks with powerful text-to-music models.\nLater in 2024, we released state-of-the-art updates to our image and video models:\nVeo 2\nand\nImagen 3\n. As our highest quality text-to-image model, Imagen 3 is capable of generating images with even better detail, richer lighting and fewer distracting artifacts than our previous models; while Veo demonstrated an improved understanding of real-world physics and the nuances of human movement and expression alongside its overall attention-to-detail and realism.\nVeo represents a significant step forward in high-quality video generation.\nResearch in this field continued apace. We explored ways to use AI to improve editing, for example by\nusing it\nto control of attributes like transparency, roughness or other physical properties of objects:\nIn these examples of AI editing with synthetic data generation, Input shows a novel, held-out image the model has never seen before. Output shows the model output, which successfully edits material properties.\nIn the field of\naudio generation\n, we announced improvements to video-to-audio (V2A) technology, which can generate dynamic soundscapes through natural language text prompts based on on-screen action. This technology is pairable with AI-created video through\nVeo\n.\nGames are an ideal environment for creative exploration of new worlds, as well as training and evaluating embodied agents. In 2024, we introduced\nGenie 2\n, a foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents. This followed the\nintroduction of SIMA\n, a Scalable Instructable Multiworld Agent that can follow natural-language instructions to carry out tasks in a variety of video game settings.\nThe architecture of intelligence: advances in robotics, hardware and computing\nAs our multimodal models become more capable and gain a better understanding of the world and its physics, they are making possible incredible new advances in robotics and bringing us closer to our goal of ever-more capable and helpful robots.\nWith ALOHA Unleashed, our robot learned to tie a shoelace, hang a shirt, repair another robot, insert a gear and even clean a kitchen.\nAt the beginning of the year, we\nintroduced\nAutoRT, SARA-RT and RT-Trajectory, extensions of our\nRobotics Transformers\nwork intended to help robots better understand and navigate their environments, and make decisions faster. We also published\nALOHA Unleashed\n, a breakthrough in teaching robots on how to use two robotic arms in coordination, and\nDemoStart\n, which uses a reinforcement learning algorithm to improve real-world performance on a multi-fingered robotic hand by using simulations.\nRobotic Transformer 2 (RT-2) is a novel vision-language-action model that learns from both web and robotics data.\nBeyond robotics, our\nAlphaChip\nreinforcement learning method for accelerating and improving chip floorplanning is transforming the design process for chips found in data centers, smartphones and more. To accelerate adoption of these techniques, we released a\npre-trained checkpoint\nto enable external parties to more easily make use of the\nAlphaChip open source release\nfor their own chip designs. And we made\nTrillium\n, our sixth-generation and most performant TPU to date, generally available to Google Cloud customers. Advances in computer chips have accelerated AI. And now, AI can return the favor.\nAlphaChip can learn the relationships between interconnected chip components and generalize across chips, letting AlphaChip improve with each layout it designs.\nOur research also focused on correcting the errors in the physical hardware of today's quantum computers. In November, we launched\nAlphaQubit\n, an AI-based decoder that identifies quantum computing errors with state-of-the-art accuracy. This collaborative work brought together Google DeepMind\u2019s ML knowledge and Google Research\u2019s error correction expertise to accelerate progress on building a reliable quantum computer. In tests, it made 6% fewer errors than tensor network methods and 30% fewer errors than correlated matching.\nThen in December, the Google Quantum AI team, part of Google Research, announced\nWillow\n, our latest quantum chip which can perform in under five minutes a benchmark computation that would take one of today\u2019s fastest supercomputers 10 septillion years. Willow can reduce errors exponentially as it scales up using more qubits. In fact, it used our quantum error correction to cut the error rate in half, solving a 30+ year challenge known in the field as \u201cbelow threshold.\u201d This leap forward won the\nPhysics Breakthrough of the Year\naward.\nWillow has state-of-the-art performance across a number of metrics.\nUncovering new solutions: progress in science, biology and mathematics\nWe continued to push the envelope on accelerating scientific progress with AI-based approaches, releasing a series of tools and papers this year that showed just how useful and powerful a tool AI is for advancing science and mathematics. We're sharing a few highlights.\nIn January, we introduced\nAlphaGeometry\n, an AI system engineered to solve complex geometry problems. Our updated version, AlphaGeometry 2, and AlphaProof, a reinforcement-learning-based system for formal math reasoning,\nachieved the same level as a silver medalist\nin July 2024\u2019s\nInternational Mathematical Olympiad\n.\nAlphaGeometry 2 solved Problem 4 in July 2024\u2019s International Mathematical Olympiad within 19 seconds after receiving its formalization. Problem 4 asked to prove the sum of \u2220KIL and \u2220XPY equals 180\u00b0.\nIn collaboration with Isomorphic Labs, we introduced\nAlphaFold 3\n, our latest model which predicts the structure and interactions of all of life\u2019s molecules. By accurately predicting the structure of proteins, DNA, RNA, ligands and more, and how they interact, we hope it will transform our understanding of the biological world and drug discovery.\nAlphaFold 3\u2019s capabilities come from its next-generation architecture and training that now covers all of life\u2019s molecules.\nWe made several key developments in protein-shaping. We announced\nAlphaProteo\n, an AI system for designing novel, high-strength protein binders. AlphaProteo can lead to the discovery of new drugs, the development of biosensors and improve our understanding of biological processes.\nAlphaProteo can generate new protein binders for diverse target proteins.\nIn collaboration with Harvard\u2019s Lichtman Lab and others, we\nproduced\na nano-scale mapping of a piece of the human brain at a level of detail never previously achieved, and made it publicly available for researchers to build on. This follows\na decade of working to advance our understanding of connectomics\n, with earlier work on fly brain and mouse brain connectomics now giving way to the larger scale and more complex human brain connectomics.\nIn the deepest layer of the cortex, clusters of cells tend to occur in mirror-image orientation to one another, as shown in this brain mapping project.\nThen in late November, as part of a\nbroader effort\nto expand and deepen public dialogue around science and AI, we co-hosted\nthe AI for Science Forum\nwith the Royal Society, which convened\nscientists\n, researchers, governmental leaders and executives to discuss\nkey topics\nlike cracking the protein structure prediction challenge, mapping the human brain and saving lives through accurate forecasting and spotting wildfires. We hosted a Q&A with the four Nobel Laureates in attendance at the forum, Sir Paul Nurse, Jennifer Doudna, Demis Hassabis and John Jumper, which is available to listen to via the Google DeepMind\npodcast\n.\nThis was also a landmark year for another reason: Demis Hassabis and John Jumper, along with David Baker, were awarded the\n2024 Nobel Prize\u00ae in Chemistry\nfor their work on AlphaFold 2. As the Nobel committee\nrecognized\n, their work:\n\"[H]as opened up completely new possibilities to design proteins that have never been seen before, and we now have access to predicted structures of all 200 million known proteins. These are truly great achievements.\"\nIt was also exciting to see the\n2024 Nobel Prize\u00ae in Physics\nawarded to recently retired long-time Googler Geoffrey Hinton (along with John Hopfield), \"for foundational discoveries and inventions that enable machine learning with artificial neural networks.\u201d\nThe Nobels followed additional recognitions for Google including the\nNeurIPS 2024 Test of Time Paper Awards\nfor\nSequence to Sequence Learning with Neural Networks\nand\nGenerative Adversarial Nets\n, and the\nBeale\u2014Orchard-Hays Prize\n, which was awarded to a collaborative team of educators and Google professionals for groundbreaking work on\nPrimal-Dual Linear Programming (PDLP)\n. (PDLP, now part of\nGoogle OR Tools\n, helps solve large-scale linear programming problems with real-world applications from\ndata center network traffic engineering\nto\ncontainer shipping optimization\n.)\nAI for the benefit of humanity\nThis year, we made a number of product advances and published research that showed how AI can benefit people directly and immediately, ranging from preventative and diagnostic medicine to disaster readiness and recovery to learning.\nIn healthcare, AI holds the promise of democratizing quality of care in key areas, such as early\ndetection of cardiovascular disease\n. Our\nresearch\ndemonstrated how using a simple fingertip device that measures variations in blood flow, combined with basic metadata, can predict heart health risks. We built on previous AI-enabled diagnostic research for tuberculosis,\ndemonstrating\nhow AI models can be used for accurate TB screenings in populations with high rates of TB and HIV. This is important to reducing the prevalence of TB (more than\n10 million people\nfall ill with it each year), as roughly 40% of people with TB go\nundiagnosed\n.\nOn the MedQA (USMLE-style) benchmark, Med-Gemini attains a new state-of-the-art score, surpassing our prior best (\nMed-PaLM 2\n) by a significant margin of 4.6%.\nOur Gemini model is a powerful tool for professionals generally, but our teams are also working to create fine-tuned models for other domains. For example, we introduced\nMed-Gemini\n, a new family of next-generation models that combine training on de-identified medical data with Gemini\u2019s reasoning, multimodal and long-context abilities. On the MedQA US Medical Licensing Exam (USMLE)-style question benchmark, Med-Gemini\nachieves\na state-of-the-art performance of 91.1% accuracy, surpassing our prior best of Med-PaLM 2 by 4.6% (shown above).\nWe are exploring how machine learning can help medical fields struggling with access to imaging expertise, such as\nradiology, dermatology and pathology\n. In the past year, we\nreleased\ntwo research tools,\nDerm Foundation\nand\nPath Foundation\n, that can help develop models for diagnostic tasks, image indexing and curation and biomarker discovery and validation. We collaborated with physicians at Stanford Medicine on an open-access, inclusive\nSkin Condition Image Network (SCIN) dataset\n. And we unveiled\nCT Foundation\n, a medical imaging embedding tool used for rapidly training models for research.\nWith regard to learning, we explored new generative AI tools to support educators and learners. We introduced\nLearnLM\n, our new family of models fine-tuned for learning and used it to enhance learning experiences in products like Search, YouTube and Gemini; a recent report showed LearnLM\noutperformed\nother leading AI models. We also\nmade it available\nto developers as an experimental model in AI Studio. Our new conversational learning companion,\nLearnAbout\n, uses AI to help you dive deeper into any topic you\u2019re curious about, while\nIlluminate\nlets you turn content into engaging AI-generated audio discussions.\nIn the fields of disaster forecasting and preparedness, we announced several breakthroughs. We introduced\nGenCast\n, our new high-resolution AI ensemble model, which improves day-to-day weather and extreme events forecasting across all possible weather trajectories. We also introduced our\nNeuralGCM model\n, able to simulate over 70,000 days of the atmosphere in the time it would take a physics-based model to simulate only 19 days. And\nGraphCast\nwon the\n2024 MacRobert Award\nfor engineering innovation.\nThis selection of GraphCast\u2019s predictions rolling across 10 days shows specific humidity at 700 hectopascals (about 3 kilometers above surface), surface temperature and surface wind speed.\nWe also improved our\nflood forecasting model\nto predict flooding seven days in advance (up from five) and expanded our riverine flood forecasting coverage to 100 countries and 700 million people. This marks a significant milestone in a multi-year initiative that Google Research embarked on in 2018.\nOur flood forecasting model is now available in over 100 countries (left), and we now have \u201cvirtual gauges\u201d for experts and researchers in more than 150 countries, including countries where physical gauges are not available.\nAI can also help with wildfire detection and mitigation, which is especially top of mind given the devastation in California. Our\nWildfire Boundary Maps capabilities\nare now available in 22 countries. Alongside leading wildfire authorities, Google Research also created\nFireSat\n, a constellation of satellites that can detect and track wildfires as small as a classroom (roughly 5x5 meters) within 20 minutes.\nAnd we continued building on our commitment to making more information more accessible to more people,\nexpanding Google Translate\nwith 110 new languages, including Cantonese, Papua New Guinea\u2019s Tok Pisin, N\u2019Ko from West Africa and Manx from the Isle of Man. Google Translate \u2014 which now supports over 240 languages \u2014 can help people overcome barriers to information, knowledge and opportunity.\nThese new languages in Google Translate represent more than 614 million speakers, opening up translations for around 8% of the world\u2019s population.\nHelping set the standard in responsible AI\nWe furthered our industry-leading research in AI safety, developing new tools and techniques and integrating these advances into our latest models. We\u2019re committed to working with others to address risks.\nWe continued\nresearching\nmisuse, conducting a study that found the two most common types of misuse were deep fakes and jailbreaks. In May, we introduced\nThe Frontier Safety Framework\n, which established protocols for identifying the emerging capabilities of our most advanced AI models, and launched our\nAI Responsibility Lifecycle framework\nto the public. In October, we\nexpanded\nour\nResponsible GenAI Toolkit\nto work with any LLM, giving developers more tools to build AI responsibly.\nAnd, among our other efforts, we released a paper this year on\nThe Ethics of Advanced AI Assistants\nthat examined and mapped the new technical and moral landscape of a future populated by AI assistants, and characterized the opportunities and risks society might face.\nWe expanded\nSynthID\u2019s capabilities\nto watermarking AI-generated text in the\nGemini app and web experience\n, and video in\nVeo\n. To help increase overall transparency online, not just with content created by Google gen AI tools, we also\njoined\nthe Coalition for Content Provenance and Authenticity (C2PA) as a steering committee member and\ncollaborated\non a new, more secure version of the technical standard, Content Credentials.\nWhen there\u2019s a range of different tokens to choose from, SynthID can adjust the probability score of each predicted token, in cases where it won\u2019t compromise the quality, accuracy and creativity of the output.\nBeyond LLMs, we shared our approach to\nbiosecurity\nfor\nAlphaFold 3\n. We also worked with industry partners to launch the\nCoalition for Secure AI\n(CoSAI), and we participated in the\nAI Seoul Summit\n, as a way of building and contributing to an international consensus and a common, coordinated approach to governance.\nAs we develop new technologies like AI agents, we\u2019ll continue to encounter new questions around safety, security and privacy. Guided by our\nAI Principles\n, we are\ndeliberately taking\nan exploratory and gradual approach to development, conducting research on multiple prototypes, iteratively implementing safety training, working with trusted testers and external experts and performing extensive risk assessments and safety and assurance evaluations.\nLooking ahead to 2025\n2024 was a productive year, and a very exciting time for groundbreaking new products and research in AI. We made a great deal of progress and we\u2019re even more excited about the year ahead.\nAs we continue to produce groundbreaking AI research in the fields of products, science, health, creativity and more, it becomes increasingly important to think deeply about how and when it should be deployed. By continuing to prioritize responsible AI practices and fostering collaboration, we\u2019ll play an important role in building a future where AI benefits humanity.\nPOSTED IN:\nRelated stories\nGoogle Workspace\nHow AI made Meet\u2019s language translation possible\nBy\nMolly McHugh-Johnson\nSep 11, 2025\nAI\nThe latest AI news we announced in August\nBy\nKeyword Team\nSep 10, 2025\nLearning & Education\nAI Quests: Bringing AI literacy to the classroom\nBy\nRonit Levavi Morad\nSep 09, 2025\nAI\nThe latest Google AI literacy resources all in one place\nBy\nJennie Magiera\nResearch\nGoogle Quantum AI has been selected for the DARPA Quantum Benchmarking Initiative.\nBy\nHartmut Neven\nSep 09, 2025\nSearch\nGoogle Doodles show how AI Mode can help you learn.\nSep 08, 2025\n.\nJump to position 1\nJump to position 2\nJump to position 3\nJump to position 4\nJump to position 5\nJump to position 6\nLet\u2019s stay in touch. Get the latest news from Google in your inbox.\nSubscribe\nNo thanks",
        "image_urls": [
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Demis_headshot.max-244x184.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2024_Headshot_for_James_Manyika.max-244x184.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Jeff_Dean_Photo_1.max-244x184.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FACTS_system_instruction2x.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/EOY-2024-Figure-250114-r01.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Fig_1.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Social_03.width-100.format-webp_GDqJDqv.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AF_hero_2_crop.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Med-Gemini-2b-MedQA.width-100.format-webp.webp",
            "score": 0
          },
          {
            "url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Flood-Forecasting.width-100.format-webp.webp",
            "score": 0
          }
        ],
        "title": "Year in review: Google's biggest AI advancements of 2024"
      },
      {
        "url": "https://www.forbes.com/sites/bernardmarr/2024/12/16/6-game-changing-ai-breakthroughs-that-defined-2024/",
        "raw_content": "6 Game-Changing AI Breakthroughs That Defined 2024\nInnovation\nEnterprise Tech\n6 Game-Changing AI Breakthroughs That Defined 2024\nBy\nBernard Marr\n,\nContributor.\nFollow Author\nDec 16, 2024, 02:09am EST\nShare\nSave\nComment\nFrom Apple\u2019s entry into generative AI to unprecedented achievements in robotics and art, 2024 marked a transformative year in artificial intelligence innovation.\nAdobe Stock\nWithout a doubt, 2024 will go down as a year in which we saw much groundbreaking progress and many giant leaps forward in the development of artificial intelligence.\nWith companies racing to build AI features and functionalities into products, we\u2019re increasingly getting used to automation in the workplace, and AI is becoming integrated across all aspects of our everyday lives.\nSo, with the AI revolution well underway, here\u2019s my overview of the year\u2019s AI highlights \u2013 including the game-changing breakthroughs and discoveries setting the stage for an even more momentous 2025.\nThe Continuing Evolution And Advancement Of Generative AI Chatbots\nWhen ChatGPT emerged two years ago (was that all it was?), it was clear that what we were seeing was just the beginning. Since then, we\u2019ve seen rival chatbots emerging from established tech leaders, including Google and Meta, fellow AI startups such as Anthropic, and many\nopen-source\ncollaborations and projects. New features like memory and multimodal capabilities have broken new ground in terms of what we expect from AI. And the most exciting thing is we\u2019re still clearly only just getting started.\nApple Enters The Generative AI Arena With Apple Intelligence\nIf there\u2019s one thing that Apple does really well, it\u2019s taking a great idea and launching it into the mainstream. This is why the\n2024 arrival of Apple Intelligence\ncould well go down as a watershed moment in consumer adoption of AI. By integrating OpenAI-powered generative language and graphics functionality across its product ecosystem, it created a typically refined, Apple-shaped gateway into the world of day-to-day AI for millions of non-techy people.\nMORE FROM\nFORBES ADVISOR\nBest High-Yield Savings Accounts Of 2024\nBy\nKevin Payne\nContributor\nBest 5% Interest Savings Accounts of 2024\nBy\nCassidy Horton\nContributor\nHead Of Google AI Wins The Nobel Prize For Chemistry\nDemis Hassabis has said that the most important effect of the AI revolution is that it will act as an accelerator in many other fields of science. In 2024, he demonstrated this when he was made\njoint winner\nof the Nobel Prize for chemistry, thanks to the AI model AlphaFold 2 being integral to the task of creating new proteins. By predicting the complex amino acid sequences needed, it is thought that this breakthrough will lead to new developments in medicines, vaccines and material sciences.\nThe EU AI Act \u2013 AI Legislation Begins To Take Shape\nIn August 2024, the EU\u2019s Artificial Intelligence Act\ncame into force\n, marking a significant step by an international regulator to implement a framework and safeguards around AI. Rather than conferring rights on individuals (as is the case with the union\u2019s data protection regulation, GDPR), it aims to impose controls on providers of AI services. This is done by categorizing applications according to their potential for causing harm, regulating some while outright banning those classed as \u201cunacceptable.\u201d This highest-risk category includes applications that enable facial recognition technology to be used in public places or for social scoring.\nOptimus Breaks New Ground For Humanoid Robots\nTesla\ndemonstrated\nthe latest iteration of its humanoid robot, codenamed Optimus after the Transformers character, in front of a stunned audience at its We Robot event in October. Despite controversy over how much of its operation was automated and how much was simply remote-controlled via telepresence, experts agreed that it showed impressive progress toward the development of bipedal robots that could eventually assist with many tasks in homes and industry.\nPainting Created By AI Robot Sells For $1 Million\nThe last couple of years have seen an explosion in AI art \u2013 but perhaps the most mind-blowing milestone was passed when Ai-Da became the first humanoid robot to sell a piece of artwork at auction.\nThe painting, titled AI God, was estimated to sell for between $120,000 and $180,000, but\nbidding\nsoared to a final $1,084,000 at the historic Sotheby's auction house in London in February this year.\nAs we reflect on 2024's remarkable AI achievements, it's clear that we're witnessing not just technological advancement but a fundamental transformation in how AI integrates into our lives and work. As we look toward 2025, these developments suggest we're entering an era where AI's impact will continue to expand and evolve in ways that promise to reshape every aspect of human endeavor.\nEditorial Standards\nReprints & Permissions",
        "image_urls": [
          {
            "url": "https://specials-images.forbesimg.com/imageserve/675fd1ce122216c83e2c53fc/From-Apple-s-entry-into-generative-AI-to-unprecedented-achievements-in-robotics-and/960x0.jpg?fit=scale",
            "score": 0
          },
          {
            "url": "https://thumbor.forbes.com/thumbor/fit-in/1290x/https://www.forbes.com/advisor/wp-content/uploads/2020/12/getty_1-best-online-savings-thumbnail_101920pm.jpg",
            "score": 0
          },
          {
            "url": "https://thumbor.forbes.com/thumbor/fit-in/900x510/https://www.forbes.com/advisor/wp-content/uploads/2023/09/Saving-Rates-2.jpg",
            "score": 0
          }
        ],
        "title": "6 Game-Changing AI Breakthroughs That Defined 2024"
      }
    ]
  },
  "duckduckgo_Climate Research": {
    "success": true,
    "urls_found": 3,
    "urls_scraped": 2,
    "retrieval_time": 0.9542460441589355,
    "scraping_time": 0.7523999214172363,
    "total_time": 1.7066459655761719,
    "content_analysis": {
      "successful_scrapes": 2,
      "failed_scrapes": 0,
      "total_content_length": 186377,
      "total_images": 4,
      "relevance_score": 100.0,
      "content_samples": [
        {
          "url": "https://en.wikipedia.org/wiki/Media_coverage_of_climate_change",
          "title": "Media coverage of climate change - Wikipedia",
          "content_length": 78381,
          "keyword_matches": 5,
          "sample_content": "Media coverage of climate change - Wikipedia\nJump to content\nFrom Wikipedia, the free encyclopedia\nGlobal warming was the cover story of this 2007 issue of the liberal-leaning feminist\nMs. magazine\n.\n..."
        },
        {
          "url": "https://www.physicsforums.com/threads/new-climate-science-update-latest-findings-since-2006-report.358328/",
          "title": "New Climate Science Update: Latest Findings Since 2006 Report \u2022 Physics Forums",
          "content_length": 107996,
          "keyword_matches": 5,
          "sample_content": "New Climate Science Update: Latest Findings Since 2006 Report \u2022 Physics Forums\nChemistry\nBiology and Medical\nEarth Sciences\nComputer Science\nComputing and Technology\nDIY Projects\nMenu\nLog in\nRegister\n..."
        }
      ],
      "titles": [
        "Media coverage of climate change - Wikipedia",
        "New Climate Science Update: Latest Findings Since 2006 Report \u2022 Physics Forums"
      ]
    },
    "search_results": [
      {
        "title": "Media coverage of climate change - Wikipedia",
        "href": "https://en.wikipedia.org/wiki/Media_coverage_of_climate_change",
        "body": "Climate change communication research shows that coverage has grown and become more accurate. ... researchers and journalists believe that media ..."
      },
      {
        "title": "NASA researchers retract Nature paper on climate change and",
        "href": "https://retractionwatch.com/2022/03/03/nasa-researchers-retract-nature-paper-on-climate-change-and-evapotranspiration/",
        "body": "... Nature paper on how climate change ... 8 thoughts on \u201c NASA researchers retract Nature paper on climate change and evapotranspiration \u201d"
      },
      {
        "title": "New Climate Science Update: Latest Findings Since 2006 Report",
        "href": "https://www.physicsforums.com/threads/new-climate-science-update-latest-findings-since-2006-report.358328/",
        "body": "The latest findings indicate a more sensitive climate system than previously understood, with global temperatures and sea levels expected to rise ..."
      }
    ],
    "scraped_results": [
      {
        "url": "https://en.wikipedia.org/wiki/Media_coverage_of_climate_change",
        "raw_content": "Media coverage of climate change - Wikipedia\nJump to content\nFrom Wikipedia, the free encyclopedia\nGlobal warming was the cover story of this 2007 issue of the liberal-leaning feminist\nMs. magazine\n.\nMedia coverage of climate change\nhas had effects on\npublic opinion on climate change\n, as it conveys the\nscientific consensus on climate change\nthat the global\ntemperature\nhas increased in recent decades and that the trend is caused by human-induced emissions of\ngreenhouse gases\n.\n[\n1\n]\nClimate change communication\nresearch shows that coverage has grown and become more accurate.\n[\n2\n]\n:\u200a11\nSome researchers and journalists believe that media coverage of\npolitics of climate change\nis adequate and fair, while a few feel that it is biased.\n[\n3\n]\n[\n4\n]\n[\n5\n]\n[\n6\n]\nHistory\n[\nedit\n]\nThis 1902 article attributes to Swedish Nobel laureate (chemistry)\nSvante Arrhenius\na theory that coal combustion could eventually lead to\nhuman extinction\n.\n[\n7\n]\nThis 1912 article succinctly describes the greenhouse effect, focusing on how burning coal creates carbon dioxide that causes climate change.\n[\n8\n]\nThe theory that increases in\ngreenhouse gases\nwould lead to an increase in temperature was\nfirst proposed\nby the Swedish chemist\nSvante Arrhenius\nin 1896, but climate change did not arise as a\npolitical issue\nuntil the 1990s. It took many years for this particular issue to attract any type of popular attention.\n[\n9\n]\nIn the\nUnited States\n, the mass media devoted little coverage to global warming until the\ndrought\nof 1988, and\nJames E. Hansen\n's testimony to the\nSenate\n, which explicitly attributed \"the abnormally hot weather plaguing our nation\" to global warming. Global warming in the U.S. gained more attention after the release of the 2006 documentary\nAn Inconvenient Truth\n, featuring\nAl Gore\n.\n[\n10\n]\nThe British press also changed its coverage at the end of 1988, following a speech by\nMargaret Thatcher\nto the\nRoyal Society\nadvocating action against\nhuman-induced climate change\n.\n[\n11\n]\nAccording to Anabela Carvalho, an academic analyst, Thatcher's \"appropriation\" of the risks of climate change to promote\nnuclear power\n, in the context of the dismantling of the coal industry following the\n1984\u20131985 miners' strike\nwas one reason for the change in public discourse. At the same time environmental organizations and the political opposition were demanding \"solutions that contrasted with the government's\".\n[\n12\n]\nIn 2007, the\nBBC\nannounced the cancellation of a planned television special\nPlanet Relief\n, which would have highlighted the global warming issue and included a mass electrical switch-off.\n[\n13\n]\nThe editor of BBC's\nNewsnight\ncurrent affairs show said: \"It is absolutely not the BBC's job to save the planet. I think there are a lot of people who think that, but it must be stopped.\"\n[\n14\n]\nAuthor\nMark Lynas\nsaid \"The only reason why this became an issue is that there is a small but vociferous group of extreme right-wing climate 'sceptics' lobbying against taking action, so the BBC is behaving like a coward and refusing to take a more consistent stance.\"\n[\n15\n]\nA peak in media coverage occurred in early 2007, driven by the\nIPCC Fourth Assessment Report\nand\nAl Gore\n's documentary\nAn Inconvenient Truth\n.\n[\n16\n]\nA subsequent peak in late 2009, which was 50% higher,\n[\n17\n]\nmay have been driven by a combination of the November 2009\nClimatic Research Unit email controversy\nand December\n2009 United Nations Climate Change Conference\n.\n[\n16\n]\n[\n18\n]\nThe Media and Climate Change Observatory team at the University of Colorado Boulder found that 2017 \"saw media attention to climate change and global warming ebb and flow\" with June seeing the maximum global media coverage on both subjects. This rise is \"largely attributed to news surrounding United States (US) President Donald J. Trump's withdrawal from the 2015 United Nations (UN)\nParis Climate Agreement\n, with continuing media attention paid to the emergent US isolation following through the\nG7 summit\na few weeks later.\"\n[\n19\n]\nMedia coverage of climate change during the Trump Administration remained prominent as most news outlets placed heavy emphasis on Trump-related stories rather than climate-related events.\n[\n19\n]\nThis shift in media focus is referred to as \"Trump Dump\" and was shown to peak in times when the President was most active on\nTwitter\n. Just in the year 2017, the word \"Trump\" was mentioned 19,187 times in stories covered by five of the nation's biggest press accounts, with \"climate\" being the second most frequent word.\n[\n19\n]\nIn a 2020 article, Mark Kaufman of\nMashable\nnoted that the\nEnglish Wikipedia\n's article on climate change has \"hundreds of credible citations\" which \"counters the stereotype that publicly-policed, collaboratively-edited Wikipedia pages are inherently unreliable\".\n[\n20\n]\nCommon distortions\n[\nedit\n]\nFactual\n[\nedit\n]\nScientists and media scholars who express frustrations with inadequate science reporting argue that it can lead to at least three basic distortions. First, journalists distort reality by making scientific errors. Second, they distort by concentrating on human-interest stories rather than scientific content. And third, journalists distort by rigid adherence to the construct of balanced coverage.\n[\n21\n]\n[\n22\n]\n[\n23\n]\n[\n24\n]\n[\n25\n]\n[\n26\n]\n[\nexcessive citations\n]\nBord, O'Connor, & Fisher (1998) argue that responsible citizenry necessitates a concrete knowledge of causes and that until, for example, the public understands what causes climate change it cannot be expected to take voluntary action to mitigate its effects.\n[\n27\n]\nIn 2022 the\nIPCC reported\nthat \"Accurate transference of the climate science has been undermined significantly by climate change countermovements, in both legacy and new/social media environments through\nmisinformation\n.\"\n[\n2\n]\n:\u200a11\nA study published in\nPLOS One\nin 2024 found that even a single repetition of a claim was sufficient to increase the\nperceived\ntruth of both climate science-aligned claims and climate change skeptic/denial claims\u2014\"highlighting the insidious effect of repetition\".\n[\n28\n]\nThis effect was found even among climate science endorsers.\n[\n28\n]\nNarrative\n[\nedit\n]\nAccording to Shoemaker and Reese, controversy is one of the main variables affecting story choice among news editors, along with human interest, prominence, timeliness, celebrity, and proximity. Coverage of climate change has been accused of falling victim to the journalistic norm of \"personalization\".\n[\n29\n]\nW.L Bennet defines this trait as: \"the tendency to downplay the big social, economic, or political picture in favor of human trials, tragedies and triumphs\".\n[\n30\n]\nThe culture of\npolitical journalism\nhas long used the notion of balanced coverage in covering the controversy. In this construct, it is permissible to air a highly\npartisan\nopinion, provided this view is accompanied by a competing opinion. But recently scientists and scholars have challenged the legitimacy of this journalistic core value with regard to matters of great importance on which the overwhelming majority of the scientific community has reached a well-substantiated consensus view.\n[\ncitation needed\n]\nIn a survey of 636 articles from four top United States newspapers between 1988 and 2002, two scholars found that most articles gave as much time to the small group of\nclimate change deniers\nas to the scientific consensus view.\n[\n21\n]\nGiven real consensus among climatologists over\nglobal warming\n, many scientists find the media's desire to portray the topic as a scientific controversy to be a gross distortion. As\nStephen Schneider\nput it:\n[\n24\n]\n\"a mainstream, well-established consensus may be 'balanced' against the opposing views of a few extremists, and to the uninformed, each position seems equally credible.\"\nScience journalism concerns itself with gathering and evaluating various types of relevant evidence and rigorously checking sources and facts. Boyce Rensberger, the director of the Massachusetts Institute of Technology (MIT) Knight Center for Science Journalism, said, \"balanced coverage of science does not mean giving equal weight to both sides of an argument. It means apportioning weight according to the balance of evidence.\"\n[\n31\n]\nThe claims of scientists also get distorted by the media by a tendency to seek out extreme views, which can result in portrayal of risks well beyond the claims actually being made by scientists.\n[\n32\n]\nJournalists tend to overemphasize the most extreme outcomes from a range of possibilities reported in scientific articles. A study that tracked press reports about a climate change article in the journal\nNature\nfound that \"results and conclusions of the study were widely misrepresented, especially in the news media, to make the consequences seem more catastrophic and the timescale shorter\".\n[\n33\n]\nA 2020 study in\nPNAS\nfound that newspapers tended to give greater coverage of press releases that opposed action on climate change than those that supported action. The study attributes it to\nfalse balance\n.\n[\n34\n]\nResearch that was done by Todd Newman, Erik Nisbet, and Matthew Nisbet shows that people's partisan preference is an indicator as to which media outlet they will most likely consume. Most media outlets often align with a particular partisan ideology. This causes people to resort to selective exposure which influences views on world issues such as climate change beliefs.\n[\n3\n]\nSince 1990 climate scientists have communicated urgent warnings while simultaneously experiencing the media converting their statements into sensational entertainment.\n[\n35\n]\nAlarmism\n[\nedit\n]\nTo achieve climate action\n[\nedit\n]\nSee also:\nClimate apocalypse\nAlarmism\nis using inflated language, including an urgent tone and imagery of doom.\n[\ncitation needed\n]\nIn a report produced for the\nInstitute for Public Policy Research\nGill Ereaut and Nat Segnit suggested that alarmist language is frequently used in relation to environmental matters by newspapers, popular magazines and in campaign literature put out by the government and environment groups.\n[\n36\n]\nIt is claimed that when applied to climate change, alarmist language can create a greater sense of urgency.\n[\n37\n]\nIt has been argued that using sensational and alarming techniques, often evoke \"denial, paralysis, or apathy\" rather than motivating individuals to action and do not motivate people to become engaged with the issue of climate change.\n[\n38\n]\n[\n39\n]\nIn the context of\nclimate refugees\n\u2014the potential for climate change to\ndisplace people\n\u2014it has been reported that \"alarmist hyperbole\" is frequently employed by\nprivate military contractors\nand\nthink tanks\n.\n[\n40\n]\nTo challenge the science related to global warming\n[\nedit\n]\nThe term\nalarmist\nhas been used as a\npejorative\nby critics of mainstream climate science to describe those that endorse the scientific consensus without necessarily being unreasonable.\n[\n41\n]\nMIT\nmeteorologist\nKerry Emanuel\nwrote that labeling someone as an \"alarmist\" is \"a particularly infantile smear considering what is at stake\". He continued that using this \"inflammatory terminology has a distinctly\nOrwellian\nflavor.\"\n[\n42\n]\nSome media reports have used alarmist tactics to challenge the science related to global warming by comparing it with a purported episode of\nglobal cooling\n. In the 1970s, global cooling, a claim with limited scientific support (even during the height of a media frenzy over\nglobal cooling\n, \"the possibility of anthropogenic warming dominated the peer-reviewed literature\") was widely reported in the press.\n[\n43\n]\nSeveral media pieces have claimed that since the even-at-the-time-poorly-supported theory of\nglobal cooling\nwas shown to be false, that the well-supported theory of global warming can also be dismissed. For example, an article in\nThe Hindu\nby Kapista and Bashkirtsev wrote: \"Who remembers today, they query, that in the 1970s, when global temperatures began to dip, many warned that we faced a new ice age? An editorial in The Time magazine on June 24, 1974, quoted concerned scientists as voicing alarm over the atmosphere 'growing gradually cooler for the past three decades', 'the unexpected persistence and thickness of pack ice in the waters around Iceland,' and other harbingers of an ice age that could prove 'catastrophic.' Man was blamed for global cooling as he is blamed today for global warming\",\n[\n44\n]\nand the\nIrish Independent\npublished an article claiming that \"The widespread alarm over global warming is only the latest scare about the environment to come our way since the 1960s. Let's go through some of them. Almost exactly 30 years ago the world was in another panic about climate change. However, it wasn't the thought of global warming that concerned us. It was the fear of its opposite, global cooling. The doom-sayers were wrong in the past and it's entirely possible they're wrong this time as well.\"\n[\n45\n]\nNumerous other examples exist.\n[\n46\n]\n[\n47\n]\n[\n48\n]\nMedia, politics, and public discourse\n[\nedit\n]\nAs McCombs et al.'s 1972 study of the political function of mass media showed, media coverage of an issue can \"play an important part in shaping political reality\".\n[\n49\n]\nResearch into media coverage of climate change has demonstrated the significant role of the media in determining\nclimate policy\nformation.\n[\n50\n]\nThe media has considerable bearing on public opinion, and the way in which issues are reported, or framed, establishes a particular\ndiscourse\n.\n[\n51\n]\nMedia-policy interface\n[\nedit\n]\nThe relationship between media and politics is\nreflexive\n. As Feindt & Oels state, \"[media] discourse has material and power effects as well as being the effect of material practices and power relations\".\n[\n52\n]\nPublic support of climate change research ultimately decides whether or not funding for the research is made available to scientists and institutions.\nMedia coverage in the United States during the Bush Administration often emphasized and exaggerated scientific uncertainty over climate change, reflecting the interests of the political elite.\n[\n50\n]\nHall et al. suggest that government and corporate officials enjoy privileged access to the media, allowing their line to become the 'primary definer' of an issue.\n[\n53\n]\nMedia sources and their institutions very often have political leanings which determine their reporting on climate change, mirroring the views of a particular party.\n[\n54\n]\nHowever, media also has the capacity to challenge political norms and expose corrupt behaviour,\n[\n55\n]\nas demonstrated in 2007 when\nThe Guardian\nrevealed that\nAmerican Enterprise Institute\nreceived $10,000 from petrochemical giant\nExxonMobil\nto publish articles undermining the\nIPCC\n's 4th assessment report.\nEver-strengthening scientific consensus on climate change means that skepticism is becoming less prevalent in the media (although the email scandal in the build up to Copenhagen reinvigorated climate skepticism in the media\n[\n56\n]\n).\n[\nfailed verification\n]\nDiscourses of action\n[\nedit\n]\nThe polar bear has become a symbol for those attempting to generate support for addressing climate change.\nCommentators have argued that the climate change discourses constructed in the media have not been conducive to generating the political will for swift action. The polar bear has become a powerful discursive symbol in the fight against climate change. However, such images may create a perception of climate change impacts as geographically distant,\n[\n57\n]\nand MacNaghten argues that climate change needs to be framed as an issue 'closer to home'.\n[\n58\n]\nOn the other hand, Beck suggests that a major benefit of global media is that it brings distant issues within our consciousness.\n[\n59\n]\nFurthermore, media coverage of climate change (particularly in tabloid journalism but also more generally), is concentrated around extreme weather events and projections of catastrophe, creating \"a language of imminent terror\"\n[\n60\n]\nwhich some commentators argue has instilled policy-paralysis and inhibited response. Moser et al. suggest using solution-orientated frames will help inspire action to solve climate change.\n[\n61\n]\nThe predominance of catastrophe frames over solution frames\n[\n62\n]\nmay help explain the apparent\nvalue-action gap\nwith climate change; the current discursive setting has generated concern over climate change but not inspired action.\nBreaking the prevailing notions in society requires discourse that is traditionally appropriate and approachable to common people. For example, Bill McKibben, an environmental activist, provides one approach to inspiring action: a war-like mobilization, where climate change is the enemy. This approach could resonate with working Americans who normally find themselves occupied with other news headlines.\n[\n63\n]\nKester & Sovacool found that the usage of military termes in climate policy is dangerous and can lead to unintended consequences.\n[\n64\n]\nBlock, Li, G\u00e4rtner & Lenzen found thar real wars hamper climate change mitigation by several ways, and one of them is reducing the time media devotes to climate.\n[\n65\n]\nCompared to what experts know about traditional media's and tabloid journalism's impacts on the formation of public perceptions of climate change and willingness to act, there is comparatively little knowledge of the impacts of social media, including message platforms like Twitter, on public attitudes toward climate change.\n[\n66\n]\nIn recent years, there has been an increase in the influence and role that\nsocial media\nplays in conveying opinions and knowledge through information sharing. There are several emerging studies that explore the connection between social media and the public's awareness of climate change. Anderson found that there is evidence that\nsocial media\ncan raise awareness of climate change issues, but warns that it can also lead to opinion-dominated ideologies and reinforcement.\n[\n67\n]\nAnother study examined datasets from\nTwitter\nto assess the ideas and attitudes that users of the application held toward climate change.\n[\n68\n]\nWilliams et al. found that users tend to be active in groups that share the same opinions, often at the extremes of the spectrum, resulting in less polarized opinions between the groups.\n[\n68\n]\nThese studies show that\nsocial media\ncan have both a negative and positive impact on the information sharing of issues related to climate change.\n[\n67\n]\n[\n68\n]\nYouth awareness and activism\n[\nedit\n]\nPublished in the journal\nChildhood\n, the article \"Children's protest in relation to the climate emergency: A qualitative study on a new form of resistance promoting political and social change\" considers how children have evolved into prominent actors to create a global impact on awareness of climate change. It highlights the work of children like\nGreta Thunberg\nand the significance of their resistance to the passivity of world leaders regarding climate change. It also discusses how individual resistance can directly be linked to collective resistance and that this then creates a more powerful impact, empowering young people to act more responsibly and take authority over the future. The article discusses the potential impact of youth to raise awareness while also inspiring action, and using social media platforms to share the message.\n[\n69\n]\nThreats against climate journalism\n[\nedit\n]\nThe Covering the Planet report, a global survey of more than 740 climate journalists from 102 countries by\nInternews\n\u2019\nEarth Journalism Network\n(EJN) and\nDeakin University\n, reported that 39% of surveyed journalists were \"sometimes or frequently threatened\" by their government or from companies or individuals involved in illegal operations that included logging and mining, while the same percentage had to self-censor the content they reported out of fear of repercussions. The report stated that 30% of journalists faced threats of legal action due to their reporting. 62% included statements from sources skeptical of anthropogenic climate change in order to \"balance\" their reports, some doing so to lower potential scrutiny.\n[\n70\n]\nCoverage by country\n[\nedit\n]\nResults of a survey in 31 countries of public opinion on the causes of climate change in 2021\n[\n71\n]\nAustralia\n[\nedit\n]\nSee also:\nClimate change in Australia\nAustralian news outlets\nhave been reported to present misleading claims and information.\n[\n72\n]\nOne article from\nThe Australian\nin 2009 claimed that climate change and global warming were fraudulent claims pushed by so-called \"warmaholics\".\n[\n73\n]\n[\nnon-primary source needed\n]\nMany other examples of claims that dismiss climate change have been posted by media outlets in Australia throughout the years following as well.\n[\n74\n]\n[\n75\n]\n[\n76\n]\nThe 2013 summer and heat wave colloquially known as \"\nAngry Summer\n\" attracted a great deal of media attention, although few outlets directly linked the unprecedented heat to climate change.\n[\n77\n]\nAs the world entered into 2020, global media coverage of climate change issues decreased and\nCOVID-19 coverage\nincreased. In Australia there was a 34% decrease in climate change articles published from March 2020.\n[\n78\n]\nA 2022 analysis found that\nSky News Australia\nwas a major source of\nclimate misinformation\nglobally.\n[\n79\n]\nAustralia has recently experienced some of the most intense\nbushfire seasons\nin its immediate history. This phenomenon has sparked extensive media coverage both nationally and internationally. Much of the media coverage of the\n2019 and 2020 Australian bushfire seasons\ndiscussed the different factors that lead to and increase the chances of extreme fire seasons.\n[\n80\n]\nA climate scientist,\nNerilie Abram\n, at\nAustralian National University\nexplained in an article for\nScientific American\n, that the four major conditions need to exist for wildfire and those include \"available fuel, dryness of that fuel, weather conditions that aid the rapid spread of fire and an ignition.\n[\n81\n]\nCanada\n[\nedit\n]\nThis section needs to be\nupdated\n.\nPlease help update this article to reflect recent events or newly available information.\n(\nMay 2019\n)\nFurther information:\nEnvironmental policy of the Harper government \u00a7\u00a0Media coverage of climate change\nDuring the Harper government (2006-2015), Canadian media, mostly notably the\nCBC\n, made little effort to balance the claims of global warming deniers with voices from science.\n[\n82\n]\nThe Canadian coverage appeared to be driven more by national and international political events rather than the changes to carbon emissions or various other ecological factors.\n[\n82\n]\nThe discourse was dominated by matters of government responsibility, policy-making, policy measures for mitigation, and ways to mitigate climate change; with the issue coverage by mass media outlets continuing to act as an important means of communicating environmental concerns to the general public, rather than introducing new ideas about the topic itself.\n[\n82\n]\nWithin various provincial and language media outlets, there are varying levels of articulation regarding scientific consensus and the focus on ecological dimensions of climate change.\n[\n82\n]\nWithin Quebec, specifically, these outlets are more likely to position climate change as an international issue, and to link climate change to social justice concerns in order to depict Quebec as a pro-environmental society.\n[\n82\n]\nAcross various nations, including Canada, there has been an increased effort in the use of celebrities in climate change coverage, which is able to gain audience attention, but in turn, it reinforces individualized rather than structural interpretations of climate change responsibility and solutions.\n[\n82\n]\nChina\n[\nedit\n]\nSee also:\nClimate change in China\nThis section is empty.\nYou can help by\nadding to it\n.\n(\nAugust 2021\n)\nSweden\n[\nedit\n]\nSee also:\nClimate change in Sweden\nJapan\n[\nedit\n]\nSee also:\nClimate change in Japan\nIn Japan, a study of newspaper coverage of climate change from January 1998 to July 2007 found coverage increased dramatically from January 2007.\n[\n83\n]\nIndia\n[\nedit\n]\nSee also:\nClimate change in India\nA 2010 study of four major, national circulation English-language newspapers in India examined \"the frames through which climate change is represented in India\", and found that \"The results strongly contrast with previous studies from developed countries; by framing climate change along a 'risk-responsibility divide', the Indian national press set up a strongly nationalistic position on climate change that divides the issue along both developmental and\npostcolonial\nlines.\"\n[\n84\n]\nOn the other hand, a qualitative analysis of some mainstream Indian newspapers (particularly opinion and editorial pieces) during the release of the IPCC 4th Assessment Report and during the Nobel Peace Prize win by Al Gore and the IPCC found that Indian media strongly pursue scientific certainty in their coverage of climate change. This is in contrast to the skepticism displayed by American newspapers at the time. Indian media highlights energy challenges, social progress, public accountability and looming disaster.\n[\n85\n]\nIreland\n[\nedit\n]\nIreland\nhas quite a low coverage of climate change in media. A survey created shows how the\nIrish Times\nhad only 0.84% of news coverage for\nclimate change\nin the space of 13 years. This percentage is low compared to the rest of Europe. For example- Coverage of climate change in Ireland 10.6 stories, while the rest of Europe lies within 58.4 stories.\n[\n86\n]\nNew Zealand\n[\nedit\n]\nThis section needs to be\nupdated\n.\nPlease help update this article to reflect recent events or newly available information.\n(\nNovember 2019\n)\nSee also:\nClimate change in New Zealand\nA six-month study in 1988 on climate change reporting in the media found that 80% of stories were no worse than slightly inaccurate. However, one story in six contained significant misreporting.\n[\n87\n]\nAl Gore's film\nAn Inconvenient Truth\nin conjunction with the\nStern Review\ngenerated an increase in media interest in 2006.\nThe popular media in New Zealand often give equal weight to those supporting\nanthropogenic climate change\nand those who deny it. This stance is out of step with the findings of the scientific community where the vast majority support the\nclimate change scenarios\n. A survey carried out in 2007 on climate change gave the following responses:\n[\n88\n]\nNot really a problem\n8%\nA problem for the future\n13%\nA problem now\n42%\nAn urgent and immediate problem\n35%\nDon't know\n2%\nTurkey\n[\nedit\n]\nSee also:\nGreenhouse gas emissions by Turkey\nand\nClimate change in Turkey\nA study of mainstream media coverage in the late 2010s said that it tended to cover the consequences of climate change rather than mitigation or adaptation.\n[\n89\n]\nUnited Kingdom\n[\nedit\n]\nSee also:\nClimate change in the United Kingdom \u00a7\u00a0Media coverage\nThe Guardian\nnewspaper is internationally respected for its coverage of\nclimate change\n.\n[\n90\n]\nIn the UK, statements by government officials have been influential in the public perception on climate change. In 1988, Prime Minister\nMargaret Thatcher\ngave one of the first speeches to draw public attention to climate change. This speech highlighted the assumption that industrialization had no impact on the global climate and contrasted it with the stark reality of an increasingly volatile climate. In another speech, Margaret Thatcher expressed that \"we have unwittingly begun a massive experiment with the system of the planet itself\".\n[\n91\n]\nThatcher's speeches on climate change contributed to a record-breaking number of votes for the\nGreen Party\nin the\n1989 European Parliament Election\n. These speeches sparked an increase in broader media coverage of climate change.\n[\n92\n]\nIn the early 2000s,\nDavid King\n, Chief Scientific Advisor to the UK, stated that the most difficult issue facing the UK was climate change and that its effects were worse than terrorism. David King established that reducing carbon emissions would not only benefit the environment but also the collective wellbeing of UK citizens. King's personal focus was climate change and he produced innovative thinking, tactics and negotiations for the media.\n[\n93\n]\nIn 1988 in United States, NASA scientist\nJames Hansen\nstated that climate change was anthropogenic, that is, man-made. This had a similar result to Thatcher's speeches, drawing public attention to the climate crisis and spurring increased media coverage of the issue. The US and UK are comparable in their coverage of climate change for this reason.\n[\n94\n]\nDespite evidence for anthropogenic climate change arising as early as the late 19th century, both countries lacked significant media coverage on climate change prior to 1988. However, the trajectory of media coverage in these countries varies significantly after this 1988 increase.\nFor a short period in 1988, the United States had slightly more coverage, but the two countries were quite similar. However, in the following years, the UK consistently produced more articles, and in 2003, it spiked, producing a significantly larger amount of articles. The year 2003 saw the UK and much of Europe experience the hottest summer to date.\n[\n95\n]\nTemperatures reached up to 38.5\u00a0\u00b0C, which is 101.3\u00a0\u00b0F, resulting in 2,000 deaths in the UK, and more across Europe. This significant event drew the attention of newspapers, therefore increasing the amount of articles produced. For example, in the year following the heatwave,\nThe Guardian\nreleased an article in March, 2004, warning about even more severe summers that would come. This article included a quote from Dr. Luterbacher, who stated, \"We don't know if it will get warmer every year, but the trend is certainly in that direction.\" The article also claimed that this extreme event was not due to natural causes, suggesting that human activity was responsible.\n[\n96\n]\nThis fear of worse summers on the way and growing understanding of the human causes continued to shows up in increased media coverage after 2003.\nIn 2001, the National Survey of Public Attitudes to Quality of Life survey found that the public ranked global warming 8th on their list of current concerns. The Office for National Statistics then constructed an additional poll asking the same question but asked about expectations for 20 years ahead. A majority reported that in 20 years time, congestion fumes and noises from traffic would be more concerning than the significant impacts of climate change.\n[\n92\n]\nAlong with heatwaves, other problems that arise from climate change tend to generate more media coverage. Specifically, the issue of flooding as a result from the changing climate draws attention, and therefore, causes media to report on the issue. In a six year span, between 2001 and 2007, the UK had over a hundred articles per newspaper covering the topic of flooding, showing a clear concern with extreme weather events.\n[\n94\n]\nHowever, although the UK tends to frame climate change as being the fault of humans more than the US, the newspapers often ignore the role that climate change plays in these extreme events. In the hundreds of articles about flooding in the UK between 2001 and 2007, climate change was only mentioned 55 times in any of them. The\nGuardian\nhad the most mentions of climate change and more consistently drew connections between climate change and issues such as flooding. However, the\nGuardian\nstill only mentioned climate change 17 times out of 197 stories about climate change.\n[\n94\n]\nTherefore, while extreme events and tangible effects such as floods or heatwaves do cause more media attention, the media does not always draw connections between these issues and climate change.\nMedia companies in the United Kingdom produce a diverse range of types of articles regarding climate change, evident when looking at\nThe Guardian\n,\nThe\nObserver\n,\nThe Daily Mail\n,\nMail on Sunday\n,\nSunday Telegraph\n,\nThe Times\nand\nSunday Times\n. One scholarly article categorized newspapers from presenting anthropogenic global warming is the only cause of climate change to anthropogenic global warming negligently contributes to climate change. In this study, it is clear that on average, these news sources have increased in scientific credibility.\n[\n97\n]\nIn 2006 Futerra published research to determine if feedback from the UK community on the topic of global warming was either positive or negative. The results were that only 25 percent of the climate change newspapers were positive. A huge media company that participated in the positive feedback was the\nFinancial Times\n, which contained the most coverage relating climate change, including a focus on climate change and business opportunities.\n[\ncitation needed\n]\nThe commuters of London, reaching to the amount of a million participants, on the date of October 25, 2007, t provided a free metro newspaper which contained an important article with the headline \"We're in the biggest race of our lives.\" which encompassed the details of the fourth report of the United Nations Environmental Programme's Global Environment Outlook (GEO). The contents of the GEO noted that the actions to address climate change were critically insufficient. A majority of UK citizens were not ready for a change in light of present facts of scientific uncertainty.\n[\n93\n]\nThe Sunday Telegraph\nspecifically has a history of producing anti-climate change articles and news. The media publication did a major publication of\nChristopher Monckton\n, who is well known for his denial of climate change. This stance is reflected in one of their articles:\n[\n97\n]\n[\n98\n]\n\"When this global warming madness passes, future generations will remove this derelict solar and wind infrastructure and return to the only reliable and economical electricity options\u2014coal, gas, hydro and nuclear.\" (The Sunday Telegraph, London, 2010, 'Officials & climate').\n[\n97\n]\nGeorge Monbiot\n, a weekly column writer for\nThe Guardian\n, says specifically in Britain that there is a prevalent discourse of unity and collaboration when it comes to environmental concerns in media outlets such as The Guardian, The Times, the Sun and the Independent. He also claims to have read \"utter nonsense\" in The Daily Mail or The Sunday Telegraph.\n[\n98\n]\nA specific case of the community's reaction to climate change can be seen in the YouthStrike4Climate movement, specifically\nUK Youth Climate Coalition\n(UKYCC) and the UK Student Climate Network (UKSCN). According to Bart Cammaerts, there has been an overall positive media representation of the climate movement from United Kingdom media outlets. It is significant that 60% of the\nDaily Mail'\ns articles written about the climate movement were in a negative tone, while the\nBBC\nhad over 70% written in a positive tone. There are a range of media outlets covering climate change, and they all have different opinions on this movement.\n[\n99\n]\nWhile there are diverse perspectives represented in print media, right-wing newspapers reach far more readers. For example, the right-leaning\nDaily Mail\nand\nThe Sun\neach circulated more than 1 million copies in 2019, while the left-wing equivalents,\nDaily Mirror\nand\nThe Guardian\nonly circulated 600,000 copies.\n[\n100\n]\nOver time, these right-wing newspapers have published fewer editorials opposing climate action. In 2011, the proportion of these editorials was 5:1 against climate change. In 2021, this ratio had dropped to 1:9. Additionally, articles critical of climate action have shifted away from outright denial of climate change. Instead, these editorials highlight the costs associated with climate action, as well as blame other countries for climate change.\n[\n101\n]\nIn the United Kingdom, the youth activism movement played a key role in the increased production of media coverage of climate change.global activist celebrity and media outlets began covering her more and more. From September 17, 2019, to October 3, 2019, 21% of all media coverage on specific people was about Greta Thunberg. This young climate activist's prevalence in the media continued to increase and thus so did the amount of media on the subject.\n[\n99\n]\nWith more attention to Greta Thunberg and other young women, there has arguably been increased misogyny regarding\nwomen in climate change\n. According to Bart Cammaerts, \"These disparaging discourses of belittlement also serve to deny children the right to have a voice on environmentalism and politics.\"\n[\n99\n]\nUnited States\n[\nedit\n]\nSee also:\nClimate change in the United States\nand\nPropaganda model \u00a7\u00a0Applications\nThe way the media report on climate change in\nEnglish-speaking\ncountries, especially in the United States, has been widely studied, while studies of reporting in other countries have been less expansive.\n[\n102\n]\n[\n103\n]\nA number of studies have shown that particularly in the United States and in the UK\ntabloid press\n, the media significantly understated the strength of\nscientific consensus on climate change\nestablished in\nIPCC\nAssessment Reports\nin 1995\nand\nin 2001\n.\nOne of the first critical studies of media coverage of climate change in the United States appeared in 1999. The author summarized her research:\n[\n6\n]\nFollowing a review of the decisive role of the media in American politics and of a few earlier studies of media bias, this paper examines media coverage of the greenhouse effect. It does so by comparing two pictures. The first picture emerges from reading all 100 greenhouse-related articles published over a five-month period (May\u2013September 1997) in\nThe Christian Science Monitor\n,\nNew York Times\n,\nThe San Francisco Chronicle\n,\nand\nThe Washington Post\n. The second picture emerges from the mainstream scientific literature. This comparison shows that media coverage of environmental issues suffers from both shallowness and pro-corporate bias.\nAccording to Peter J. Jacques et al., the mainstream news media of the United States is an example of the effectiveness of\nenvironmental skepticism\nas a tactic.\n[\n104\n]\nA 2005 study reviewed and analyzed the US\nmass-media\ncoverage of the environmental issue of\nclimate change\nfrom 1988 to 2004. The authors confirm that within the journalism industry there is great emphasis on eliminating the presence of\nmedia bias\n. In their study they found that \u2014 due to this practice of journalistic\nobjectivity\n\u2014 \"Over a 15-year period, a majority (52.7%) of prestige-press articles featured balanced accounts that gave 'roughly equal attention' to the views that humans were contributing to global warming and that exclusively natural fluctuations could explain the earth's temperature increase [...] US mass-media have misrepresented the top climate scientific perspective regarding anthropogenic climate change.\" As a result, they observed that it is unsurprising for the public to believe that the issue of global warming and the accompanying\nscientific evidence\nis still hotly debated.\n[\n62\n]\nA study of US newspapers and television news from 1995 to 2006 examined \"how and why US media have represented conflict and contentions, despite an emergent consensus view regarding anthropogenic climate science.\" The\nIPCC\nAssessment Reports\nin 1995\nand\nin 2001\nestablished an increasingly strong scientific consensus, yet the media continued to present the science as contentious. The study noted the influence of\nMichael Crichton\n's 2004 novel\nState of Fear\n, which \"empowered movements across scale, from individual perceptions to the perspectives of US federal powerbrokers regarding human contribution to climate change.\"\n[\n105\n]\nA 2010 study concluded that \"Mass media in the U.S. continue to suggest that scientific consensus estimates of global climate disruption, such as those from the Intergovernmental Panel on Climate Change (IPCC), are 'exaggerated' and overly pessimistic. By contrast, work on the Asymmetry of Scientific Challenge (ASC) suggests that such consensus assessments are likely to understate climate disruptions [...] new scientific findings were more than twenty times as likely to support the ASC perspective than the usual framing of the issue in the U.S. mass media. The findings indicate that supposed challenges to the scientific consensus on global warming need to be subjected to greater scrutiny, as well as showing that, if reporters wish to discuss \"both sides\" of the climate issue, the scientifically legitimate 'other side' is that, if anything, global climate disruption may prove to be significantly worse than has been suggested in scientific consensus estimates to date.\"\n[\n106\n]\nScientific consensus on climate change (left) versus attitudes of Fox News guests in 2013 (right)\n[\n107\n]\nThe most watched\nnews network\nin the United States,\nFox News\n, most of the time promotes climate misinformation and employs tactics that distract from the urgency of global climate change, according to a 2019 study by\nPublic Citizen\n. According to the study, 86% of Fox News segments that discussed the topic were \"dismissive of the climate crisis, cast its consequences in doubt or employed fear mongering when discussing climate solutions\". These segments presented global climate change as a political construct, rarely, if ever, discussing the threat posed by climate change or the vast body of scientific evidence for its existence. Consistent with such politicized framing, three messages were most commonly advanced in these segments: global climate change is part of a \"big government\" agenda of the\nDemocratic Party\n(34% of segments); an effective response to the climate crisis would destroy the economy and hurtle us back to the Stone Age (26% of segments); and, concern about the climate crisis is \"alarmists\", \"hysterical\", the shrill voice of a \"doomsday climate cult\", or the like (12% of segments). Such segments often featured \"experts\" who are not climate scientists at all or are personally connected to vested interests, such as the\nenergy industry\nand its network of\nlobbyists\nand\nthink tanks\n, for example, the\nHeartland Institute\n, funded by the\nExxonMobil\ncompany and the\nKoch foundation\n. The remaining segments (14%) were neutral on the subject or presented information without editorializing.\n[\n108\n]\nIt has been suggested that the association of climate change with the Arctic in popular media may undermine effective communication of the scientific realities of anthropogenic climate change. The close association of images of Arctic glaciers, ice, and fauna with climate change might harbor cultural connotations that contradict the fragility of the region. For example, in cultural-historical narratives, the Arctic was depicted as an unconquerable, foreboding environment for explorers; in climate change discourse, the same environment is sought to be understood as fragile and easily affected by humanity.\n[\n109\n]\nGallup's annual update on Americans' attitudes toward the environment shows a public that over the last two years (2008-2010) has become less worried about the threat of\nglobal warming\n, less convinced that its effects are already happening, and more likely to believe that scientist themselves are uncertain about its occurrence. In response to one key question, 48% of Americans now believe that the seriousness of global warming is generally exaggerated, up from 41% in 2009 and 31% in 1997, when Gallup first asked the question.\n[\n110\n]\nData from the Media Matters for America organization has shown that, despite 2015 being \"a year marked by more landmark actions to address climate change than ever before\", the combined climate coverage on the top broadcast networks was down by 5% from 2014.\n[\n111\n]\n[\n18\n]\nPresident\nDonald Trump\ndenies the threat of global warming publicly. As a result of the Trump Presidency, media coverage on climate change was expected to decline during his term as president.\n[\n112\n]\n[\nneeds update\n]\nGlobally, media coverage of global warming and climate change decreased in 2020.\n[\n78\n]\nIn the United States, however, newspaper coverage of climate change increased 29% between March 2020 and April 2020, these numbers are still 22% down from coverage in January 2020.\n[\n78\n]\nThis spike in April 2020 can be attributed to the increased coverage of the \"\nCovering Climate Now'\n' campaign and the US holiday of \"\nEarth Day\n\". The overall decline in climate change coverage in the year 2020 is related to the increased coverage and interconnectedness of\nCOVID-19\nand President Trump, without mention of climate change, that began in January 2020.\n[\n113\n]\nThe U.S. experienced its highest level of climate change media coverage to date in September and October 2021. This increase can be attributed to coverage of the United Nations Conference of Parties meeting which aimed to outline policies to address climate change.\n[\n114\n]\nAccording to the analisys of\nMedia Matters for America\n, in 2024 the corporate broadcast networks in the USA dedicated to climate change 12 hours and 51 minutes, which is considered as highly insufficient. Climate coverage declined in the years 2022-2024.\n[\n115\n]\nMedia coverage of the\nJanuary 2025 Southern California wildfires\nhas been criticized for not addressing the impact of climate change on the fires, with some coverage ignoring the climate crisis altogether.\n[\n116\n]\n[\n117\n]\nSee also\n[\nedit\n]\nGlobal warming portal\nClimate apocalypse\n(about usage of the term)\nClimate change and civilizational collapse\nClimate change denial\nClimate Change Denial Disorder\n,\nsatirical\nparody\nfilm about a\nfictional disease\nClimate change in popular culture\nClimate crisis\n(about usage of the term)\nClimate emergency declaration\n(includes usage of the term \"climate emergency\")\nEnvironmental communication\nEnvironmental skepticism\nGlobal warming controversy\nMerchants of Doubt\nRequiem for a Species\nReferences\n[\nedit\n]\n^\nAntilla, Liisa (March 2010). \"Self-censorship and science: a geographical review of media coverage of climate tipping points\".\nPublic Understanding of Science\n.\n19\n(2):\n240\u2013\n256.\ndoi\n:\n10.1177/0963662508094099\n.\n^\na\nb\n\"Climate Change 2022: Mitigation of Climate Change: Technical Summary\"\n(PDF)\n. Archived from\nthe original\n(PDF)\non 2022-04-04\n. Retrieved\n2022-04-10\n.\n^\na\nb\nNewman, Todd P.; Nisbet, Erik C.; Nisbet, Matthew C. (November 2018). \"Climate change, cultural cognition, and media effects: Worldviews drive news selectivity, biased processing, and polarized attitudes\".\nPublic Understanding of Science\n.\n27\n(8):\n985\u2013\n1002.\ndoi\n:\n10.1177/0963662518801170\n.\nPMID\n30253695\n.\n^\nLichter, S. R.; Rothman, S. (1984). \"The media and national defense\". In Pfaltzgraff, Robert L.; Ra'anan, Uri (eds.).\nNational Security Policy: The Decision-making Process\n. Archon Books. pp.\n265\u2013\n282.\nISBN\n978-0-208-02003-1\n.\n^\nBozell, L. Brent; Baker, Brent H. (1990).\nAnd That's the Way it Is(n't): A Reference Guide to Media Bias\n. Media Research Center.\nISBN\n978-0-9627348-0-9\n.\nOCLC\n551474402\n.\n[\npage\u00a0needed\n]\n^\na\nb\nNissani, Moti (September 1999). \"Media coverage of the greenhouse effect\".\nPopulation and Environment\n.\n21\n(1):\n27\u2013\n43.\ndoi\n:\n10.1007/BF02436119\n.\n^\n\"Hint to Coal Consumers\"\n.\nThe Selma Morning Times\n. Selma, Alabama, US. October 15, 1902. p.\u00a04.\nArchived\nfrom the original on September 8, 2021\n. Retrieved\nSeptember 8,\n2021\n.\n^\n\"Coal Consumption Affecting Climate\"\n.\nRodney and Otamatea Times, Waitemata and Kaipara Gazette\n. Warkworth, New Zealand. 14 August 1912. p.\u00a07.\nArchived\nfrom the original on 8 September 2021\n. Retrieved\n8 September\n2021\n.\nText was earlier\npublished in\nPopular Mechanics\n, March 1912, p. 341.\n^\nBodansky, Daniel (2001).\n\"The History of the Global Climate Change Regime\"\n(PDF)\n. In Luterbacher, Urs; Sprinz, Detlef F. (eds.).\nInternational Relations and Global Climate Change\n.\nThe MIT Press\n. pp.\n23\u2013\n40. Archived from\nthe original\n(PDF)\non 27 March 2014\n. Retrieved\n22 November\n2016\n.\n^\nMcCright, A. M.; Dunlap R. E. (2000).\n\"Challenging global warming as a social problem: An analysis of the conservative movement's counter-claims\"\n(PDF)\n.\nSocial Problems\n.\n47\n(4):\n499\u2013\n522.\ndoi\n:\n10.2307/3097132\n.\nJSTOR\n3097132\n.\nSee p.\u00a0500.\n^\n\"Speech to the Royal Society | Margaret Thatcher Foundation\"\n.\nwww.margaretthatcher.org\n. Retrieved\n2022-09-20\n.\n^\nCarvalho, Anabela (April 2007). \"Ideological cultures and media discourses on scientific knowledge: re-reading news on climate change\".\nPublic Understanding of Science\n.\n16\n(2):\n223\u2013\n243.\ndoi\n:\n10.1177/0963662506066775\n.\nhdl\n:\n1822/41838\n.\n^\nBlack, Richard (5 September 2007).\n\"BBC switches off climate special\"\n.\nBBC\n. Retrieved\n15 December\n2011\n.\n^\nBBC drops climate change special\n.\nThe Guardian\n. 5 September 2007. Retrieved 15 December 2011.\n^\nMcCarthy, Michael,\nGlobal Warming: Too Hot to Handle for the BBC\nArchived\n15 September 2007 at the\nWayback Machine\n,\nThe Independent\n, 6 September 2007\n^\na\nb\nBoykoff, Max (March 2010). \"Indian media representations of climate change in a threatened journalistic ecosystem\".\nClimatic Change\n.\n99\n(\n1\u2013\n2):\n17\u2013\n25.\nBibcode\n:\n2010ClCh...99...17B\n.\ndoi\n:\n10.1007/s10584-010-9807-8\n.\n^\n\"2004\u20132010 World Newspaper Coverage of Climate Change or Global Warming\"\n.\nCenter for Science and Technology Policy Research\n.\nUniversity of Colorado at Boulder\n.\nArchived\nfrom the original on 2019-08-31\n. Retrieved\n2010-08-15\n.\n^\na\nb\n\"Study: How Broadcast Networks Covered Climate Change In 2015\"\n.\nMedia Matters for America\n. 2016-02-29.\nArchived\nfrom the original on 2019-06-13\n. Retrieved\n2016-12-03\n.\n^\na\nb\nc\nBoykoff, M.; Andrews, K.; Daly, M.; Katzung, J.; Luedecke, G.; Maldonado, C.; Nacu-Schmidt, A.\n\"A Review of Media Coverage of Climate Change and Global Warming in 2017\"\n. Media and Climate Change Observatory, Center for Science and Technology Policy Research, Cooperative Institute for Research in Environmental Sciences, University of Colorado.\nArchived\nfrom the original on 2019-08-06\n. Retrieved\n2018-03-02\n.\n^\nKaufman, Mark (2020).\n\"The guardians of Wikipedia's climate change page\"\n.\nMashable\n.\nArchived\nfrom the original on 2021-04-18\n. Retrieved\n2021-04-22\n.\n^\na\nb\nBoykoff, M.T.;\nBoykoff, J.M.\n(2004). \"Balance as bias: Global warming and the US prestige press\".\nGlobal Environmental Change\n.\n14\n(2):\n125\u2013\n136.\nBibcode\n:\n2004GEC....14..125B\n.\ndoi\n:\n10.1016/j.gloenvcha.2003.10.001\n.\n^\nMoore, Barbara; Singletary, Michael (December 1985). \"Scientific Sources' Perceptions of Network News Accuracy\".\nJournalism Quarterly\n.\n62\n(4):\n816\u2013\n823.\ndoi\n:\n10.1177/107769908506200415\n.\n^\nNelkin, Dorothy (1995).\nSelling Science: How the Press Covers Science and Technology\n. W.H. Freeman.\nISBN\n978-0-7167-2595-4\n.\n[\npage\u00a0needed\n]\n^\na\nb\nSchneider, S.\n\"Mediarology: The role of citizens, journalists, and scientists in debunking climate change myths\"\n.\nArchived\nfrom the original on 2019-10-01\n. Retrieved\n2011-04-03\n.\n^\nSinger, Eleanor; Endreny, Phyllis (June 1994).\n\"Reporting on Risk: How the Mass Media Portray Accidents, Diseases, Disasters and Other Hazards\"\n.\nRISK\n.\n5\n(3).\n^\nTankard, James W.; Ryan, Michael (June 1974). \"News Source Perceptions of Accuracy of Science Coverage\".\nJournalism Quarterly\n.\n51\n(2):\n219\u2013\n225.\ndoi\n:\n10.1177/107769907405100204\n.\n^\nBord, R.J.; O'Connor; Fisher (1998).\n\"Public perceptions of global warming: United States and international perspectives\"\n.\nClimate Research\n.\n11\n(1):\n75\u2013\n84.\nBibcode\n:\n1998ClRes..11...75B\n.\ndoi\n:\n10.3354/cr011075\n.\n^\na\nb\nJiang, Yangxueqing; Schwarz, Norbert; Reynolds, Katherine J.; Newman, Eryn J. (7 August 2024).\n\"Repetition increases belief in climate-skeptical claims, even for climate science endorsers\"\n.\nPLOS ONE\n.\n19\n(8): e0307294.\nBibcode\n:\n2024PLoSO..1907294J\n.\ndoi\n:\n10.1371/journal.pone.0307294\n.\nPMC\n11305575\n.\nPMID\n39110668\n.\n{{\ncite journal\n}}\n: CS1 maint: article number as page number (\nlink\n)\n^\nShoemaker, Pamela J.; Reese, Stephen D. (1996).\nMediating the Message: Theories of Influences on Mass Media Content\n. Longman. p.\u00a0261.\nISBN\n978-0-8013-1251-9\n.\n^\nBennett, W. Lance (2003).\nNews: The Politics of Illusion\n. Longman. p.\u00a045.\nISBN\n978-0-321-08878-9\n.\n^\nRensberger, B (2002).\n\"Reporting Science Means Looking for Cautionary Signals\"\n.\nNieman Reports\n:\n12\u2013\n14.\nArchived\nfrom the original on 2019-08-06\n. Retrieved\n2018-02-05\n.\n^\nBoykoff, Maxwell T. (2009).\n\"We Speak for the Trees: Media Reporting on the Environment\"\n.\nAnnual Review of Environment and Resources\n.\n34\n(1):\n431\u2013\n457.\ndoi\n:\n10.1146/annurev.environ.051308.084254\n.\n^\nLadle, Richard. J.; Jepson, Paul; Whittaker, Robert J. (September 2005). \"Scientists and the media: the struggle for legitimacy in climate change and conservation science\".\nInterdisciplinary Science Reviews\n.\n30\n(3):\n231\u2013\n240.\nBibcode\n:\n2005ISRv...30..231L\n.\ndoi\n:\n10.1179/030801805X42036\n.\n^\nWetts, Rachel (2020-07-23).\n\"In climate news, statements from large businesses and opponents of climate action receive heightened visibility\"\n.\nProceedings of the National Academy of Sciences\n.\n117\n(32):\n19054\u2013\n19060.\nBibcode\n:\n2020PNAS..11719054W\n.\ndoi\n:\n10.1073/pnas.1921526117\n.\nPMC\n7431090\n.\nPMID\n32719122\n.\n^\nRichardson, John H. (20 July 2018).\n\"When the End of Human Civilization Is Your Day Job\"\n.\nEsquire\n.\n^\nEreaut, Gill; Segnit, Nat (August 2006).\nWarm Words: How are we telling the climate story and can we tell it better?\n.\nInstitute for Public Policy Research\n(Report).\n^\nNuccitelli, Dana (9 July 2018).\n\"There are genuine climate alarmists, but they're not in the same league as deniers\"\n.\nThe Guardian\n.\n^\nDilling, Lisa; Moser, Susanne C. (2007). \"Introduction\". In Moser, Susanne C.; Dilling, Lisa (eds.).\nCreating a Climate for Change\n. pp.\n1\u2013\n28.\ndoi\n:\n10.1017/CBO9780511535871\n.\nISBN\n978-0-521-86923-2\n.\n^\nO'Neill, Saffron; Nicholson-Cole, Sophie (March 2009). \"\n'Fear Won't Do It': Promoting Positive Engagement With Climate Change Through Visual and Iconic Representations\".\nScience Communication\n.\n30\n(3):\n355\u2013\n379.\ndoi\n:\n10.1177/1075547008329201\n.\n^\nHartmann, Betsy (2010). \"Rethinking climate refugees and climate conflict: Rhetoric, reality and the politics of policy discourse\".\nJournal of International Development\n.\n22\n(2):\n233\u2013\n246.\ndoi\n:\n10.1002/jid.1676\n.\n^\nLomborg, Bjorn (11 July 2020).\n\"How climate change alarmists are actually damaging the planet\"\n.\nNew York Post\n.\n^\nEmanuel, Kerry (July 19, 2010).\n\"\n\"Climategate\": A Different Perspective\"\n.\nNational Association of Scholars\n.\nArchived\nfrom the original on August 10, 2021\n. Retrieved\nAugust 10,\n2021\n.\n^\nPeterson, Thomas C.; Connolley, William M.; Fleck, John (September 2008). \"THE MYTH OF THE 1970s GLOBAL COOLING SCIENTIFIC CONSENSUS\".\nBulletin of the American Meteorological Society\n.\n89\n(9):\n1325\u2013\n1338.\nBibcode\n:\n2008BAMS...89.1325P\n.\ndoi\n:\n10.1175/2008BAMS2370.1\n.\n^\nKapitsa, Andrei, and Vladimir Bashkirtsev, \"Challenging the basis of Kyoto Protocol\",\nThe Hindu\n, 10 July 2008,\n[\nverification needed\n]\n^\nIrish Independent\n, \"Don't believe doomsayers that insist the world's end is nigh\", 16 March 2007, p. 1.\n^\nSchmidt, David, \"It's curtains for global warming\",\nJerusalem Post\n, 28 June 2002, p. 16B. \"If there is one thing more remarkable than the level of alarm inspired by global warming, it is the thin empirical foundations upon which the forecast rests. Throughout the 1970s, the scientific consensus held that the world was entering a period of global cooling, with results equally catastrophic to those now predicted for global warming.\"\n^\nWilson, Francis\n, \"The rise of the extreme killers\",\nSunday Times\n, 19 April 2009, p. 32. \"Throughout history, there have been false alarms: \"shadow of the bomb\", \"nuclear winter\", \"ice age cometh\" and so on. So it's no surprise that today many people are skeptical about climate change. The difference is that we have hard evidence that increasing temperatures will lead to a significant risk of dangerous repercussions.\"\n^\nNational Post\n, \"The sky was supposed to fall: The '70s saw the rise of environmental Chicken Littles of every shape as a technique for motivating public action\", 5 April 2000, p. B1. \"One of the strange tendencies of modern life, however, has been the institutionalization of scaremongering, the willingness of the mass media and government to lend plausibility to wild surmises about the future. The crucial decade for this odd development was the 1970s. Schneider's book excited a frenzy of glacier hysteria. The most-quoted ice-age alarmist of the 1970s became, in a neat public-relations pivot, one of the most quoted global-warming alarmists of the 1990s.\"\n^\nMcCombs, M; Shaw, D. (1972). \"The Agenda Setting Function of Mass Media\".\nPublic Opinion Quarterly\n.\n36\n(2):\n176\u2013\n187.\ndoi\n:\n10.1086/267990\n.\n^\na\nb\nBoykoff, M (2007). \"Flogging a Dead Norm? Newspaper Coverage of Anthropogenic Climate Change in the United States and United Kingdom from 2003-2006\".\nArea\n.\n39\n(2):\n000\u2013\n000, 200.\nBibcode\n:\n2007Area...39..470B\n.\ndoi\n:\n10.1111/j.1475-4762.2007.00769.x\n.\n^\nHajer, Maarten; Versteeg, Wytske (September 2005). \"A decade of discourse analysis of environmental politics: Achievements, challenges, perspectives\".\nJournal of Environmental Policy & Planning\n.\n7\n(3):\n175\u2013\n184.\nBibcode\n:\n2005JEPP....7..175H\n.\ndoi\n:\n10.1080/15239080500339646\n.\n^\nFeindt, Peter H.; Oels, Angela (September 2005).\n\"Does discourse matter? Discourse analysis in environmental policy making\"\n.\nJournal of Environmental Policy & Planning\n.\n7\n(3):\n161\u2013\n173.\nBibcode\n:\n2005JEPP....7..161F\n.\ndoi\n:\n10.1080/15239080500339638\n.\n^\nHall, Stuart; Critcher, Chas; Jefferson, Tony; Clarke, John; Roberts, Brian (2017).\nPolicing the Crisis: Mugging, the State and Law and Order\n. Bloomsbury Publishing. p.\u00a0438.\nISBN\n978-1-137-00721-6\n.\n^\nCarvalho, Anabela; Burgess, Jacquelin (December 2005). \"Cultural Circuits of Climate Change in U.K. Broadsheet Newspapers, 1985\u20132003\".\nRisk Analysis\n.\n25\n(6):\n1457\u2013\n1469.\nBibcode\n:\n2005RiskA..25.1457C\n.\ndoi\n:\n10.1111/j.1539-6924.2005.00692.x\n.\nhdl\n:\n1822/41721\n.\nPMID\n16506975\n.\n^\nAnderson, Alison (March 2009). \"Media, Politics and Climate Change: Towards a New Research Agenda\".\nSociology Compass\n.\n3\n(2):\n166\u2013\n182.\ndoi\n:\n10.1111/j.1751-9020.2008.00188.x\n.\n^\nMonibot, George (29 April 2009).\n\"The media laps up fake controversy over climate change\"\n.\nThe Guardian\n. London\n. Retrieved\n2011-11-05\n.\n^\nLorenzoni, Irene; Pidgeon, Nick F. (21 August 2006). \"Public Views on Climate Change: European and USA Perspectives\".\nClimatic Change\n.\n77\n(\n1\u2013\n2):\n73\u2013\n95.\nBibcode\n:\n2006ClCh...77...73L\n.\ndoi\n:\n10.1007/s10584-006-9072-z\n.\n^\nMacnaghten, Phil (February 2003).\n\"Embodying the Environment in Everyday Life Practices\"\n.\nThe Sociological Review\n.\n51\n(1):\n63\u2013\n84.\ndoi\n:\n10.1111/1467-954X.00408\n.\n^\nBeck, U (1992).\nRisk Society - Towards a New Modernity\n. Frankfurt: Sage.\nISBN\n978-0-8039-8345-8\n.\n^\nHulme, M (2009).\nWhy We Disagree About Climate Change\n. Cambridge University Press. p.\u00a0432.\nISBN\n978-0-521-72732-7\n.\n^\nMoser & Dilling, M., and L. (2007).\nCreating a Climate for Change\n. Cambridge University Press.\nISBN\n978-0-521-86923-2\n.\n{{\ncite book\n}}\n: CS1 maint: multiple names: authors list (\nlink\n)\n^\na\nb\nBoykoff, M; Boykoff, J (November 2007). \"Climate Change and Journalistic Norms: A case study of US mass-media coverage\".\nGeoforum\n.\n38\n(6):\n1190\u2013\n1204.\ndoi\n:\n10.1016/j.geoforum.2007.01.008\n.\n^\nMcKibben, Bill.\n\"We Need to Literally Declare War on Climate Change\"\n.\nThe New Republic\n. The New Republic.\nArchived\nfrom the original on 10 June 2021\n. Retrieved\n1 March\n2018\n.\n^\nKester, Johannes; Sovacool, Benjamin K. (May 2017).\n\"Torn between war and peace: Critiquing the use of war to mobilize peaceful climate action\"\n.\nEnergy Policy\n.\n104\n:\n50\u2013\n55.\nBibcode\n:\n2017EnPol.104...50K\n.\ndoi\n:\n10.1016/j.enpol.2017.01.026\n.\n^\nBlock, Katharina; Li, Mengyu; G\u00e4rtner, Jan; Lenzen, Manfred (29 March 2025). \"Geopolitical conflict impedes climate change mitigation\".\nnpj Climate Action\n.\n4\n(1): 33.\nBibcode\n:\n2025npjCA...4...33B\n.\ndoi\n:\n10.1038/s44168-025-00224-7\n.\n^\nAuer, Matthew R.; Zhang, Yuman; Lee, Priscilla (May 2014). \"The potential of microblogs for the study of public perceptions of climate change\".\nWIREs Climate Change\n.\n5\n(3):\n291\u2013\n296.\nBibcode\n:\n2014WIRCC...5..291A\n.\ndoi\n:\n10.1002/wcc.273\n.\n^\na\nb\nAnderson, Ashley A. (2017). \"Effects of Social Media Use on Climate Change Opinion, Knowledge, and Behavior\".\nOxford Research Encyclopedia of Climate Science\n.\ndoi\n:\n10.1093/acrefore/9780190228620.013.369\n.\nISBN\n978-0-19-022862-0\n.\n^\na\nb\nc\nWilliams, Hywel T.P.; McMurray, James R.; Kurz, Tim; Hugo Lambert, F. (2015-05-01).\n\"Network analysis reveals open forums and echo chambers in social media discussions of climate change\"\n.\nGlobal Environmental Change\n.\n32\n:\n126\u2013\n138.\nBibcode\n:\n2015GEC....32..126W\n.\ndoi\n:\n10.1016/j.gloenvcha.2015.03.006\n.\nhdl\n:\n10871/17565\n.\n^\nHolmberg, Arita; Alvinius, Aida (2019-10-10).\n\"Children's protest in relation to the climate emergency: A qualitative study on a new form of resistance promoting political and social change\"\n.\nChildhood\n.\n27\n:\n78\u2013\n92.\ndoi\n:\n10.1177/0907568219879970\n.\n^\nLakhani, Nina; reporter, Nina Lakhani climate justice (2024-06-05).\n\"Nearly half of journalists covering climate crisis globally received threats for their work\"\n.\nThe Guardian\n. Retrieved\n2024-06-10\n.\n^\nLeiserowitz, A.; Carman, J.; Buttermore, N.; Wang, X.; et\u00a0al. (June 2021).\nInternational Public Opinion on Climate Change\n(PDF)\n. New Haven, CT, U.S.: Yale Program on Climate Change Communication and Facebook Data for Good. p.\u00a07.\nArchived\n(PDF)\nfrom the original on 28 June 2021.\n^\nReadfearn, Graham (14 January 2020).\n\"The Australian says it accepts climate science, so why does it give a platform to 'outright falsehoods'?\"\n.\nThe Guardian\n.\n^\n\"The warmaholics' fantasy\"\n.\nThe Australian\n. 2009-01-16. Archived from\nthe original\non 2009-01-16\n. Retrieved\n2021-04-22\n.\n^\nBacon, Wendy (2013-10-30).\n\"Sceptical climate part 2: climate science in Australian newspapers\"\n.\nAnalysis & Policy Observatory\n.\nArchived\nfrom the original on 2021-04-22\n. Retrieved\n2021-04-27\n.\n^\n\"The Australian Brings You The Climate Science Denial News From Five Years Ago \u2013 Graham Readfearn\"\n. 10 May 2013.\nArchived\nfrom the original on 2021-11-19\n. Retrieved\n2021-04-22\n.\n^\nChapman, Simon (16 July 2015).\n\"The Australian's campaign against wind farms continues but the research doesn't stack up\"\n.\nThe Conversation\n.\nArchived\nfrom the original on 2021-04-24\n. Retrieved\n2021-04-22\n.\n^\nAldred, Jessica (2013-03-07).\n\"Australia links 'angry summer' to climate change \u2013 at last\"\n.\nThe Guardian\n. Retrieved\n2023-03-13\n.\n^\na\nb\nc\nBoykoff, Max; Nacu-Schmidt, Ami; Pearman, Olivia; Katzung, Jennifer (April 2020).\n\"Media and Climate Change Observatory Monthly Summary: This historic decline in emissions is happening for all the wrong reasons\"\n.\nMedia and Climate Change Observatory Monthly Summaries\n(40). University of Colorado Boulder.\ndoi\n:\n10.25810/cr61-gy20\n.\n^\nReadfearn, Graham (2022-06-13).\n\"Sky News Australia is a global hub for climate misinformation, report says\"\n.\nThe Guardian\n. Retrieved\n2023-02-23\n.\n^\n\"Media reaction: Australia's bushfires and climate change\"\n.\nCarbon Brief\n. 2020-01-07.\nArchived\nfrom the original on 2020-09-29\n. Retrieved\n2021-04-22\n.\n^\nAbram, Nerilie.\n\"Australia's Angry Summer: This Is What Climate Change Looks Like\"\n.\nScientific American Blog Network\n.\nArchived\nfrom the original on 2021-05-05\n. Retrieved\n2021-04-22\n.\n^\na\nb\nc\nd\ne\nf\nStoddart, Mark C. J.; Haluza-DeLay, Randolph; Tindall, David B. (February 2016). \"Canadian News Media Coverage of Climate Change: Historical Trajectories, Dominant Frames, and International Comparisons\".\nSociety & Natural Resources\n.\n29\n(2):\n218\u2013\n232.\nBibcode\n:\n2016SNatR..29..218S\n.\ndoi\n:\n10.1080/08941920.2015.1054569\n.\n^\nSampei Y, Aoyagi-Usui M (2009). \"Mass-media coverage, its influence on public awareness of climate-change issues, and implications for Japan's national campaign to reduce greenhouse gas emissions\".\nGlobal Environmental Change\n.\n19\n(2):\n203\u2013\n212.\nBibcode\n:\n2009GEC....19..203S\n.\ndoi\n:\n10.1016/j.gloenvcha.2008.10.005\n.\n^\nBillett, Simon (March 2010). \"Dividing climate change: global warming in the Indian mass media\".\nClimatic Change\n.\n99\n(\n1\u2013\n2):\n1\u2013\n16.\nBibcode\n:\n2010ClCh...99....1B\n.\ndoi\n:\n10.1007/s10584-009-9605-3\n.\n^\nMittal, Radhika (2012). \"Climate Change Coverage in Indian Print Media: A Discourse Analysis\".\nThe International Journal of Climate Change: Impacts and Responses\n.\n3\n(2):\n219\u2013\n230.\ndoi\n:\n10.18848/1835-7156/CGP/v03i02/37105\n.\nhdl\n:\n1959.14/181298\n.\n^\nRobbins, David (November 26, 2015).\n\"Why the media doesn't care about climate change. News likes unambiguous, discrete events, straight-forward, one-off happenings rather than long-term social trends\"\n.\nThe Irish Times\n.\nArchived\nfrom the original on 2020-11-08\n. Retrieved\n2019-10-16\n.\n^\nBell, Allan (July 1994). \"Media (mis)communication on the science of climate change\".\nPublic Understanding of Science\n.\n3\n(3):\n259\u2013\n275.\ndoi\n:\n10.1088/0963-6625/3/3/002\n.\n^\nShapeNZ research report. 13 April 2007,\nNew Zealanders' views on climate change and related policy options\n^\nBaykal Fide, Ece (November 2022).\n\"Turkish press climate crisis coverage (2018\u20132019): elements of disconnect in discourses and the representation of solutions\"\n.\nNew Perspectives on Turkey\n.\n67\n:\n32\u2013\n56.\ndoi\n:\n10.1017/npt.2022.8\n.\n^\n\"Contemporary Turkey: an ecological account\"\n(PDF)\n.\nCitizens' Assembly-Turkey\n(2). January 2019.\nArchived\n(PDF)\nfrom the original on 2021-11-19\n. Retrieved\n2019-12-09\n.\n^\nBoykoff, Maxwell T; Rajan, S Ravi (March 2007).\n\"Signals and noise: Mass-media coverage of climate change in the USA and the UK\"\n.\nEMBO Reports\n.\n8\n(3):\n207\u2013\n211.\ndoi\n:\n10.1038/sj.embor.7400924\n.\nPMC\n1808044\n.\nPMID\n17330062\n.\n^\na\nb\nHulme, Mike; Turnpenny, John (June 2004). \"Understanding and managing climate change: the UK experience\".\nThe Geographical Journal\n.\n170\n(2):\n105\u2013\n115.\nBibcode\n:\n2004GeogJ.170..105H\n.\ndoi\n:\n10.1111/j.0016-7398.2004.00112.x\n.\nJSTOR\n3451587\n.\n^\na\nb\nShanahan, Mike (2007). Talking about a revolution: climate change and the media (Report). International Institute for Environment and Development.\nJSTOR\nresrep01410\n.\n^\na\nb\nc\nGavin, Neil T.; Leonard-Milsom, Liam; Montgomery, Jessica (May 2011). \"Climate change, flooding and the media in Britain\".\nPublic Understanding of Science\n.\n20\n(3):\n422\u2013\n438.\ndoi\n:\n10.1177/0963662509353377\n.\nPMID\n21796885\n.\n^\n\"The heatwave of 2003\"\n.\nMet Office\n. Retrieved\n2023-12-07\n.\n^\nSample, Ian (5 March 2004).\n\"2003 heatwave a record waiting to be broken\"\n.\nThe Guardian\n.\n^\na\nb\nc\nMcAllister, Lucy; Daly, Meaghan; Chandler, Patrick; McNatt, Marisa; Benham, Andrew; Boykoff, Maxwell (August 2021).\n\"Balance as bias, resolute on the retreat? Updates & analyses of newspaper coverage in the United States, United Kingdom, New Zealand, Australia and Canada over the past 15 years\"\n.\nEnvironmental Research Letters\n.\n16\n(9): 094008.\nBibcode\n:\n2021ERL....16i4008M\n.\ndoi\n:\n10.1088/1748-9326/ac14eb\n.\n^\na\nb\nBird, Helen; Boykoff, Max; Goodman, Mike; Monbiot, George; Littler, Jo (2009-12-01).\n\"The media and climate change\"\n.\nSoundings\n.\n43\n(43):\n47\u2013\n64.\ndoi\n:\n10.3898/136266209790424595\n.\nProQuest\n211274894\n.\n^\na\nb\nc\nCammaerts, Bart (February 2024).\n\"The mediated circulation of the United Kingdom's YouthStrike4Climate movement's discourses and actions\"\n.\nEuropean Journal of Cultural Studies\n.\n27\n(1):\n107\u2013\n128.\ndoi\n:\n10.1177/13675494231165645\n.\n^\nMayhew, Freddy (2019-02-14).\n\"National newspaper ABCs: Mail titles see slower year-on-year circulation decline as bulk sales distortion ends\"\n.\nPress Gazette\n. Retrieved\n2023-12-07\n.\n^\nGabbatiss, Josh; Hayes, Sylvia; Goodman, Joe; Prater, Tom.\n\"Analysis: How UK newspapers changed their minds about climate change\"\n.\nCarbon Brief\n.\n^\nLyytim\u00e4ki J, Tapio P (2009). \"Climate change as reported in the press of Finland: From screaming headlines to penetrating background noise\".\nInternational Journal of Environmental Studies\n.\n66\n(6):\n723\u2013\n735.\nBibcode\n:\n2009IJEnS..66..723L\n.\ndoi\n:\n10.1080/00207230903448490\n.\n^\nSchmidt, Andreas; Ivanova, Ana; Sch\u00e4fer, Mike S. (2013). \"Media attention for climate change around the world: A comparative analysis of newspaper coverage in 27 countries\".\nGlobal Environmental Change\n.\n23\n(5):\n1233\u2013\n1248.\nBibcode\n:\n2013GEC....23.1233S\n.\ndoi\n:\n10.1016/j.gloenvcha.2013.07.020\n.\n^\nEnvironmental skepticism is \"a tactic of an elite-driven counter-movement designed to combat environmentalism, and ... the successful use of this tactic has contributed to the weakening of US commitment to environmental protection.\" \u2014\nJacques, P.J.; Dunlap, R.E.; Freeman, M. (June 2008). \"The organization of denial: Conservative think tanks and environmental skepticism\".\nEnvironmental Politics\n.\n17\n(3):\n349\u2013\n385.\nBibcode\n:\n2008EnvPo..17..349J\n.\ndoi\n:\n10.1080/09644010802055576\n.\n^\nBoykoff, Maxwell T (October 2007). \"From convergence to contention: United States mass media representations of anthropogenic climate change science\".\nTransactions of the Institute of British Geographers\n.\n32\n(4):\n477\u2013\n489.\nBibcode\n:\n2007TrIBG..32..477B\n.\ndoi\n:\n10.1111/j.1475-5661.2007.00270.x\n.\n^\nFreudenburg WR, Muselli V (2010). \"Global warming estimates, media expectations, and the asymmetry of scientific challenge\".\nGlobal Environmental Change\n.\n20\n(3):\n483\u2013\n491.\nBibcode\n:\n2010GEC....20..483F\n.\ndoi\n:\n10.1016/j.gloenvcha.2010.04.003\n.\n^\nDana Nuccitelli (23 October 2013).\n\"Fox News defends global warming false balance by denying the 97% consensus\"\n.\nThe Guardian\n. Retrieved\n12 September\n2022\n.\n^\nPublic Citizen, 13 Aug. 2019,\n\"Foxic: Fox News Network's Dangerous Climate Denial 2019: Fox's Continues to Pollute the Airwaves with Misinformation, Give Platform to Deniers\"\nArchived\n2020-07-17 at the\nWayback Machine\n^\nStenport, Anna Westerstahl; Vachula, Richard S (March 2017). \"Polar bears and ice: cultural connotations of Arctic environments that contradict the science of climate change\".\nMedia, Culture & Society\n.\n39\n(2):\n282\u2013\n295.\ndoi\n:\n10.1177/0163443716655985\n.\n^\nNewport, Frank (11 March 2010).\n\"Americans' Global Warming Concerns Continue to Drop\"\n.\nGallup\n.\n^\n\"How Broadcast Networks Covered Climate Change in 2015\"\n.\nScribd\n. Media Matters for America.\nArchived\nfrom the original on 2021-11-19\n. Retrieved\n2018-03-01\n.\n^\nPark, David J (November 2017). \"United States news media and climate change in the era of US President Trump\".\nIntegrated Environmental Assessment and Management\n.\n14\n(2):\n202\u2013\n204.\nBibcode\n:\n2018IEAM...14..202P\n.\ndoi\n:\n10.1002/ieam.2011\n.\nPMID\n29193745\n.\n^\n\"Climate change news coverage has declined. The audience has not\"\n.\nDigital Content Next\n. 2020-09-23.\nArchived\nfrom the original on 2021-04-21\n. Retrieved\n2021-04-21\n.\n^\n\"2021 Year End Retrospective, Special Issue 2021, A Review of Media Coverage of Climate Change and Global Warming in 2021\"\n.\nsciencepolicy.colorado.edu\n. MeCCO Monthly Summaries\u00a0:: Media and Climate Change Observatory. 2021\n. Retrieved\n2023-11-22\n.\n^\nCooper, Evlondo (6 March 2025).\n\"How broadcast TV networks covered climate change in 2024\"\n.\nMedia Matters for America\n. Retrieved\n6 April\n2025\n.\n^\nHertsgaard, Mark (2025-01-16).\n\"The media needs to show how the climate crisis is fueling the LA wildfires\"\n.\nThe Guardian\n.\n^\nGoldsmith, Eloise (Jan 16, 2025).\n\"Critics Warn Media Outlets Failing to Explain Climate Cause Behind Los Angeles Fires | Common Dreams\"\n.\nCommon Dreams\n.\nFurther reading\n[\nedit\n]\nPooley, Eric (June 8, 2010).\nThe Climate War: True Believers, Power Brokers, and the Fight to Save the Earth\n. Hachette Books.\nISBN\n978-1-4013-2326-4\n.\nSpecter, Michael\n(2010).\nDenialism: How Irrational Thinking Harms the Planet and Threatens Our Lives\n. Penguin.\nISBN\n978-0-14-311831-2\n.\nHulme, Mike\n(2009).\nWhy We Disagree about Climate Change\n.\ndoi\n:\n10.1017/CBO9780511841200\n.\nISBN\n978-0-521-89869-0\n.\nBoyce, Tammy; Lewis, Justin (2009).\nClimate Change and the Media\n. Peter Lang.\nISBN\n978-1-4331-0460-2\n.\nBrevini, Benedetta; Lewis, Justin, eds. (2018).\nClimate Change and the Media\n.\ndoi\n:\n10.3726/b14826\n.\nISBN\n978-1-4331-5437-9\n.\nUusi-Rauva C, Tienari J (2010). \"On the relative nature of adequate measures: Media representations of the EU energy and climate package\".\nGlobal Environmental Change\n.\n20\n(3):\n492\u2013\n501.\nBibcode\n:\n2010GEC....20..492U\n.\ndoi\n:\n10.1016/j.gloenvcha.2010.03.001\n.\nAnderson, Alison (March 2009). \"Media, Politics and Climate Change: Towards a New Research Agenda\".\nSociology Compass\n.\n3\n(2):\n166\u2013\n182.\ndoi\n:\n10.1111/j.1751-9020.2008.00188.x\n.\n*\nBoykoff, Maxwell T. (2011).\nWho Speaks for the Climate?\n.\ndoi\n:\n10.1017/CBO9780511978586\n.\nISBN\n978-0-521-13305-0\n.\nv\nt\ne\nClimate change\nOverview\nCauses of climate change\nEffects of climate change\nClimate change mitigation\nClimate change adaptation\nBy country and region\nCauses\nOverview\nClimate system\nGreenhouse effect\n(\nCarbon dioxide in Earth's atmosphere\n)\nScientific consensus on climate change\nSources\nDeforestation\nFossil fuel\nGreenhouse gases\nGreenhouse gas emissions\nCarbon accounting\nCarbon footprint\nCarbon leakage\nfrom agriculture\nfrom wetlands\nWorld energy supply and consumption\nHistory\nHistory of climate change policy and politics\nHistory of climate change science\nSvante Arrhenius\nJames Hansen\nCharles David Keeling\nUnited Nations Climate Change conferences\nYears in climate change\n2019\n2020\n2021\n2022\n2023\n2024\nEffects and issues\nPhysical\nAbrupt climate change\nAnoxic event\nArctic methane emissions\nArctic sea ice decline\nAtlantic meridional overturning circulation\nDrought\nExtreme weather\nFlood\nCoastal flooding\nHeat wave\nMarine\nUrban heat island\nOceans\nacidification\ndeoxygenation\nheat content\nsea surface temperature\nstratification\ntemperature\nOzone depletion\nPermafrost thaw\nRetreat of glaciers since 1850\nSea level rise\nSeason creep\nClimate sensitivity\nTipping points in the climate system\nTropical cyclones\nWater cycle\nWildfires\nFlora and fauna\nBiomes\nMass mortality event\nBirds\nExtinction risk\nForest dieback\nInvasive species\nMarine life\nPlant biodiversity\nSocial and economic\nAgriculture\nLivestock\nMulti-breadbasket failure\nIn the United States\nChildren\nCities\nCivilizational collapse\nCrime\nDepopulation of settlements\nDestruction of cultural heritage\nDisability\nEconomic impacts\nU.S. insurance industry\nFisheries\nGender\nHealth\nMental health\nIn the United Kingdom\nIn the Philippines\nHuman rights\nIndigenous peoples\nInfectious diseases\nMigration\nPoverty\nPsychological impacts\nSecurity and conflict\nUrban flooding\nWater scarcity\nWater security\nBy country and region\nAfrica\nAmericas\nAntarctica\nArctic\nAsia\nAustralia\nCaribbean\nEurope\nMiddle East and North Africa\nSmall island countries\nby individual country\nMitigation\nEconomics and finance\nCarbon budget\nCarbon emission trading\nCarbon offsets and credits\nGold Standard (carbon offset standard)\nCarbon price\nCarbon tax\nClimate debt\nClimate finance\nClimate risk insurance\nCo-benefits of climate change mitigation\nEconomics of climate change mitigation\nFossil fuel divestment\nGreen Climate Fund\nLow-carbon economy\nNet zero emissions\nEnergy\nCarbon capture and storage\nEnergy transition\nFossil fuel phase-out\nNuclear power\nRenewable energy\nSustainable energy\nPreserving and enhancing\ncarbon sinks\nBlue carbon\nCarbon dioxide removal\nCarbon sequestration\nDirect air capture\nCarbon farming\nClimate-smart agriculture\nForest management\nafforestation\nforestry for carbon sequestration\nREDD and REDD+\nreforestation\nLand use, land-use change, and forestry\n(LULUCF and AFOLU)\nNature-based solutions\nOther\nIndividual action on climate change\nGeoengineering\nSociety and\nadaptation\nSociety\nBusiness action\nClimate action\nClimate emergency declaration\nClimate movement\nSchool Strike for Climate\nDenial\nEcological grief\nGovernance\nJustice\nLitigation\nPolitics\nPublic opinion\nWomen\nAdaptation\nAdaptation strategies on the German coast\nAdaptive capacity\nDisaster risk reduction\nEcosystem-based adaptation\nFlood control\nLoss and damage\nManaged retreat\nNature-based solutions\nResilience\nRisk\nVulnerability\nThe Adaptation Fund\nNational Adaptation Programme of Action\nCommunication\nClimate Change Performance Index\nClimate crisis (term)\nClimate spiral\nEducation\nMedia coverage\nPopular culture depictions\nart\nfiction\nvideo games\nWarming stripes\nInternational agreements\nGlasgow Climate Pact\nKyoto Protocol\nParis Agreement\nCooperative Mechanisms under Article 6 of the Paris Agreement\nNationally determined contributions\nSustainable Development Goal 13\nUnited Nations Framework Convention on Climate Change\nBackground and theory\nMeasurements\nGlobal surface temperature\nInstrumental temperature record\nProxy\nSatellite temperature measurement\nTheory\nAlbedo\nCarbon cycle\natmospheric\nbiologic\noceanic\npermafrost\nCarbon sink\nClimate sensitivity\nClimate variability and change\nCloud feedback\nCloud forcing\nFixed anvil temperature hypothesis\nCryosphere\nEarth's energy budget\nExtreme event attribution\nFeedbacks\nGlobal warming potential\nIllustrative model of greenhouse effect on climate change\nOrbital forcing\nRadiative forcing\nResearch and modelling\nClimate change scenario\nClimate model\nCoupled Model Intercomparison Project\nIntergovernmental Panel on Climate Change (IPCC)\nIPCC Sixth Assessment Report\nPaleoclimatology\nRepresentative Concentration Pathway\nShared Socioeconomic Pathways\nClimate change portal\nCategory\nGlossary\nIndex\nRetrieved from \"\nhttps://en.wikipedia.org/w/index.php?title=Media_coverage_of_climate_change&oldid=1300061902\n\"\nCategories\n:\nClimate change and society\nClimate change controversies\nMedia coverage and representation\nClimate change denial\nClimate change mass media\nHidden categories:\nWikipedia articles needing page number citations from June 2025\nWebarchive template wayback links\nCS1 maint: article number as page number\nAll pages needing factual verification\nWikipedia articles needing factual verification from June 2025\nCS1 maint: multiple names: authors list\nArticles with short description\nShort description is different from Wikidata\nPages using multiple image with auto scaled images\nCitation overkill\nArticles tagged with the inline citation overkill template from August 2021\nAll articles with unsourced statements\nArticles with unsourced statements from June 2025\nArticles with unsourced statements from August 2021\nAll articles with failed verification\nArticles with failed verification from August 2021\nWikipedia articles needing factual verification from March 2023\nWikipedia articles in need of updating from May 2019\nAll Wikipedia articles in need of updating\nArticles to be expanded from August 2021\nAll articles to be expanded\nArticles with empty sections from August 2021\nAll articles with empty sections\nWikipedia articles in need of updating from November 2019\nWikipedia articles in need of updating from December 2020\nSearch\nSearch\nMedia coverage of climate change\n6 languages\nAdd topic",
        "image_urls": [
          {
            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/2021_Public_opinion_on_climate_change_-_Yale_Program_on_Climate_Change_Communication.svg/500px-2021_Public_opinion_on_climate_change_-_Yale_Program_on_Climate_Change_Communication.svg.png",
            "score": 1
          },
          {
            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Ms._magazine_Cover_-_Spring_2007.jpg/250px-Ms._magazine_Cover_-_Spring_2007.jpg",
            "score": 0
          }
        ],
        "title": "Media coverage of climate change - Wikipedia"
      },
      {
        "url": "https://www.physicsforums.com/threads/new-climate-science-update-latest-findings-since-2006-report.358328/",
        "raw_content": "New Climate Science Update: Latest Findings Since 2006 Report \u2022 Physics Forums\nChemistry\nBiology and Medical\nEarth Sciences\nComputer Science\nComputing and Technology\nDIY Projects\nMenu\nLog in\nRegister\nNavigation\nMore options\nStyle variation\nContact us\nClose Menu\nJavaScript is disabled. For a better experience, please enable JavaScript in your browser before proceeding.\nYou are using an out of date browser. It may not display this or other websites correctly.\nYou should upgrade or use an\nalternative browser\n.\nForums\nOther Sciences\nEarth Sciences\nNew Climate Science Update: Latest Findings Since 2006 Report\nThread starter\nXnn\nStart date\nNov 27, 2009\nTags\nClimate\nScience\nAI Thread Summary\nRecent climate science updates reveal that CO2 emissions from fossil fuels have risen 40% since 1990, with a significant acceleration over the past 18 years. The latest findings indicate a more sensitive climate system than previously understood, with global temperatures and sea levels expected to rise more rapidly. Evidence shows that every year since 2001 has ranked among the warmest on record, and the melting of glaciers and ice caps is contributing increasingly to sea level rise. The report emphasizes the urgent need for improved communication of scientific findings to bridge the gap between science and public policy. Overall, the findings underscore the critical state of climate change and the potential for irreversible impacts if current trends continue.\nXnn\n554\n0\nScience marches on.\nThe http://www.ipcc.ch/publications_and_data/publications_ipcc_fourth_assessment_report_wg1_report_the_physical_science_basis.htm\" for climate change was based on\npeer reviewed literature available in 2006. Since that time,\nthere have been a number of newer studies that have contributed\nto a better understanding. These have been put together into a\nhttp://www.ccrc.unsw.edu.au/Copenhagen/Copenhagen_Diagnosis_LOW.pdf\" for the meeting in Copenhagen.\nIn general, uncertainties resolved since 2006 point to a more\nrapidly changing and more sensitive climate than previously thought.\nThere are several interesting sections in the report with lots of vivid\ncolor photos. However, overall it is a sombering report.\nCO2 emissions are accelerating while temperatures, sea level and\nwater cycle increases are all expected to accelerate.\nIt's very difficult to conceive the climate tracking anything but\nthe upper end of the projections.\nHere are highlights from the new report:\nGlobal carbon dioxide (CO2) emissions from fossil fuel burning in 2008 were 40%\nhigher than those in 1990, with a three-fold acceleration over the past 18 years.\nGlobal CO2 emissions from fossil fuel burning are tracking near the highest scenarios\nconsidered so far by the IPCC.\nThe fraction of CO2 emissions absorbed by the land and ocean CO2 reservoirs has likely\ndecreased by ~5% (from 60 to 55%) in the past 50 years, though interannual variability is\nlarge.\nGlobal air temperature, humidity and rainfall trend patterns exhibit a distinct fingerprint\nthat cannot be explained by phenomena apart from increased atmospheric greenhouse gas\nconcentrations.\nEvery year this century (2001-2008) has been among the top 10 warmest years since\ninstrumental records began, despite solar irradiance being relatively weak over the past few\nyears.\nGlobal atmospheric temperatures maintain a strong warming trend since the 1970s\n(~0.6\u00b0C), consistent with expectations of greenhouse induced warming.\nIncreases in hot extremes and decreases in cold extremes have continued and are expected\nto amplify further.\nIce-shelves connect continental ice-sheets to the ocean. Destabilization of ice-shelves\nalong the Antarctic Peninsula has been widespread with 7 collapses over the past 20 years.\nSigns of ice shelf weakening have been observed elsewhere than in the Antarctic Peninsula,\ne.g. in the Bellingshausen and Amundsen seas, indicating a more widespread influence of\natmospheric and oceanic warming than previously thought.\nThere is a strong influence of ocean warming on ice sheet stability and mass balance via the\nmelting of ice-shelves. Anthropogenic climate change is expected to lead to further increases\nin precipitation extremes, both increases in heavy precipitation and increases in drought.\nAlthough future changes in tropical cyclone activity cannot yet be modeled, new analyses\nof observational data confirm that the intensity of tropical cyclones has increased in the\npast three decades in line with rising tropical ocean temperatures.\nThere is widespread evidence of increased melting of glaciers and ice-caps since the mid\n1990s.\nThe contribution of glaciers and ice-caps to global sea-level has increased from 0.8\nmillimeters per year in the 1990s to be 1.2 millimeters per year today.\nThe adjustment of glaciers and ice caps to present climate alone is expected to raise sea\nlevel by ~18 centimeters. Under warming conditions they may contribute as much as ~55\ncentimeters by 2100\nThe surface area of the Greenland ice sheet which experiences summer melt has increased\nby 30% since 1979, consistent with warming air temperatures. Melt covered 50% of the ice\nsheet during the record season in 2007.\nThe net loss of ice from the Greenland ice sheet has accelerated since the mid-1990s and is\nnow contributing as much as 0.7 millimeters per year to sea level rise due to both increased\nmelting and accelerated ice flow.\nAntarctica is also losing ice mass at an increasing rate, mostly from the West Antarctic ice\nsheet due to increased ice flow. Antarctica is currently contributing to sea level rise at a\nrate nearly equal to Greenland.\nThe observed summer-time melting of Arctic sea-ice has far exceeded the worst-case\nprojections from climate models of IPCC AR4.\nThe warming commitment associated with existing atmospheric greenhouse gas levels means\nit is very likely that in the coming decades the summer Arctic Ocean will become ice-free,\nalthough the precise timing of this remains uncertain.\nSatellite observations show a small increase of Antarctic sea-ice extent and changes to\nseasonality, although there is considerable regional variability. This is most likely due to\nchanges in Southern Ocean winds associated with stratospheric ozone-depletion.\nEstimates of ocean heat uptake have converged and are found to be 50% higher than\nprevious calculations.\nGlobal ocean surface temperature reached the warmest ever recorded for each of June, July\nand August 2009.\nOcean acidification and ocean de-oxygenation have been identified as potentially\ndevastating for large parts of the marine ecosystem.\nSatellite measurements show sea-level is rising at 3.4 millimeters per year since these\nrecords began in 1993. This is 80% faster than the best estimate of the IPCC Third\nAssessment Report for the same time period.\nAccounting for ice-sheet mass loss, sea-level rise until 2100 is likely to be at least twice as\nlarge as that presented by IPCC AR4, with an upper limit of ~2m based on new ice-sheet\nunderstanding.\nThere are several elements in the climate system that could pass a tipping point this century\ndue to human activities, leading to abrupt and/or irreversible change.\n1 \u00b0C global warming (above 1980-1999) carries moderately significant risks of passing large\nscale tipping points, and 3 \u00b0C global warming would give substantial or severe risks.\nThere are prospects for early warning of approaching tipping points, but if we wait until a\ntransition begins to be observed, in some cases it would be unstoppable.\nThe full report is available here:\nhttp://www.copenhagendiagnosis.com/default.html\nLink directly to pdf file:\nhttp://www.ccrc.unsw.edu.au/Copenhagen/Copenhagen_Diagnosis_LOW.pdf\nLast edited by a moderator:\nMay 4, 2017\nEarth sciences news\non Phys.org\nBlowing from the north, winds emerge as key driver of Antarctic ice loss\nThe role of nanoscale crystals in volcanic eruptions\nHow uneven ocean warming is altering propagation of the Madden-Julian Oscillation\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nI have to say I hate this kind of semi-scientific-political publi-brochure. This kind of stuff is exactly what makes people wary of climate science. This looks like an advertisement !\nThat doesn't mean that what's said in there is wrong, but I don't like the commercial way in which it is said.\nJust some things on the surface that shock me:\nFrom the first grey box, in fact the very first sentence of the report:\nGlobal carbon dioxide (CO2) emissions from fossil fuel burning in 2008 were 40% higher\nthan those in 1990,\nwith a three-fold acceleration over the past 18 years\n.\nThere is also:\nCO2 levels increased at a rate of 1.9 ppm/year between\n2000 and 2008, compared to 1.5 ppm/yr in the 1990s.\nNow how does that rime with figure 2, where we see an almost linear rise of CO2 in the atmosphere since 1980 ?\nIt seems to me that especially alarming language is used here, as if one had to promote a certain product.\nSorry!\n416\n0\nvanesch said:\nI have to say I hate this kind of semi-scientific-political publi-brochure. This kind of stuff is exactly what makes people wary of climate science. This looks like an advertisement !\nThat doesn't mean that what's said in there is wrong, but I don't like the commercial way in which it is said.Just some things on the surface that shock me:\nFrom the first grey box, in fact the very first sentence of the report:There is also: Now how does that rime with figure 2, where we see an almost linear rise of CO2 in the atmosphere since 1980 ?\nIt seems to me that especially alarming language is used here, as if one had to promote a certain product.\nIt is kinda of a weird way of them to promote their findings though (in a brochure) but we have to think about who this is trying to sway... the common person. This isn't really meant for scientists to use it's meant to be a political tool (which I admit isn't the best thing but nearly all science has political aspects, climate change just has more due to its seeming importance to the world)\nLast edited:\nNov 27, 2009\nsylas\nScience Advisor\n1,647\n9\nvanesch said:\nI have to say I hate this kind of semi-scientific-political publi-brochure. This kind of stuff is exactly what makes people wary of climate science. This looks like an advertisement !\nThat doesn't mean that what's said in there is wrong, but I don't like the commercial way in which it is said.\nMy reaction is completely the reverse. The problem with this whole area is that there is a lot of public interest and a lot of confusion.\nIf we were serious about simply following the scientific literature, then it would be pretty straight forward and you'd get conclusions pretty much like what is in this report.\nHowever, the scientific literature is written primarily for a different audience. And although the science should be pursued independent of any policy considerations; the reverse is not the case; policy needs to take into account the best available scientific information on matters of relevance.\nIt follows that there is a need for scientists to communicate better, to a wider audience; not just the general public but governments and other policy makers. The IPCC reports are driven by this requirement.\nThe interaction between science and politics and policy, in any ideal world, should be like the following:\nThe conclusions reached by science need to be obtained without any deference to policy implications of the conclusions. Science ideally seeks answers and confidence limits on those answers based exclusively on what the evidence and research actually can show.\nThe questions and issues addressed by scientists, however, might well be driven by secondary requirements of what is deemed important to know, for policy reasons.\nPrecisely how we improve the communication of credible science is a good question; but anything you do along those lines should be in the way of providing accessible information.\nI think this only looks like an advertisement because there is such a gaping disconnect between what is happening in the world of science and what is being debated in the political world. There are a heap of open questions in climate science and all kinds of large uncertainties. But they are not the same as the major uncertainties debated more widely.\nThe wider questions seem to be things like... is global warming real? is it caused by human activities?\nThe answers to those two questions are actually very straightforward. It's yes, and yes.\nThere are riders you can add, along the lines that everything in science is always in principle open to dispute and revision; but for an overview, the \"yes\" in both cases is about as strong as you can possibly get. The warming is measured. The importance of greenhouse effects is basic physics. And the association of that to human activities is unambiguous.\nThese answers don't rule out all other factors; but the strong warming trend of the latter half of the twentieth century in particular is solidly linked to atmospheric composition and a stronger greenhouse effect.\nThe relevant open scientific questions are about quantifying the warming trend, along with other effects, refining physical understanding to model it better (a never ending project of continual improvements) and sorting out things like the carbon cycle, the energy balance into the ocean, the feedbacks from cloud and weather and much else beside which bear upon the complex response of the climate system.\nvanesch said:\nJust some things on the surface that shock me:\nFrom the first grey box, in fact the very first sentence of the report:\nGlobal carbon dioxide (CO2) emissions from fossil fuel burning in 2008 were 40% higher than those in 1990, with a three-fold acceleration over the past 18 years.[/color]\u200b\nThere is also:\nCO2 levels increased at a rate of 1.9 ppm/year between 2000 and 2008, compared to 1.5 ppm/yr in the 1990s.[/color]\u200b\nNow how does that rime with figure 2, where we see an almost linear rise of CO2 in the atmosphere since 1980 ?\nIt seems to me that especially alarming language is used here, as if one had to promote a certain product.\nI don't understand your objection here, frankly. The context of this report is a world that is looking at managing carbon emissions as a matter of policy to mitigate against the risks associated with larger changes in the atmospheric greenhouse effect. The report is promoting the need for managing emissions and noting that they are continuing to increase at levels that are right along the high end of the range of projections considered in the most recent IPCC report.\nFigure 2 is completely consistent with the numbers given. The rate of increase IS increasing and you can see quite easily that the increase since 1980 is not linear. Just hold a ruler up against the graph if you want to check. Of course, the proper measure of linearity works from the numbers, not eyeballing a graph, and the numbers are as you have quoted from the report. What\u2019s the problem?\nThere are a number of other sources that are attempting to address the gap between what is published in the literature and what is accessible to policy matters or interested members of the public. Not all of them are thoroughly grounded in the scientific literature or well reviewed by directly relevant scientific researchers. This one is, however; and stands as a good summary of technical material, thoroughly grounded in scientific literature, produced by a large group of some of the most active scientists researching on the directly relevant science, and with a high level of oversight and review. I think it stands as a useful resource for helping follow this whole topic.\nCheers -- sylas\nsylas\nScience Advisor\n1,647\n9\nA better link\nBy the way... the home page for this report\nThe Copenhagen Diagnosis\n\u200b\ngives easy access to the full report at two resolution levels, an online version, background on the authors, background on the reasons for the report, and so on; which may help understand some of the background to why and how it was written.\nLast edited:\nNov 28, 2009\nXnn\n554\n0\nFrom the report:\nGlobal carbon dioxide (CO2) emissions from fossil fuel burning in 2008 were 40%\nhigher than those in 1990, with a three-fold acceleration over the past 18 years.\nGlobal CO2 emissions from fossil fuel burning are tracking near the highest scenarios\nconsidered so far by the IPCC.\nvanesch said:\nNow how does that rime with figure 2, where we see an almost linear rise of CO2 in the atmosphere since 1980 ?\nIt seems to me that especially alarming language is used here, as if one had to promote a certain product.\nI agree that there is some alarming language in the report. However, the prospects\nof significant reductions in emissions are fairly low. As the report points out, emissions\nhave only increased and I sense that the Climate Scientist that put the\nreport together are very concerned and frustrated. It's apparent that there\nwill be a significant climate shift over the next century.\nAnyhow, I also struggle with reconciling the 3 fold acceleration in emissions\nsince 1990 while atmospheric CO2 concentrations have increased steadily\nwith only the slightest hint of an acceleration.\nFrom the report:\nThe global rate of increase of fossil fuel CO2 emissions has accelerated\nthree-fold over the last 18 years, increasing from 1.0% per year in the 1990s to\n3.4% per year between 2000-2008 (Figure 1). The accelerated growth in fossil\nfuel CO2 emissions since 2000 was primarily caused by fast growth rates in developing\ncountries (particularly China) in part due to increased international trade of goods\n(Peters and Hertwich 2008), and by the slowdown of previous improvements in the CO2\nintensity of the global economy (Raupach et al. 2007). The observed acceleration in fossil fuel CO2 emissions is tracking high-end emissions scenarios used by IPCC AR4 (Nakicenovic et al. 2000).\nThe report does reviews CO2 sinks, but jumps rather abruptly to vulnerabilities.\nWhat's obvious to me is that the sinks have increased almost as fast as emission\nhave grown. That is rather odd. Sinks ought to be operating in proportion to\natmospheric CO2 concentration, precipitation and winds.\nThere are 3 major sinks: Plants & soils, the deep ocean and sediments (rocks).\nAbout 30% of CO2 emissions end up in plants and soils, 25% goes into the deep\nocean and <1% ends up in sediments.\nThe report makes the following statement concerning the deep oceans:\nIn the Southern Ocean, the CO2 sink has not increased since 1981\nin spite of the large increase in atmospheric CO2 (Le Qu\u00e9r\u00e9 et al. 2007;\nMetzl 2009; Takahashi et al. 2009). The Southern Ocean trends have been\nattributed to an increase in winds, itself a likely consequence of\nozone depletion (Lovenduski et al. 2008). Similarly, in the North\nAtlantic, the CO2 sink decreased by ~50% since 1990 (Schuster\net al. 2009), though part of the decrease has been associated\nwith natural variability (Thomas et al. 2008).\nSo, I can only infer that plants and soils have been taking most all\nof the slack; in other words there is some good news that may\nhave been overlooked.\nsylas\nScience Advisor\n1,647\n9\nXnn said:\nAnyhow, I also struggle with reconciling the 3 fold acceleration in emissions\nsince 1990 while atmospheric CO2 concentrations have increased steadily\nwith only the slightest hint of an acceleration.\nOn the contrary. The rate of atmospheric CO\n2\nincrease has accelerated as emissions have accelerated. Remember to to look at the percentage change in the rate of increase; not merely the increase itself.\nThe major CO\n2\nobservatory is the\nNOAA monitoring station at Mauna Luo\n. It provides ready access to most recent measurements and rates of change, both for the Mauna Luo site itself and a global estimate.\nThe rate of increase varies from year to year; as short term variations that arise from any changes in the global carbon cycle. Over all there is a significant increasing trend in the rate of increase, and a 10 year moving average (for example) shows the rate increasing from around 1.5 ppm/yr to around 1.9 ppm/yr as described in the report. This is a more than a slight hint of acceleration. It is about 27%, though with limited precision.\nThe data for emissions is cited to Le Qu\u00e9r\u00e9 et al. (2009) which is listed as in press, though it has just now come out as advance online publication. See\nCorinne Le Qu\u00e9r\u00e9 et al (2009)\nTrends in the sources and sinks of carbon dioxide\n,\nNature Geoscience\n, Published online: 17 November 2009 | doi:10.1038/ngeo689\nPreprint available http://www.civicgovernance.ca/files/uploads/Global_CO2_per_capita_report.pdf[/URL].[/list]\nThis has been on my to-do list to write about, as it is particularly relevant to another recent thread on carbon cycles.\nThis paper notes in the abstract that \"fossil fuel emissions increased by 29% between 2000 and 2008\", and the text notes an increase of 41% since 1990, as given in the report discussed in this thread. The supplementary information of the paper points us to [url=http://www.globalcarbonproject.org]globalcarbonproject[/url] for the emissions data; also tabulated [url=http://lgmacweb.env.uea.ac.uk/lequere/co2/carbon_budget.htm]here[/url].\n1990 was 6.14 Pg emissions; 2008 was 8.67. The uncertainties are around 6%. This is the 41% increase.\nThere link from emissions to increasing atmospheric levels is surprising complex; but to a first approximation about 40% of emissions remain in the atmosphere.\nIn any case, the increase in atmospheric CO[sub]2[/sub] is from about 1.5 ppm/yr to 1.9 ppm/yr: around 27%, but with a substantially larger uncertainty given the natural variations on top of the trend.\nThis is not a discrepancy; we are measuring two different things, which are strongly related, but should not be expected to simply have the same value.\nCheers -- sylas\nPS. Xnn, you'd be interested in Le Qu\u00e9r\u00e9 et al (2009). It is looking at all those details of sources and sinks in the carbon cycle.\nLast edited by a moderator:\nMay 4, 2017\nmheslep\nGold Member\n364\n719\nsylas said:\n1990 was 6.14 Pg emissions; 2008 was 8.67. The uncertainties are around 6%. This is the 41% increase.\nThere link from emissions to increasing atmospheric levels is surprising complex; but to a first approximation about 40% of emissions remain in the atmosphere.\nIn any case, the increase in atmospheric CO\n2\nis from about 1.5 ppm/yr to 1.9 ppm/yr: around 27%, but with a substantially larger uncertainty given the natural variations on top of the trend.\nThis is not a discrepancy; we are measuring two different things, which are strongly related, but should not be expected to simply have the same value...\nI wonder where the balance of the CO2 emissions go - some to the oceans but surely not all?\nsylas\nScience Advisor\n1,647\n9\nmheslep said:\nI wonder where the balance of the CO2 emissions go - some to the oceans but surely not all?\nSome goes to terrestrial carbon sinks. It all has to go somewhere, and \"land/ocean/atmosphere\" is a simple classification of the many sinks involved.\nWithin this broad classification there are all kinds of sinks and many unknowns. The ocean is a number of different regional oceans, which are not uniform, and involves exchanges over all depths, which are not clear. The land sinks are especially hard to figure out. Generally speaking the fraction of carbon that is taken up into the terrestrial sinks is estimated by seeing what is left over after the atmosphere and oceans are considered. There are attempts to further identify where the various terrestrial sinks can be found; but there's no complete accounting and no way to get a direct measurement of all the land sinks. Some wag once described this as the \"missing sink\", which now makes a good search term to get started finding relevant research.\nThe \"airborne fraction\" is the best known; it is around 40% to 45%. That leaves 55% to 60% for other sinks. Page 12 of this report gives a quick summary. The paper by Le Qu\u00e9r\u00e9 that I have cited is an important contribution and there is a lot more research on this if you want to keep hunting. From Le Qu\u00e9r\u00e9 (2009):\nCombined evidence from atmosphere and ocean observations constrains the mean uptake rates of land and ocean CO\n2\nsinks to 2.6\u00b10.7 and 2.2\u00b10.4 Pg C yr\n\u22121\nfor 1990\u20132000, respectively\n11,19\u201322\n.[/color]\u200b\nThe emissions amount includes both direct industrial emissions (which is what has increased by 41% since 1990) and also emissions from land use change, especially deforestation. Put together As noted previously direct emissions in 2008 were 8.67 Pg. To this we add about 1.2 Pg from land use change (an estimate from Le Qu\u00e9r\u00e9 2009) for 2008, giving 9.9 Pg total in 2008.\nThe atmospheric increase was 1.66 ppm in 2008, which you can simply multiply by 2.13 to get the atmospheric uptake of 3.54 Pg. This varies a lot from year to year, over recent years 1.9 ppm/yr is about the current rate; pretty close to 4 Pg.\nFurther breaking it all down is an ongoing open question; sorting out how all carbon cycle will continue to work as it keeps being loaded with carbon is also a major open question and significant uncertainty. The \"airborne fraction\" is about 43%, and most research indicates this is increasing. This is described in the Copenhagen Diagnosis; and more detail is in Le Qu\u00e9r\u00e9 (2009).\nOn average, 43% of the total CO2 emissions each year between 1959 and 2008 remained in the atmosphere, but this fraction is subject to very large year-to-year variability (Fig. 2a). This \u2018airborne fraction\u2019 increased on average by 0.3\u00b10.2% yr\n\u22121\nbetween 1959 and 2008. There is a 90% probability that this increasing trend is significant taking into account the background variability (Methods). The trend and its significance are sensitive to estimates of LUC emissions, which have large uncertainties.\u200b\nIt seems likely that the trend of an increasing airborne fraction will continue.\nLast edited:\nNov 28, 2009\nXnn\n554\n0\nSylas;\nThanks for the link to the Le Qu\u00e9r\u00e9 paper. I see that she notes the problems\nof quantifying sinks and also explains how economic data is used to measure\nemissions along with a host of other estimates. So, there is considerable\nuncertainty with all of this.\nHer charts show both land and ocean sinks trending more negative,\nalthough in 2008 there was a small up tick in ocean sinks due to La Ni\u00f1a\nand the southern annular mode:\nDuring La Ni\u00f1a conditions, the land CO2 sink is enhanced owing to lower\ntemperatures and wetter conditions in the tropics, whereas the ocean\nCO2 sink is reduced owing to more intense equatorial upwelling of carbon-rich\nwaters. Observations in the equatorial Pacific Ocean corroborate the lower ocean\nCO2 sink in 2008 (ref. 23) estimated by the models. The ocean models also\nattributed the low ocean CO2 sink in 2008 in part to a weaker Southern Ocean\nsink, in response to the continuing increase in the southern annular mode.\nAnyhow, it's curious that the sinks are trending towards more negative values\nand I wonder if maybe perhaps the GDP method of estimating emissions is biased\nas the residual chart (figure 2 e) appears to generally be accumulating.\nLast edited:\nNov 28, 2009\nNaty1\n5,605\n40\nSylas posted:\nThe wider questions seem to be things like... is global warming real? is it caused by human activities?\nThe answers to those two questions are actually very straightforward. It's yes, and yes.\nNice try; but such speculation is political in nature not scientific...38,000 scientists (who signed correspondence to the UN) and others who wrote the US congress strongly disagree about man made causes of climate change.\nEven in Australia, home of the uopdated report referenced by Silas, government there remains in turmoil over man made global warming and carbon reduction plans. The Australian senate appears likely to reject such legislation for plans passed by their house.\nThe legitimate answers to those two questions is ACTUALLY dependent on valid data, valid scientific theory, and models that work...NOT what East Anglica \"scientists\" concocked/invented/created fraudulently for the IPCC.\nThe Earth IS likely warming, just like it has thousands of times in the past...but the Earth has emerged from numerous ice ages, some when the Earth was virtually covered in mile thick ice...and it will most likely cool as well in the future, also repeating past changes long before man was here.\nOne recent recent study shows that infrared radiation from a cabon thick(er) atmosphere actually increases, not decreases, as climate models would have you believe. So there is much left to learn before we declare \"victory\" in our understanding of climate...besides, whose to say that a warmer climate would not be a big net plus? The Vikings, who tried to settle Greenland when it was previously warm enough to be productive for farming, would likely have argued HOORAY for some warming...\nLast edited:\nNov 28, 2009\nsylas\nScience Advisor\n1,647\n9\nXnn said:\nThanks for the link to the Le Qu\u00e9r\u00e9 paper. I see that he notes the problems...\nThat's \"she\", for what it is worth.\nhttp://lgmacweb.env.uea.ac.uk/lequere/\nis Professor of Environmental Sciences at the University of East Anglia. Her home page has some good further links.\nAnyhow, it's curious that the sinks are trending towards more negative values\nand I wonder if maybe perhaps the GDP method of estimating emissions is biased\nas the residual chart (figure 2 e) appears to generally be accumulating.\nYes, it is interesting; the residuals are large, which is a good indication of how much still is unknown about the carbon cycle.\nI don't think GDP is used to estimate emissions. The connection between GDP and emissions is an observation given the data on each one, and the paper speaks of a need to decouple this observed relationship. Emissions are estimated from energy statistics, according to the associated\nhttp://lgmacweb.env.uea.ac.uk/lequere/co2/carbon_budget.htm\nwebste, same link as I gave previously for the tabulation of data used in this paper.\nAll the charts in figure 2 have error bars indicated. The largest uncertainties are associated with carbon sinks on the land; both the indirect emissions (figure 2a) from land use changes and the highly uncertain terrestrial sinks (figure 2c).\nThe residual is basically a count of how much carbon is missing after they add up the emissions and the estimates for sinks. The comment in the paper itself is:\nOur estimates of sources and sinks of CO\n2\nwere based on largely independent data and methods. Thus, when all the sources and sinks were summed every year they did not necessarily add to zero, because of the errors in the various methods. The sum of all CO\n2\nsources and sinks, which we call the \u2018residual\u2019, spanned a range of \u00b12.1 Pg C yr\n\u22121\n(Fig. 2e). This residual was not explained by the atmospheric CO\n2\ngrowth rate, the CO\n2\nemissions from fossil fuel combustion or the ocean uptake, because the uncertainties in these components were much smaller than the variability of the residual. Errors in LUC flux may explain a small part of the residual, for instance during the late 1990s, when fires in Indonesia were partly caused by land clearance taking advantage of the drought conditions\n17\n. Our fire-based LUC anomalies for 1997 were 0.7 Pg C greater than normal and account for one-half of the residual for that year. Overall, the residual was most probably caused by the regional responses of terrestrial vegetation to climate variability, indicating that land models overestimated the response of vegetation to the relatively cool/wet La Ni\u00f1a-like climatic conditions of the mid 1970s and underestimated the response to the volcanic eruption of Mount Pinatubo, in the Philippines, in the early 1990s. This later underestimation has been explained elsewhere as resulting from a missing response in the models to the aerosol-induced increase in the diffuse-light component of surface irradiance, and the subsequent enhancement of light penetration into vegetation canopies\n29\n.[/color]\u200b\nFrom the tabulations, you can use a spread sheet to verify that in fact, the residuals are on average slightly positive with a small trend to being more positive; but of course they are all over the place in general. (Mean 0.273, sd 0.957) (Caution: the tabulation uses slightly different sign conventions to the diagram.) If the paper is correct in supposing that the greatest part of this is due to inaccuracies in estimating how vegetation is taking up CO\n2\n, it would mean that some years over estimate and other years underestimate the amount of carbon taken into this sink.\nA positive residual means either over estimated emission or (much more likely) underestimated sinks. Hence: \"missing sink\".\nCheers -- sylas\nLast edited by a moderator:\nApr 24, 2017\nMark44\nMentor\nInsights Author\n38,036\n10,507\nsylas said:\nCorinne Le Qu\u00e9r\u00e9 is Professor of Environmental Sciences at the University of East Anglia.\nThe home of the Hadley CRU, which has come under a serious cloud in the last week or two.\nMark44\nMentor\nInsights Author\n38,036\n10,507\nsylas said:\nThe Copenhagen Disagnosis\n\u200b\nFreudian slip?\nsylas\nScience Advisor\n1,647\n9\nMark44 said:\nThe home of the Hadley CRU, which has come under a serious cloud in the last week or two.\nThat's a classic ad hominem; and worse, an indirect smear. It's highly inappropriate.\nShe's not in the CRU. She's not in any of the emails, except in one case that was an enormous cc to hundreds of scientists all over the world. There's nothing linking her to anything in the whole CRU emails brouhaha. It isn't Hadley CRU, by the way. The Hadley Centre is part of the UK Met Office, a different thing entirely. It's a common confusion. And finally, although there are issues showing up in the hacked emails affair concerning how some CRU personnel responded to the excessive flood of FOI requests they were receiving, there is nothing there whatever to indicate anything wrong with the science.\nNone of the other co-authors to the paper are in the CRU either. Indeed, Le Quere is the only one of the 31 authors from the Uni of East Anglia. The others come from all over the world, and their contributions and affiliations are in the paper.\nIf you think there's a science issue, then that might be something for this forum, in a different thread I would suggest. Matters of policy and politics, such as how to deal with FOI or adequate openness with data and so on belong in the\nPolitics and World Affairs\nforum.\nI do understand that people are concerned, and want to have questions answered in relation to the hacked files. I have chosen to be firm to underline that this is actually very serious. Accusations of fraud, or malfeasance, or scientific misconduct, are serious matters. It's not okay just to slip in an insinuations like this in a public forum without some credible basis. Being at the same university doesn't count. Heck; even the emails don't count for much; though that's a different subject for the other forum since it isn't actually about the quality of the science itself. The thread to use at present is [thread=355595]this one[/thread] that is mainly about the hacked files affair.\nAlso, thanks for picking up my Freudian slip. I've fixed it!\nCheers -- Sylas.\nPS. How many Freudian psychologists does it take to change a light bulb?\nAnswer: Two. One to fit the new bulb, and another to hold my p... THE LADDER. I mean the ladder.\nLast edited:\nNov 28, 2009\nXnn\n554\n0\nNaty1 & Mark44;\nThere is clearly a heated political debate concerning what to do about\nglobal warming and that is all well and good. However, the science is\nrobust enough that attempts to suggest that CO2 emissions are not\nat the root of it fall short of being credible.\nsylas\nScience Advisor\n1,647\n9\nNaty1 said:\nsylas said:\nThe wider questions seem to be things like... is global warming real? is it caused by human activities?\nThe answers to those two questions are actually very straightforward. It's yes, and yes.\nNice try; but such speculation is political in nature not scientific...\nIt is not speculation. It is not political. It is basic science independent of any political or policy concerns, based on measurement and elementary physics, and not in any credible scientific dispute. It is a starting point for looking at all the many more interesting open questions in climate science that are now a focus of active research and investigation. It is also a good starting point for the goal of basic science education, which is what I see as the main role of physicsforums.\nThese two points don't resolve the big political questions surrounding climate; but they do form a kind of basic solid ground that can be used no matter what your political or policy preferences.\nMeasuring global warming\nThe measurement of temperature increase can be seen in multiple independent research efforts, and they all give the same result to within measurement accuracies; a strong overall warming trend over the twentieth century, becoming particularly strong since about 1975, generally stronger over the land than the ocean. There is no published research indicating this is incorrect or giving any substantially different result. It really ought to be an elementary starting point for the scientific discussions of how the warming trend is measured, what values can be given to it, what causes it, how it is distributed regionally, and so on.\nReferences:\nHadCRUT3 dataset; described in Brohan, P. et. al. (2006) http://www.agu.org/pubs/crossref/2006/2005JD006548.shtml, in\nJ. Geophysical Research\n111, D12106, doi:10.1029/2005JD006548.\nPdf preprint http://www.cru.uea.ac.uk/cru/data/temperature/HadCRUT3_accepted.pdf .\nGISS dataset; described in Hansen, J., et. al. (2006) http://www.pnas.org/content/103/39/14288, in PNAS 103, pp 14288-14293, doi:10.1073/pnas.0606291103.\nPreprint\nhere\n; data downloads, including summaries and full gridded data:\nat Goddard Institute for Space Sciences\n, NASA.\nNOAA/NCDC dataset; described in Smith, T.M., and Reynolds R.W. (2005),\nA global merged land air and sea surface temperature reconstruction based on historical observations (1880-1997)\n, in\nJ. Climate\n, 18(12), pp 2021-2036, doi:10.1175/JCLI3362.1\nPdf preprint http://lwf.ncdc.noaa.gov/oa/climate/research/Smith-Reynolds-dataset-2005.pdf .\nThe cause of warming\nThe measured warming trend is substantial, and has a cause. There have been many factors that are involved in the changes of global temperature over Earth's long history. The change in this specific instance is primarily from an enhanced atmospheric greenhouse effect; and that is being driven by human activities.\nThere are still many open questions about quantifying the temperature response of Earth to the changing energy balance. It is a solid discovery, however, that human activities have made a substantial change to the Earth's atmosphere, and this has substantially increased the atmospheric greenhouse effect. The factors the drive changing temperatures are called forcings; and all the research that actually quantifies these gives the same result; anthropogenic greenhouse effect is the dominant factor over the twentieth century and especially in the latter half, where we have the best measurements and the strongest warming.\nReferences:\nMeehl, G.A. et al., (2004)\nCombinations of Natural and Anthropogenic Forcings in Twentieth-Century Climate\n, in\nJournal of Climate\n19, 3721-3727, doi: 10.1175/1520-0442(2004)017<3721:CONAAF>2.0.CO;2. Pdf preprint\nat UCAR\n.\nTett, S.F.B et. al. (2007)\nThe impact of natural and anthropogenic forcings on climate and hydrology since 1550\n, in\nClimate Dynamics\n, 28(1), pp 3-24, doi:10.1007/s00382-006-0165-1.\nIt would be easy to go on; but my aim is not to simply overwhelm with references. The point is that the answers to these two rather basic questions that I am giving are not politics, but really are science. Furthermore the confidence given in these answers is very high.\nThere are other questions, such as estimates of sensitivity, or details of the carbon cycle, or all kinds of other things, where the literature will be expressed quite cautiously and with acknowledgment of large uncertainties.\nThe two questions I have proposed, however, are not really in that category. They are legitimately discoveries; and a backdrop to all the truly open questions. Everything in science is in principle open to question and revision; you never get absolute certainty in anything. But IMO there's really not any credible prospect of getting these questions answered with any meaningful additional confidence -- only with more precision.\nI appreciate that there are many people who are skeptical of the answers I have given to these two questions. The question is -- is there any actual scientific basis for withholding basic assent to these answers? If so, then given the guidelines for the forum, you should provide some peer reviewed reference, or credible equivalent, and we can look at the scientific case on its own merits. I don't think there is any such literature except possibly a handful of isolated and minimal impact papers of dubious worth on their own immediate merits; but I truly am interested and open to suggestions if you disagree. Just make sure that they do address the questions at issue; and not some other less strongly constrained matter.\nOther matters\nIn your post, you raise a number of further peripheral matters that I think would be better taken up elsewhere, if at all. I am quoting extracts; linked back to the original as usual.\nNaty1 said:\n... 38,000 scientists ... strongly disagree about man made causes of climate change.\nEven in Australia ... government there remains in turmoil over man made global warming ...\nThe legitimate answers to those two questions is ACTUALLY dependent on valid data, valid scientific theory, and models that work...NOT what East Anglica \"scientists\" concocked/invented/created fraudulently for the IPCC.\nThe Earth IS likely warming, just like it has thousands of times in the past...\nOne recent recent study shows ... ...besides, whose to say that a warmer climate would not be a big net plus?...\nThe petition you allude to is notorious; and further discussion on that belongs in the politics forum. The implosion of our liberal party over climate issues would be very relevant in the politics forum. There is no indication whatever of invalid data or theory in the CRU hack affair, but discussion of that belongs in the politics forum. Your comment that the Earth likely IS warming appears to be agreement with my first point; if you can just recognize that this is actually a measurement. Changes in the past and in the future, for all kinds of reasons, are not in dispute. This says nothing about the specifics of what in particular is driving the change in the present. Your recent study requires a citation. It may well be a paper I have recently blogged about, along with three others in my PF blog as https://www.physicsforums.com/blog.php?b=1493 . If so, it has been discussed here before; but I'm very familiar with it and happy to consider it again in the main forums. The question of whether changes in climate are \"good\" or \"bad\" is another irrelevancy to the scientific question raised here; let's not have politics or policy distort consideration of scientific answers to the two questions.\nCheers -- sylas\nLast edited by a moderator:\nMay 4, 2017\nMark44\nMentor\nInsights Author\n38,036\n10,507\nXnn said:\nNaty1 & Mark44;\nThere is clearly a heated political debate concerning what to do about\nglobal warming and that is all well and good. However, the science is\nrobust enough that attempts to suggest that CO2 emissions are not\nat the root of it fall short of being credible.\nThere is also a scientific debate about whether the Earth is warming at all, with some climate scientists predicting a major cooling period in the next 20 years in their peer-reviewed paper (Zhen-Shan, L. and S. Xian. 2007. Multi-scale analysis of global temperature changes and trend of a drop in temperature in the next 20 years. Meteorology and Atmospheric Physics, 95, 115\u2013121.)\nFor science that is supposedly \"robust\" there are certainly lots of scientifically trained people who aren't buying it. The Global Warming Petition Project (\nhttp://www.petitionproject.org\n) has had over 30,000 signers, of which over 9,000 hold PhDs. The following is one of the two paragraphs that make up this petition.\n\u201cThere is no convincing scientific evidence that human release of carbon dioxide,\nmethane, or other greenhouse gasses is causing or will, in the foreseeable future, cause\ncatastrophic heating of the Earth\u2019s atmosphere and disruption of the Earth\u2019s climate.\nMoreover, there is substantial scientific evidence that increases in atmospheric carbon\ndioxide produce many beneficial effects upon the natural plant and animal environments\nof the Earth.\u201d\u200b\nInformation about the signers includes their professions, broken down as follows (I have rounded the numbers)\natmospheric, environmental, or Earth sciences - 3800\nmathematics or computer science - 900\nphysics and aerospace sciences - 5800\nchemistry - 4800\nbiology and agriculture - 3000\nmedicine - 3000\nengineering and general science - 10,000\nThe academic credentials of the signers are broken down by degrees attained, with ~9000 PhDs, ~7000 MS, ~2600 MD or DVM, and ~12,700 BS or equivalent.\nGranted, science is not and should not be a democratic process, so the numbers for and against a particular theory are for the most part irrelevant. My point is that for science that is \"settled\" there sure are a lot of people who don't think so.\nsylas\nScience Advisor\n1,647\n9\nMark44 said:\nThere is also a scientific debate about whether the Earth is warming at all, with some climate scientists predicting a major cooling period in the next 20 years in their peer-reviewed paper (Zhen-Shan, L. and S. Xian. 2007. Multi-scale analysis of global temperature changes and trend of a drop in temperature in the next 20 years. Meteorology and Atmospheric Physics, 95, 115\u2013121.)\nExcellent... a valid reference. I am genuinely interested in this and appreciate the link; I have found the paper and had a look at it.\nLin Zhen-Shan and Sun Xian (2007)\nMulti-scale analysis of global temperature changes and trend of a drop in temperature in the next 20 years\n, in\nMeteorology and Atmospheric Physics\n, Vol 95, Iss 1-2, pp 115-121, doi:10.1007/s00703-006-0199-2\nAlso http://www.crikey.com.au/Media/docs/Zhen-Shan--Xiuan-MeteorAtmosPhys-2007-d1227bc1-3183-456f-a935-69c263af1904.pdf .\nThe method used is a kind of curve fitting process called \"Empirical Mode Decomposition\". This is similar to Fourier analysis, but it is performed in the time domain. I had not heard of it before, but it certainly looks very interesting indeed. There seems to be significant interest in this technique, and I am going to look at it more carefully and consider using it myself as possible analysis method.\nA good reference to explain the method (and more readable) is:\nZhaohua Wu, Norden E. Huang, Steven R. Long, and Chung-Kang Peng (2007)\nOn the trend, detrending, and variability of nonlinear and nonstationary time series\n, in PNAS 104(38), 18 Sep 2007, pp 14889\u201314894, doi:10.1073/pnas.0701020104.\nWu et al (2007) is a mathematical paper rather than a climate paper; but this publication uses the global temperature anomaly as an illustrative example, which makes it particularly relevant.\nProfessor Huang\nis the major developer of the method, which is also the basis for the\nHilbert-Huang transform\n.\nIn the process of looking at this I am now drafting a post that may be better in a thread of its own; but I want to post this much now to acknowledge a useful reference with thanks. This method, and both the papers, actually obtain pretty much the same underlying trend as the references I have given. Using this technique, it appears as a residual function after removing the \"stationary\" (quasi-periodic)\nintrinsic mode functions\n, which represent cyclic variations in the signal. The trend is not linear; but it gives the same total amount of warming as other methods I have cited above -- as we should expect, since this is still precisely the same physical measurements involved. That is, this is not new data. This is clear in both the references cited. Furthermore Lin and Sun (2007) explicitly identifies CO\n2\nas the major factor in the trend; ironically it therefore is\nalso\nanswering \"yes\" to the two questions I have proposed.\nThe point at issue is the added variance on top of the central trend from a multi-decadal cycle revealed in the analysis; and for which no physical cause is known -- as the reference itself makes clear. This variance is exceptionally large in the Sun and Lin paper, and hence leads them to propose the possibility of an extended but temporary fall in global temperatures in coming decades. The fall is explicitly temporary, as the multi-decadal variance, by definition, has no trend. There are reasons to be dubious of extending the analysis as a projection in this way; but I'll leave that to a subsequent post.\nThe Sun and Lin paper has not had much impact at all. The other paper gives a smaller magnitude for the multi-decadal cyclic component and no expectation of a fall in temperatures. Neither one, I suggest, can really be used to give a safe projection; but I'll take that up later.\nMark44 said:\nFor science that is supposedly \"robust\" there are certainly lots of scientifically trained people who aren't buying it. The Global Warming Petition Project [...]\nGranted, science is not and should not be a democratic process, so the numbers for and against a particular theory are for the most part irrelevant. My point is that for science that is \"settled\" there sure are a lot of people who don't think so.\nI don't dispute your final sentence; nor do I find it all that unusual. I know of several such cases like this, where science is disputed by a lot of people, including many who have some science training, despite the points at issue being considered settled by almost all the scientists actively working on it. However, why that occurs and to what extent is off topic for this thread, and indeed for this whole Earth forum.\nIf there are actual scientific arguments to raise, that can be done here; and as you note the numbers don't matter. As Einstein once famously remarked, in response to a pamphlet entitled\n100 Authors Against Einstein\n: \"If I were wrong, one would be enough.\"[/color]\nCheers -- sylas\nLast edited by a moderator:\nMay 4, 2017\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nsylas said:\nIt follows that there is a need for scientists to communicate better, to a wider audience; not just the general public but governments and other policy makers. The IPCC reports are driven by this requirement.\nScientific communication, especially towards the public, should have some soberness to it. Note that it's not only in climate science that a certain way of communicating in an advertisement-style works on my nerves ; I already had that feeling in my own original field of particle physics, when crazy claims of \"exploring the big bang\" and so on were made in order to advertise for the LHC for instance.\nI think in the long term, science wins by having some soberness to it - although immediate funding maybe not.\nThe interaction between science and politics and policy, in any ideal world, should be like the following:\nThe conclusions reached by science need to be obtained without any deference to policy implications of the conclusions. Science ideally seeks answers and confidence limits on those answers based exclusively on what the evidence and research actually can show.\nThe questions and issues addressed by scientists, however, might well be driven by secondary requirements of what is deemed important to know, for policy reasons.\nIndeed. That's my point. This report isn't at all like this, and it is what is disturbing me.\nPrecisely how we improve the communication of credible science is a good question; but anything you do along those lines should be in the way of providing accessible information.\nThe accessibility is not to be confused with trading emotion and rhetoric for complication.\nI think this only looks like an advertisement because there is such a gaping disconnect between what is happening in the world of science and what is being debated in the political world. There are a heap of open questions in climate science and all kinds of large uncertainties. But they are not the same as the major uncertainties debated more widely.\nNo, it looks like an advertisement because the same communication techniques are used as in advertisements: implicit associations (look at all the - beautiful, that's true - irrelevant, but emotionally loaded pictures that are scattered around the report (of dried-out trees in a desert and so on) ; look at all the emotionally engaging qualifiers used throughout the text. This report is not just trying to convey information,\nit is trying to convey a desire for action\n. Like a commercial is trying to convey a desire to buy or something and uses similar techniques.\nYou can see this by the imbalance between the statements. For instance, the *greening* of the Sahel and part of the Sahara is mentioned only very briefly (although scattered with \"drying out\" pictures). Even though it is said that this is probably an important effect, nowhere this is found in any conclusion. The fact that temperate regions might receive MORE precipitation is also not to rhyme with the general spirit of a barren, hot, dried-out world they want to sell. All this is pretty much \"advertisement language\". This is not \"popular science\" simplification.\nWhen you look at a pseudo-scientific ad for a new SUV, you might see similar things: some scientific data about emissions, rpm/couple, braking,... with scattered pictures of strong men on an adventurous trip in wild nature and pretty girls full of admiration, trying to convey the desire to buy such a car, by association with certain emotions. It's no different here.\nAndre\n4,310\n73\nvanesch said:\n...The fact that temperate regions might receive MORE precipitation...\nWhat does that imply for a previous discussion?\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nAndre said:\nWhat does that imply for a previous discussion?\nHigher levels of humidity in the atmosphere, of course\nsylas\nScience Advisor\n1,647\n9\nCommunicating Climate Science\nvanesch said:\nScientific communication, especially towards the public, should have some soberness to it.\nThere's a huge issue with how best to communicate scientific information to the wider public, and this is not actually a question of the science itself, but a matter of communications skills, or styles.\nIt is, to some extent, subjective; and in my view it is good to have a range of styles of communication in place. It's commonly held that the problem with science communication is precisely the reverse. It is often TOO dry and sober and dispassionate. But there you go.\nI don't actually agree with or even really understand your reaction in this case; but I don't think it is all that important. The aspects I like about this report are that it is clear and concise, and starts out each section with simple bullet points that speak directly to what is most relevant for the intended audience; and also that it tackles head on many of the common popular confusions and outright errors that plague the whole popular perceptions of climate science. It is also well referenced to all the conventional dry technical literature.\nNote that it's not only in climate science that a certain way of communicating in an advertisement-style works on my nerves ; I already had that feeling in my own original field of particle physics, when crazy claims of \"exploring the big bang\" and so on were made in order to advertise for the LHC for instance.\nI don't think that is a valid comparison. If there was anything actually \"crazy\" in this report, then I'd agree, and that is a question I am willing to take up on its own merits. Are there any valid concerns with content here, rather than with style? I mean that as a serious question. I appreciate that different people may have different preferences for style; but leaving that aside... I think the biggest reason a report like this is needed is that many people instinctively\nthink\nthere's something dubious or crazy or far fetched about the content.\nThis thread would be a good place to consider such issues on their own scientific merits.\nAs for sober scientists at the LHC... I can't resist. Did you like the\nLHC rap\n(youtube link)? I was very impressed with this communication effort. I was also impressed with how CERN reacted to the appalling book\nAngels and Demons\nby Dan Brown. (Some folks liked it as a book; but its not my style...) They made it an opportunity to tap into public interest and help people learn more about the science. See\nhttp://angelsanddemons.cern.ch/\n.\nYou can see this by the imbalance between the statements. For instance, the *greening* of the Sahel and part of the Sahara is mentioned only very briefly (although scattered with \"drying out\" pictures). Even though it is said that this is probably an important effect, nowhere this is found in any conclusion. The fact that temperate regions might receive MORE precipitation is also not to rhyme with the general spirit of a barren, hot, dried-out world they want to sell. All this is pretty much \"advertisement language\". This is not \"popular science\" simplification.\nPoint taken. The pictures are style and presentation; I grant that it won't be to everyone's taste. On the other hand, I personally think it is a reasonable reflection of the general conclusions being reached about likely impacts; valid as content. Of course, it is not presented simply as a conclusion in text but as a kind of indirect stylist accompaniment. I don't have a strong negative reaction to that. Popular presentations can and should consider the effective use of images to help convey a message... as long as the message itself remains sound.\nThe text doesn't actually use the adjective \"important\" of the Sahel; it uses \"rare\" (p43):\nPerversely, if the WAM circulation collapses, this could lead to wetting of parts of the Sahel as moist air is drawn in from the Atlantic to the West (Cook and Vizy 2006; Patricola and Cook 2008), greening the region in what would be a rare example of a positive tipping point.[/color]\u200b\nThe report seems to be a reasonable account of the risks associated with changing climate. There are more negative consequences than positive ones, and all of them are given with limited confidence. It is a matter of risk assessment, and it's not simply that \"temperate regions\" will get more, or less precipitation. It varies with the region. Australia, unfortunately for me, it likely to become ever dryer. The Amazon is also at risk of increased drought. That section of the report is actually bracketed with a picture of flood (p41) and another of drought (p44). It's not simply a case of looking for the worst in every case. It is rather a consequence of the fact that we are adapted to a certain distribution of climate conditions, and rapid changes therefore tend to be disruptive rather than productive, for the most part.\nThe report is unabashed in the conclusion that climate change is a problem and something that should be mitigated against. I think this is an example of the proper roles of science and of policy. What the science says is that the consequences of changing climate are mostly negative and increasingly so with more rapid change. That's not science driven by policy. That's the answer science gives the questions legitimately asked by policy makers.\nOn page 52:\nThe Synthesis Report of the Copenhagen climate congress (Richardson et al. 2009), the largest climate science conference of 2009, concluded that \"Temperature rises above 2 \u00b0C will be difficult for contemporary societies to cope with, and are likely to cause major societal and environmental disruptions through the rest of the century and beyond.\"[/color]\u200b\nCheers -- sylas\nLast edited:\nNov 29, 2009\nAndre\n4,310\n73\nvanesch said:\nHigher levels of humidity in the atmosphere, of course\nWarm\nbut is that all? Wouldn't it suggest that the water cycle would have to accellerate to bring more rain?\nXnn\n554\n0\nMark44 said:\nGranted, science is not and should not be a democratic process, so the numbers for and against a particular theory are for the most part irrelevant. My point is that for science that is \"settled\" there sure are a lot of people who don't think so.\nMark44;\nI looked over the abstract of the Lin Zhen-Shan and Sun Xian paper.\nThey are not predicting cooling. Instead, they are hypothesizing that if\nCO2 levels were to be held constant and if the cyclic trends of the past\nwere to continue, then there could be cooling. However, we know that\nCO2 levels are continuing to rise and they haven't shown that the 60\nyear trend isn't just a coincidence.\nAlso, the key word in that petition is \"catastrophic heating\". Humans are\nremarkable good at adopting to climate change, so it's difficult to say\nthat the climate change that we are facing will be necessarily be catastrophic.\nIn fact, the IPCC has even documented that agriculture productivity will\ninitially increase due to global warming. So, I can see their point.\nAnyhow, the science behind global warming due to CO2 emission is clear.\nHowever, there is and ought to be an intelligent debate on what to do about it.\nMark44\nMentor\nInsights Author\n38,036\n10,507\nXnn said:\nMark44;\nI looked over the abstract of the Lin Zhen-Shan and Sun Xian paper.\nThey are not predicting cooling. Instead, they are hypothesizing that if\nCO2 levels were to be held constant and if the cyclic trends of the past\nwere to continue, then there could be cooling. However, we know that\nCO2 levels are continuing to rise and they haven't shown that the 60\nyear trend isn't just a coincidence.\nIf you look past the summary, you will see that they are predicting cooling in the next 20 years. In section 6, they say \"It thus indicates that whether on century scale or on the periods of quasi 60-year oscillations, the global climate will be cooling down in the next 20 years.\"\nRight after that they say \"And again, our primary conclusion, i.e., that atmospheric CO2 concentration is not a key determinant of periodic variation of the global temperature. The global climate warming is not solely affected by the CO2 greenhouse effect.\nThe best example is temperature obviously cooling however atmospheric CO2 concentration is ascending from 1940s to 1970s.\"\nXnn said:\nAlso, the key word in that petition is \"catastrophic heating\". Humans are\nremarkable good at adopting to climate change, so it's difficult to say\nthat the climate change that we are facing will be necessarily be catastrophic.\nIn fact, the IPCC has even documented that agriculture productivity will\ninitially increase due to global warming. So, I can see their point.\nAnyhow, the science behind global warming due to CO2 emission is clear.\nI disagree, and there are many climate scientists more knowledgeable in this field than I who also disagree that global warming is caused by solely or primarily by CO2 increases. This point is also made in the introduction of the Zhen-Shan and Xian study; namely, that CO2 increases follow temperature increases, not the other way round - \"And the past records have indicated that the increase of CO2 concentration did not occur before the warming up as shown by some studies (Fischer et al, 1999; Schlesinger and Ramankutty, 1994)\"\nXnn said:\nHowever, there is and ought to be an intelligent debate on what to do about it.\nMark44\nMentor\nInsights Author\n38,036\n10,507\nsylas said:\n.\nMark44 said:\nMy point is that for science that is \"settled\" there sure are a lot of people who don't think so.\nI don't dispute your final sentence; nor do I find it all that unusual. I know of several such cases like this, where science is disputed by a lot of people, including many who have some science training, despite the points at issue being considered settled by almost all the scientists actively working on it. However, why that occurs and to what extent is off topic for this thread, and indeed for this whole Earth forum.\nI find it difficult to believe that a \"science is settled\" when two different camps of equally competent scientists hold views that are contradictory. Would you care to define \"almost all\" in your assertion that the points at issue are settled? And how does that justify the science? After all, in the time of Galileo Galilei, \"almost all\" of his fellow scientists looking at the Earth's relationship with the solar system concurred with the church dogma that the Sun revolved around the earth.\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nsylas said:\nThere's a huge issue with how best to communicate scientific information to the wider public, and this is not actually a question of the science itself, but a matter of communications skills, or styles.\nThe point is that the *message* that is conveyed is more dependent on the style than on the content. That's the whole purpose of publicity btw. Communication is the art of taking factual material and presenting it in such a way that the desired message is conveyed, by using the factual information as a support for the rhetoric at hand. That's exactly what that SUV publicity does: there's no erroneous factual information in there. I'm sure that the curves of torque versus rpm are scientifically correct. But the whole is set up so that you get an impression of power, of pleasure etc... if you buy that car.\nHere, the message is to urge people to go for ambitious goals at the Kopenhagen conference and to get popular support for it, based upon fear for the future and catastrophe, blood and drama.\nWhile, if you really read the report, and you think about it, you arrive at a totally different conclusion (well, me at least). Look at figure 22. That's bluntly unfeasible. None of those paths are realistically attainable or will even be approached.\nIf you see that the result of Kyoto has been a 40% increase in CO2 exhaust, then it is clear that this kind of exhaust limitations on relatively short terms are a failure. So hoping for the drastic reductions on figure 22 is simply impossible.\nOn the other hand, the \"tipping points\" give us not such a dramatic scenario at all: greener Sahara, more available land (reduction of Amazon forest = more place for people, Greenland will become ice-free, parts of Antarctica will become ice-free), and the general \"aride\" desert picture that's everywhere in the booklet is visibly NOT the climate we will actually have, which seems to be more humid (more rain in moderate climate zones...).\nSo between an impossible reduction scheme of figure 22, and the not-so-bad consequences in the list of tipping points, I think that the wisest political decision, based on this report, is to put CO2 exhaust reduction to a lesser level of importance (although it should be pursued), and to start thinking of adapting to the new climate by the end of the century.\nThat's the message I personally get out of this report when looking at the science in it, and it is in total contradiction with the tone of the report.\nIt is, to some extent, subjective; and in my view it is good to have a range of styles of communication in place. It's commonly held that the problem with science communication is precisely the reverse. It is often TOO dry and sober and dispassionate. But there you go.\nBecause there's a difference between trying to convey information, and an UNDERSTANDING, and trying to convey a message and a desire for action. The first is science, the second is publicity and rhetoric.\nI don't actually agree with or even really understand your reaction in this case; but I don't think it is all that important. The aspects I like about this report are that it is clear and concise, and starts out each section with simple bullet points that speak directly to what is most relevant for the intended audience; and also that it tackles head on many of the common popular confusions and outright errors that plague the whole popular perceptions of climate science. It is also well referenced to all the conventional dry technical literature.\nThe text in itself, or at least the contents of the text, is ok. It is the \"drama\" that goes with it that makes me tip over. From the moment that one tries to sell me some desire or action, I consider that I have to do with an \"argument\" and not with \"a source of information\". One is not trying to \"inform me\" (explain me how things work), but one is trying to induce me into action or desire. Both are incompatible. You cannot \"inform\" (and show yourself balanced) and at the same time \"argue\" (and pull someone over). Yes, you can first \"inform\" and then consider different positions, and explain why one position is probably preferable over another.\nIn this text, at no point one considers other positions than \"we have to reduce drastically our emissions and right now because we're heading for an even worse catastrophe than we thought 5 years ago\".\nThis thread would be a good place to consider such issues on their own scientific merits.\nI still have to go through the many references given here, but the first point that hit me was that the plot on figure 2 does seem to show that there is a steady, linear, rise of CO2 content in the atmosphere. Just by looking at the plot, and putting a ruler over it (yes, there has been a slight slowing down in the 1990-ies).\nSo what's all the buzz over this acceleration in CO2 ? It might be correct, but then it needs to be\nexplained\n, right ? How can you show a linear rise in the atmosphere, and dedicate a whole part of the report over the increasing exhaust, and not explain how both are to be compatible ?\nI was also impressed with how CERN reacted to the appalling book\nAngels and Demons\nby Dan Brown. (Some folks liked it as a book; but its not my style...) They made it an opportunity to tap into public interest and help people learn more about the science. See\nhttp://angelsanddemons.cern.ch/\n.\nThis is OT, but CERN has a great [STRIKE]publicity[/STRIKE] public relations department...\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nsylas said:\nFigure 2 is completely consistent with the numbers given. The rate of increase IS increasing and you can see quite easily that the increase since 1980 is not linear. Just hold a ruler up against the graph if you want to check. Of course, the proper measure of linearity works from the numbers, not eyeballing a graph, and the numbers are as you have quoted from the report. What\u2019s the problem?\nOk, maybe somewhat cheap, but here's my \"ruler\" on that figure, just done \"by hand\". We see that in the 90ies there was indeed a dip, and that now, we are somewhat above the slope. So I can indeed see that if you pick out exactly the right \"pieces of graph\", you get out the numbers in the paper. However, doing things \"with the ruler\" doesn't give you that impression. So I do think this needed some explanation.\nLast edited by a moderator:\nMay 9, 2012\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nThere's another very misleading figure, and that's figure 9.\nAlthough I don't question the plot, what I find very misleading are the insets, of the Greenland ice cover, cherry-picked to be 1992 (exceptionally low melt area) and 2007 (exceptionally high melt area), both are not representative of the average trend (probably correctly done on the plot). I connected the \"trend line\" that connects these 1992 and 2007 points, to convey the \"slope\" that the insets are suggesting, as compared to the \"scientifically correct\" slope.\nThere's nothing factually wrong, nowhere. But it is presented in such a way that people get a wrong impression. That's advertising. That's not informing.\nAgain, I'm not disputing any of these numbers, I'm disputing the *representation* and the underlying message.\nLast edited by a moderator:\nMay 9, 2012\nGENIERE\nThere is also interesting empirical data:\nNorth Pole webcam photo of April 4, 2007 about a month after expected maximum ice extant. 2007 is the year said to have the least summer ice coverage.\nhttp://www.arctic.noaa.gov/npole/2007/images/noaa1-2007-0425-102422.jpg\nUSS Skate (SSN-578), surfaced at the North Pole, 17 March 1959. The date was specifically chosen due to it being the time of maximum ice extant.\nhttp://www.navsource.org/archives/08/0857806.jpg\nNorth Pole in August 2007, worst summer ever compared to summers of 1979 - 2000!\nhttp://www.arctic.noaa.gov/npole/2007/images/noaa2-2007-0803-065037.jpg\nSeadragon (SSN-584), foreground, and her sister Skate (SSN-578) during a rendezvous at the North Pole in August 1962. Note the men on the ice beyond the submarines.\nhttp://www.navsource.org/archives/08/0858411.jpg\n<|>\nLast edited by a moderator:\nMay 4, 2017\nmheslep\nGold Member\n364\n719\nvanesch said:\nThe point is that the *message* that is conveyed is more dependent on the style than on the content. That's the whole purpose of publicity btw. Communication is the art of taking factual material and presenting it in such a way that the desired message is conveyed, by using the factual information as a support for the rhetoric at hand. That's exactly what that SUV publicity does: there's no erroneous factual information in there. I'm sure that the curves of torque versus rpm are scientifically correct. But the whole is set up so that you get an impression of power, of pleasure etc... if you buy that car...\nAt least they didn't air brush cyclones into the page 8 Earth photo as Gore did in his http://ecx.images-amazon.com/images/I/41RLwu-GDFL._SL500_AA240_.jpg\"\nLast edited by a moderator:\nMay 4, 2017\nXnn\n554\n0\nGeniere;\nI wouldn't put much stock into sub photographs.\nThey tend to scout out open floes before surfacing; it's safer!\nMark44;\nI see the statement in section 6; it's different than what's in their summary.\nSo, much for consistency of their report.\nHowever, the point is that they are just curve fitting; that's not scientific.\nIt reminds me of the people that curve fit stock prices and try to sell it\nas a sophiscated method of investing. If stock prices and the climate were\npurely cyclic then it would work, but we know that there are drivers to the climate\nas there are to finances.\nTheir selection of quasi periodic cycles is suspect. In particular, examine how they\ndrew the 60 year cycle in Figures 1,2 and 5. It's an increasing amplitude with the strongest positive forcing over the last 30 years. That works to minimize\nthe warming trend from CO2. So, the analysis is dependant on the quasi 60\nyear period cycle leading to cooling. However, where is the science for that?\nIt's also only over the last 50 years that human CO2 emissions have dominated\nthe climate. Before that, natural variations were dominate. So, they are\ncurve fitting 2 different time periods and exaggerating cyclic warming over\nthe last 30.\nPersonally, I wouldn't put a dollar into their approach. It's far better to anticipate\nabout 0.015C of warming per year from CO2 increases superimposed upon a quasi periodic El Nino/La Nina of about 0.25C over a 3 to 7 year frequency. There are also\nthe quasi periodic 11 year solar cycles of about 0.05C, but they can not be discerned\nin the global temperarure record compared to ENSO events.\nLast edited:\nNov 30, 2009\nmheslep\nGold Member\n364\n719\nvanesch said:\n...\nSo what's all the buzz over this acceleration in CO2 ? It might be correct, but then it needs to be\nexplained\n, right ? How can you show a linear rise in the atmosphere, and dedicate a whole part of the report over the increasing exhaust, and not explain how both are to be compatible ?\nGlobal\nemissions\nhave accelerated, but atmospheric\naccumulation\n, i.e. figure 2, is experiencing more or less a linear increase.\nThis graph also illustrates, BTW, why CO2 emissions reductions enforced on only the EU and the US while allowing China and India to opt out would be useless.\nLast edited:\nNov 30, 2009\nBored Wombat\n119\n0\nmheslep said:\nThis graph also illustrates, BTW, why CO2 emissions reductions enforced on only the EU and the US while allowing China and India to opt out would be useless.\nWell it wouldn't be immediately effective, but useless is a bit strong.\nEvery little less carbon emitted is a retardation of climate change.\nAnd demanding CO2 emissions reductions in US and EU would force the development of low carbon technologies that could then be passed on to China, India and Brazil.\nmheslep\nGold Member\n364\n719\nBored Wombat said:\nWell it wouldn't be immediately effective, but useless is a bit strong.\nYou're right.\nBored Wombat\n119\n0\nmheslep said:\nYou're right.\nOn the other hand, you'd never get the US or probably Australia to accept enforced reductions if China and probably India weren't given reductions, so I guess my pedanticism is moot for practical purposes.\nsophiecentaur\nScience Advisor\nHomework Helper\n30,060\n7,373\nXnn\nYou have compared climate variations with the Stock Market.\nOne big difference is that betting on the Stock Market affects it in the short term. These days, everyone with red braces has been using the same computer program to spot trends and they've all been involved in a huge positive feedback system. This is a very unstable system.\nThere has been (until now, possibly) no feedback mechanism involving human behaviour.\nI feel very despondent about the latest public and press reactions to UEA's emails. People just don't want to think that we have any responsibility or any chance of changing things. How convenient that some numpty over egged things a bit and that means all the evidence must be wrong.(!?) Whatever turns out to be the 'truth', it is far too much to expect the Public to understand anything so complicated and to make the optimum decision about what to do. Same goes for the politicians, too.\nchayced\n157\n0\nmheslep said:\nThis graph also illustrates, BTW, why CO2 emissions reductions enforced on only the EU and the US while allowing China and India to opt out would be useless.\nNot true at all. If emmision reductions were inforced on the US it would cause more financial trouble.\nIt's already nearly impossible to compete with Chinese manufacturing because of standard of living/labor costs, nonexistant quality control, and disregard for environmental standards.\nIf the west is left pennyless by its own enforced handycap, who will get china to clean up their act?\nIf it were truly useless I wouldn't care about it. This is counterproductive.\nXezlec\n318\n0\nVanesch, et al.:\nI would genuinely love to be on your side and not worry about the whole climate change thing, but there are some questions I would need to find convincing answers to first. This list is not meant as a critique; I honestly wonder what the right thing to do is, and am open to persuasion.\n1. I keep hearing this notion everywhere that the one right course of action is adaptation to global warming rather than any reduction in fossil fuel consumption. I've been trying to understand it. Don't forever-increasing CO2 emissions most likely mean forever-increasing temperature? How can we adapt to a forever-increasing temperature? Is that even possible?\n2. I know that so far, industrialized nations have failed to reduce emissions significantly, and (though I'm not well-versed enough to actually know) I could certainly be persuaded that significant reductions could be an enormous economic strain, maybe even sufficient to set our standard of living back 100 years or more. But when I envision massive shifts of climate and productivity from one region to another, and the inevitable conflicts over resources that come along with it, plus possible mass extinctions due to such a rapid climate shift being too much for most species to adapt to, and unknown wider effects due to that (don't \"pest\" species tend to be favored by rapid changes in environment?), I guess I don't see why it would necessarily be obvious that the possible-but-debatable economic armageddon wrought by switching to alternative energy rivals the possible-but-debatable environmental armageddon that could result (even with some adaptation) from not doing so. In the context of that kind of uncertainty, what makes you confident in favoring the option you favor?\n3. Do you believe that \"advertising\" a position to the public is wrong? That science should just state the facts and leave the decision-making to the decision-makers? If so, then is it OK for science to at least \"advertise\" those facts, so long as they aren't advocating a course of action? I mean, for example, is it OK to try to persuade people that the theory of evolution is plausible, as long as you don't explicitly advocate a position regarding teaching it in schools?\nHistory would seem to show that the public (and, to a lesser extent, leaders) are not going to carefully and scientifically analyze a scientific position. Rather, they give science relatively little weight in deciding their beliefs and courses of action. I submit that people believe what is sold to them, and when two people are trying to sell them competing ideas, then being right just gives one of them a slight statistical advantage in persuasiveness. If that's the case, then isn't science without a hard-sell incapable of reaching the public or decision-makers at all?\nThe upshot of that is, if (as I suggest) it is OK to use persuasion in favor of a position regarding a statement of fact, then wouldn't the potential statement of fact \"course of action A results in a more tolerable (by some metric) situation than course of action B\" also be OK to use persuasion for? Sorry if that's convoluted, but it's the best way I can explain what I keep thinking when I hear this position.\nsylas\nScience Advisor\n1,647\n9\nXezlec said:\n1. I keep hearing this notion everywhere that the one right course of action is adaptation to global warming rather than any reduction in fossil fuel consumption. I've been trying to understand it. Don't forever-increasing CO2 emissions most likely mean forever-increasing temperature? How can we adapt to a forever-increasing temperature? Is that even possible?\nThere's a hard limit on CO\n2\nemissions, and that is the availability of fuels. Oil in particular has a limited availability; it is becoming more and more expensive to obtain, in every sense. Conventional reserves are running out, and proposals such as mining shales or extracting from other such sources are much more expensive and have serious negative consequences quite apart from emissions.\nOne way or the other, we are going to be weaned off cheap oil. The question is; what path will we take for moving to new technologies? We'll be doing that anyway.\nIf we adapt industry to use other sources of fossil fuels and manage to get all of it mined or extracted; with all available fossil carbon burned and emitted out into the atmosphere, there is still a hard limit on how far we could realistically go. That's probably the easiest line of least resistance. Climate impacts would be significant, but bounded; and adapting to that would be expensive.\nIf we adapt to other technologies, then we may be able to get away with not burning all available fossil fuels. I'm a bit of a skeptic with respect to human collective sanity and risk management; but I am reasonably sure that the cheapest and and most practical long term strategy will involve leaving large reservoirs of fossil fuels in the ground (coal, especially) and moving to other technologies... which we'll have to do in any case.\nCheers -- sylas\nXezlec\n318\n0\nsylas said:\nThere's a hard limit on CO\n2\nemissions, and that is the availability of fuels.\nAh, so that's what that's all about.\nBut still, whenever a scientist says \"bounded\", I immediately think http://en.wikipedia.org/wiki/Graham%27s_number\" (which was invented precisely to provide an upper bound for something). In the interest of specifying a useful bound, is there good reason to believe that those fuels will peter out, say, within the next thousand years? I mean, sure, the current oil sources may be running out, but isn't there still a \"fecal tonne\" of coal and natural gas out there? And maybe some as-yet-undiscovered stuff that will become increasingly cost-effective in years to come? I mean like those methane clathrates I've heard so much about?\nLast edited by a moderator:\nMay 4, 2017\nBored Wombat\n119\n0\nXezlec said:\nVanesch, et al.:\nI would genuinely love to be on your side and not worry about the whole climate change thing, but there are some questions I would need to find convincing answers to first. This list is not meant as a critique; I honestly wonder what the right thing to do is, and am open to persuasion. (etc)\nGood questions.\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nXezlec said:\nVanesch, et al.:\nI would genuinely love to be on your side and not worry about the whole climate change thing, but there are some questions I would need to find convincing answers to first. This list is not meant as a critique; I honestly wonder what the right thing to do is, and am open to persuasion.\nI'm not saying that we \"shouldn't worry\". I'm just saying that it is my opinion that scientists do a disservice to science by trying to present their results in a way which is \"non-neutral\", as I pointed out to this brochure, which tries to\nemphasize\n, by using communication techniques, the gravity of climate change.\nIf people, and politicians, need to take decisions, they need \"information\" and not \"communication\". There's no point in using communication techniques that try to convey a message of \"melting Greenland\" faster than it actually melts. There's no point in representing it as melting less than it actually does as one can find on some sceptics blogs either. The message should simply be: to the best of our knowledge, Greenland will be ice-free by (say) 2070, or 2140, or...\nIt is then up to politicians and people to determine whether or not that's a sufficiently serious problem to do something about. It's not up to the scientist to go shouting \"hell, people, look, Greenland's melting FAST\" (suggesting: DO SOMETHING ABOUT IT, DAMNIT!).\nNot that scientists are not human beings and may not have political convictions - the reason is that if they do so, they put themselves on the same level as opponents of science, and hence they lose their credibility as a scientist.\n1. I keep hearing this notion everywhere that the one right course of action is adaptation to global warming rather than any reduction in fossil fuel consumption. I've been trying to understand it. Don't forever-increasing CO2 emissions most likely mean forever-increasing temperature? How can we adapt to a forever-increasing temperature? Is that even possible?\nAs others said, we'll run out of fossil fuels in any case about this century or the next, and when we have done that, we will have - if I remember well - put a 4-fold amount of CO2 in the atmosphere, and there this story will stop in any case.\n2. I know that so far, industrialized nations have failed to reduce emissions significantly, and (though I'm not well-versed enough to actually know) I could certainly be persuaded that significant reductions could be an enormous economic strain, maybe even sufficient to set our standard of living back 100 years or more. But when I envision massive shifts of climate and productivity from one region to another, and the inevitable conflicts over resources that come along with it, plus possible mass extinctions due to such a rapid climate shift being too much for most species to adapt to, and unknown wider effects due to that (don't \"pest\" species tend to be favored by rapid changes in environment?), I guess I don't see why it would necessarily be obvious that the possible-but-debatable economic armageddon wrought by switching to alternative energy rivals the possible-but-debatable environmental armageddon that could result (even with some adaptation) from not doing so. In the context of that kind of uncertainty, what makes you confident in favoring the option you favor?\nWell, we should first know with much more detail what ARE going to be the exact consequences, because global temperature itself is not a very detailed indicator. If it is just because of some species extinctions and coral reefs, I think most people are not willing to set back their lifestyle for about 100 years - especially not in develloping countries. Even if half of humanity has to die, we would like to find out WHICH half, and if we are not concerned, I don't think we are willing to set back our life style 100 years to save the OTHER half of humanity. And again, all these are political decisions and viewpoints, they have nothing to do with the science.\nScience should try to find out, to the best of their ability. Science should inform. Science shouldn't take any political position, because then science looses her virginity.\n3. Do you believe that \"advertising\" a position to the public is wrong? That science should just state the facts and leave the decision-making to the decision-makers? If so, then is it OK for science to at least \"advertise\" those facts, so long as they aren't advocating a course of action?\nThey should advertize the facts, only the facts, and the whole facts, and not represent them in a biased way towards a certain kind of action-taking. What has been done here is to try to emphasize beyond objectivity, the \"graveness\" of climate change (and hence the need of action). This is a problem because the real question to politicians is not \"should we stop this\", but rather \"what balance between limiting this, and adapting to the consequences, is best fit (for my country) ?\"\nFor that you need as objective a description of what is going to happen and not.\nHistory would seem to show that the public (and, to a lesser extent, leaders) are not going to carefully and scientifically analyze a scientific position. Rather, they give science relatively little weight in deciding their beliefs and courses of action. I submit that people believe what is sold to them, and when two people are trying to sell them competing ideas, then being right just gives one of them a slight statistical advantage in persuasiveness. If that's the case, then isn't science without a hard-sell incapable of reaching the public or decision-makers at all?\nThey shouldn't care about that. That's the whole point ! They should just try to find out how things work, and what's going to happen. Not whether anybody cares, or what action one should take.\nThe upshot of that is, if (as I suggest) it is OK to use persuasion in favor of a position regarding a statement of fact, then wouldn't the potential statement of fact \"course of action A results in a more tolerable (by some metric) situation than course of action B\" also be OK to use persuasion for? Sorry if that's convoluted, but it's the best way I can explain what I keep thinking when I hear this position.\nThe problem is that if you, as a scientist, try to persuade the public that the problem you're dealing with is terrible (much more terrible than the actual data show you), then chances are that you induce people in wrong decision making, by giving too much weight to what you are saying, for the moment. And if later on, it turns out that you've been exaggerating, even the slightest bit, that NOBODY WILL TAKE YOU SERIOUSLY ANYMORE, even if this time, you come with a genuinely serious problem, because you've been crying wolf before. And if science is not to be trusted, then who is ? Any crank that comes up with any idea ?\nIn other words, by \"putting (more than your actual) weight into the balance as a scientist\", you are risking the whole credibility of science in the future.\nBored Wombat\n119\n0\nvanesch said:\nI'm not saying that we \"shouldn't worry\". I'm just saying that it is my opinion that scientists do a disservice to science by trying to present their results in a way which is \"non-neutral\", as I pointed out to this brochure, which tries to\nemphasize\n, by using communication techniques, the gravity of climate change.\nIf people, and politicians, need to take decisions, they need \"information\" and not \"communication\". There's no point in using communication techniques that try to convey a message of \"melting Greenland\" faster than it actually melts. There's no point in representing it as melting less than it actually does as one can find on some sceptics blogs either. The message should simply be: to the best of our knowledge, Greenland will be ice-free by (say) 2070, or 2140, or...\nIt is then up to politicians and people to determine whether or not that's a sufficiently serious problem to do something about. It's not up to the scientist to go shouting \"hell, people, look, Greenland's melting FAST\" (suggesting: DO SOMETHING ABOUT IT, DAMNIT!).\nNot that scientists are not human beings and may not have political convictions - the reason is that if they do so, they put themselves on the same level as opponents of science, and hence they lose their credibility as a scientist.\nI disagree with that.\nI think the communication of science is science to the public is a different job than communicating it in the scientific literature, and is not less valuable.\nFor the former, you need to use common and often emotive language. For the latter you need to use equations.\nvanesch said:\nThe problem is that if you, as a scientist, try to persuade the public that the problem you're dealing with is terrible (much more terrible than the actual data show you), then chances are that you induce people in wrong decision making, by giving too much weight to what you are saying, for the moment. And if later on, it turns out that you've been exaggerating, even the slightest bit, that NOBODY WILL TAKE YOU SERIOUSLY ANYMORE, even if this time, you come with a genuinely serious problem, because you've been crying wolf before. And if science is not to be trusted, then who is ? Any crank that comes up with any idea ?\nIn other words, by \"putting (more than your actual) weight into the balance as a scientist\", you are risking the whole credibility of science in the future.\nI don't think anyone is saying that the problem is worse than the data shows. (And if they are I agree that this is ethically as well as morally wrong). But given that about 97% of research climatologists think that human activity is affecting climate and only about 80% of the public, then there is an information gap that should be addressed.\n(And a propaganda machine producing the information gap, that should also be addressed).\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nBored Wombat said:\nI disagree with that.\nI think the communication of science is science to the public is a different job than communicating it in the scientific literature, and is not less valuable.\nFor the former, you need to use common\nand often emotive\nlanguage. For the latter you need to use equations.\nI'm horrified by that thought. It is science denying its fundamental principles.\nI don't think anyone is saying that the problem is worse than the data shows.\nThen why does the inset of the ice melting on Greenland show the smallest and the largest outliers of the general trend instead of picking two images that lie close to the trend line ?\nBut given that about 97% of research climatologists think that human activity is affecting climate and only about 80% of the public, then there is an information gap that should be addressed.\nBut do you think the best way to get people accept a scientific viewpoint is by exaggerating the message ?\nImagine I wanted to promote the scientific idea that humans evolved from ape-like ancestors who didn't walk straight up. Would it be productive to convince those that have a hard time accepting that by exaggerating the message, and by showing pictures that suggest that humans actually evolved from apes that walked on their hands only, and slide in images of some chimp walking on his hands with his legs in the air ?\nDo you think that renders the science\nmore credible\n?\nLast edited:\nDec 10, 2009\nBored Wombat\n119\n0\nvanesch said:\nI'm horrified by that thought. It is science denying its fundamental principles.\nNot unless you think that science isn't the publicisation of science too. Climate science is the prime example where the public's general ignorance of science is becoming dangerous.\nBut scientists are (almost) always emotional about the object of their studies. It's fine for that to come out in the publicisation of it. That way it's less boring. And who among us (except perhaps the aspies) was not moved by Sagan or Feynman?\nThat's what it's all about, and it isn't against fundamental principles.\nvanesch said:\nThen why does the inset of the ice melting on Greenland show the smallest and the largest outliers of the general trend instead of picking two images that lie close to the trend line ?\nTo show the range. As long as it is clear what the inset shows, it's good.\nvanesch said:\nBut do you think the best way to get people accept a scientific viewpoint is by exaggerating the message ?\nNo. But if a scientist is concerned. (And about two thirds of the ecologists one speaks to can talk of devastation in their object of study), then they should say: \"I'm concerned\". And if they think that 75% of all ecological communities are under immediate threat of population extinction they should say: \"You should be concerned!\"\nLoudly.\nvanesch said:\nImagine I wanted to promote the scientific idea that humans evolved from ape-like ancestors who didn't walk straight up. Would it be productive to convince those that have a hard time accepting that by exaggerating the message, and by showing pictures that suggest that humans actually evolved from apes that walked on their hands only, and slide in images of some chimp walking on his hands with his legs in the air ?\nNo. But argument by analogy is like a leaky screwdriver.\nvanesch said:\nDo you think that renders the science\nmore credible\n?\nNo. But no one is leading climate science with photos of a chimp walking on their hands. And if they did, it wouldn't say anything about climate science.\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nBored Wombat said:\nNot unless you think that science isn't the publicisation of science too. Climate science is the prime example where the public's general ignorance of science is becoming dangerous.\nI don't know if it is especially dangerous in this case, but for sure (and that's my point) scientists have a big responsibility in rendering the science less credible.\nBut scientists are (almost) always emotional about the object of their studies. It's fine for that to come out in the publicisation of it. That way it's less boring. And who among us (except perhaps the aspies) was not moved by Sagan or Feynman?\nThere's a difference between showing emotion about the beauty of a study object, and trying to convey interest in the study material at hand, or, by trying to promote the scientific method and approach and lauding its principles as a way to \"find out things\" on one hand, and by using emotional arguments in a communication technique mixed with scientific ones to promote a political stance, in the same way as a vulgar commercial does.\nTo show the range. As long as it is clear what the inset shows, it's good.\nWhat range ? The range of \"natural variability\" ? It is NOT clear what the inset shows: you have to look at the years, and then SEE that these points are outliers. There is no caveat in the legend: \"the insets show two extreme outliers to illustrate how variable (how noisy) this indicator is\".\nNo. But if a scientist is concerned. (And about two thirds of the ecologists one speaks to can talk of devastation in their object of study), then they should say: \"I'm concerned\". And if they think that 75% of all ecological communities are under immediate threat of population extinction they should say: \"You should be concerned!\"\nWhy ? What if I don't care what happens to 75% of all ecological communities ? What's so \"scientific\" about it ? What is important is that people are *informed* (in as much as they care) about that. What is also important is that one explains to them what it implies for their day-to-day life. If the Amazon forest disappears, how will that affect my day-to-day life ? Will I not be able to eat Kiwis any more, and do I find it important to be able to eat kiwis ? Will it affect the way I go to my work place ? The way I go on a holiday ?\nNo. But no one is leading climate science with photos of a chimp walking on their hands. And if they did, it wouldn't say anything about climate science.\nThe chimp walking on its hands is the equivalent of the insets of the Greenland ice plot: it is a suggestive picture of a larger effect than has been observed.\nThe picture can be a true picture of a circus chimp that has learned to walk on its hands, so it is not \"wrong\". But it suggests something that is not correct.\nBored Wombat\n119\n0\nvanesch said:\nI don't know if it is especially dangerous in this case, but for sure (and that's my point) scientists have a big responsibility in rendering the science less credible.\nIt's a PR game, and they're up against PR experts.\nI don't know if you can blame them.\nvanesch said:\nWhy ? What if I don't care what happens to 75% of all ecological communities ?\nThen you need to be educated about the science. Because we're losing forever a massively powerful resource, and you should understand that if you're going to take up good space on the planet.\nvanesch said:\nWhat's so \"scientific\" about it ? What is important is that people are *informed* (in as much as they care) about that.\nBecause humans are superstitious and believe wrong things. And yet we supply them with a technological society, full of technology they don't understand. And the mix of power and ignorance is dangerous.\nScience is a candle of light in an increasingly demon-haunted darkness in people's minds, and that alone is unstable:\nhttp://www.reuters.com/article/idUSN2319603620080423\"\nIf we let it slip far enough, we could very easily get a new inquisition era or even dark ages.\n\"I worry that [...] pseudo-science and superstition will seem year by year more tempting, the siren song of unreason more sonorous and attractive. Where have we heard it before? Whenever our ethnic or national prejudices are aroused, in times of scarcity, during challenges to national self-esteem or nerve, when we agonize about our diminished cosmic place and purpose, or when fanaticism is bubbling up around us-then, habits of thought familiar from ages past reach for the controls. The candle flame gutters. Its little pool of light trembles. Darkness gathers. The demons begin to stir.\" - Carl Sagan (The Demon-Haunted World: Science as a Candle in the Dark).\nIf people don't understand science, and don't understand that we need to preserve biodiversity, they can do great damage to themselves, to us and to the world.\nvanesch said:\nWhat is also important is that one explains to them what it implies for their day-to-day life. If the Amazon forest disappears, how will that affect my day-to-day life ?\nIt will retard forever your capacity for many avenues of medical research and biochemical research. And it may destroy keystone nutritional biological processes that kicks of other extinctions. Possibly our own.\nvanesch said:\nWill I not be able to eat Kiwis any more, and do I find it important to be able to eat kiwis ?\nNo, but if we lose key species, perhaps obviously honey bees, it will make getting enough of certain vitamins difficult and expensive. And most will not be as obvious as honey bees. They will be lower on the food chain and camouflaged in out ignorance of ecological systems.\nvanesch said:\nWill it affect the way I go to my work place ?\nPossibly. Especially if your route to your work is within a few metres of the high tide mark at any point.\nvanesch said:\nThe way I go on a holiday ?\nCertainly. It will mean there will be food riots and unrest in many parts of the world, so you'll have to take a gun or avoid them.\nvanesch said:\nThe chimp walking on its hands is the equivalent of the insets of the Greenland ice plot: it is a suggestive picture of a larger effect than has been observed.\nThe picture can be a true picture of a circus chimp that has learned to walk on its hands, so it is not \"wrong\". But it suggests something that is not correct.\nI think it's okay to assume that people will read the caption.\nLast edited by a moderator:\nApr 24, 2017\nvanesch\nStaff Emeritus\nScience Advisor\nGold Member\n5,109\n20\nBored,\nI agree with you about Sagan's message (have read that book when I was young btw). But the point I was making was: it is a political choice to care for the \"world for tomorrow\" if that will cost me fun and wealth today. It is just as well my good right to choose to live still nicely for the next 20 years in all comfort, and to destroy 75% of all ecosystems in doing so, \"apres nous le deluge\". It is not up to a scientist to tell me not to take on that attitude. It is up to a scientist to inform me that I'm making that choice, but I'm entitled to make that choice.\nSo:\n- scientist: you know that you're killing the rain forests with your SUV ?\n- citizen: no, I didn't, am I ?\n- scientist: yes you are\n- citizen: ah, well, good to know. Have a nice day.\n- scientist: but shouldn't you stop driving that SUV then ?\n- citizen: nope, I like it too much.\n- scientist: but the rain forest ?\n- citizen: I weighted the pro and contra, and I prefer my SUV over the rain forest. Have a nice day.\n...\nSimilar threads\nConsequences of global climate change\nDec 16, 2022\nReplies\n28\nViews\n3K\nGenomic data to determine last time when WAIS was ice free\nDec 27, 2023\nReplies\n1\nViews\n3K\nOcean acidification and atmospheric carbon\nJul 2, 2023\nReplies\n12\nViews\n7K\nWest Antarctica's ice sheet loss \"appears unstoppable\"\nJun 2, 2014\nReplies\n21\nViews\n13K\nIs the 'Rising Sea Levels' Argument for Global Warming Valid?\nDec 3, 2015\nReplies\n1\nViews\n2K\nMid-Piacenzian Arctic: Warm Climate & Seasonally Ice-Free Oceans\nJan 11, 2010\nReplies\n39\nViews\n13K\nClimate Crisis and the Future: The Day After Tomorrow's Warning\nAug 13, 2021\nReplies\n8\nViews\n4K\nWhat would be a good global temperature?\nFeb 24, 2015\nReplies\n2\nViews\n2K\nLocal gravity effect on MSL and geoid\nNov 2, 2014\nReplies\n18\nViews\n5K\nWhat is the Controversy Behind the Discovery of Rapid Climate Swings?\nSep 18, 2009\nReplies\n4\nViews\n6K\nShare:\nBluesky\nLinkedIn\nShare\nForums\nOther Sciences\nEarth Sciences\nHot Threads\nS\nAn article on Antarctic Eocene climate\nStarted by\nsnorkack\nMar 24, 2025\nReplies: 21\nEarth Sciences\nLong term rain forecast, causes and implications?\nStarted by\nmayflowers\nMar 29, 2025\nReplies: 16\nEarth Sciences\n1831 CE mystery eruption - Zavaritskii caldera, Simushir Island (Kurils)\nStarted by\nAstronuc\nJun 1, 2025\nReplies: 0\nEarth Sciences\nL\nProbabilistic Seismic Hazard Analysis (PSHA) - Identification of area sources\nStarted by\nLuiz1304\nMay 29, 2025\nReplies: 1\nEarth Sciences\nPenguin poop seeds clouds\nStarted by\nFrabjous\nMay 23, 2025\nReplies: 2\nEarth Sciences\nRecent Insights\nInsights\nQuantum Entanglement is a Kinematic Fact, not a Dynamical Effect\nStarted by\nGreg Bernhardt\nSep 2, 2025\nReplies: 7\nQuantum Physics\nInsights\nWhat Exactly is Dirac\u2019s Delta Function? - Insight\nStarted by\nGreg Bernhardt\nSep 2, 2025\nReplies: 0\nGeneral Math\nInsights\nRelativator (Circular Slide-Rule): Simulated with Desmos - Insight\nStarted by\nGreg Bernhardt\nSep 2, 2025\nReplies: 1\nSpecial and General Relativity\nP\nInsights\nFixing Things Which Can Go Wrong With Complex Numbers\nStarted by\nPAllen\nJul 20, 2025\nReplies: 7\nGeneral Math\nF\nInsights\nFermat's Last Theorem\nStarted by\nfresh_42\nMay 21, 2025\nReplies: 91\nGeneral Math\nF\nInsights\nWhy Vector Spaces Explain The World: A Historical Perspective\nStarted by\nfresh_42\nMar 13, 2025\nReplies: 0\nGeneral Math\nBack\nTop",
        "image_urls": [
          {
            "url": "https://www.physicsforums.com/styles/physicsforums/xenforo/smilies/oldschool/blushing.gif",
            "score": 0
          },
          {
            "url": "https://www.physicsforums.com/attachments/carbon_emissions_trends-jpg.130686/",
            "score": 0
          }
        ],
        "title": "New Climate Science Update: Latest Findings Since 2006 Report \u2022 Physics Forums"
      }
    ]
  },
  "duckduckgo_Programming Tutorials": {
    "success": true,
    "urls_found": 3,
    "urls_scraped": 3,
    "retrieval_time": 0.9868426322937012,
    "scraping_time": 1.4617390632629395,
    "total_time": 2.4485816955566406,
    "content_analysis": {
      "successful_scrapes": 3,
      "failed_scrapes": 0,
      "total_content_length": 73625,
      "total_images": 22,
      "relevance_score": 100.0,
      "content_samples": [
        {
          "url": "https://www.scrapingdog.com/blog/web-scraping-with-python/",
          "title": "Python Web Scraping Guide | Scrapingdog",
          "content_length": 46796,
          "keyword_matches": 5,
          "sample_content": "Python Web Scraping Guide | Scrapingdog\nSkip to content\nWeb Scraping in Python (An Ultimate Guide)\nPublished Date\nAugust 27, 2024\nRead\n4min\nTable of Contents\nTL;DR\nStarts with\nheaders 101\n(request / r..."
        },
        {
          "url": "https://www.hostinger.com/tutorials/python-web-scraping",
          "title": "Python Web Scraping Tutorial",
          "content_length": 25117,
          "keyword_matches": 5,
          "sample_content": "Python Web Scraping Tutorial\nkeyboard_arrow_down\nCategories\nAll Tutorials\nWordPress\nVPS\nWebsite development\nEcommerce\nHostinger Horizons\nHow to make a website\nsearch\nclose\nVPS\nPython\nApr 23, 2025\nVale..."
        },
        {
          "url": "https://www.tutorialspoint.com/python_web_scraping/index.htm",
          "title": "Python Web Scraping Tutorial",
          "content_length": 1712,
          "keyword_matches": 5,
          "sample_content": "Python Web Scraping Tutorial\nPython Web Scraping - Home\nIntroduction\nGetting Started with Python\nPython Modules for Web Scraping\nLegality of Web Scraping\nData Extraction\nData Processing\nProcessing Ima..."
        }
      ],
      "titles": [
        "Python Web Scraping Guide | Scrapingdog",
        "Python Web Scraping Tutorial",
        "Python Web Scraping Tutorial"
      ]
    },
    "search_results": [
      {
        "title": "ScrapingDog Python Web Scraping Guide | Scrapingdog",
        "href": "https://www.scrapingdog.com/blog/web-scraping-with-python/",
        "body": "August 27, 2024 - Welcome to our comprehensive guide on web scraping in Python ! If you\u2019ve ever wanted to learn web scraping with Python , you\u2019ve come to the right place. In this extensive Python tutorial for web scraping , we\u2019ll cover everything you need to know, from the basics to more advanced techniques & we will build a web scraper ..."
      },
      {
        "title": "Hostinger Python Web Scraping Tutorial",
        "href": "https://www.hostinger.com/tutorials/python-web-scraping",
        "body": "April 23, 2025 - Here\u2019s the output we got after ... In this article, we learnt how to make your first request in Python, use BeautifulSoup to extract data, parse HTML and navigate the DOM tree, leverage regular expressions to scrape data, handle ......"
      },
      {
        "title": "TutorialsPoint Python Web Scraping Tutorial",
        "href": "https://www.tutorialspoint.com/python_web_scraping/index.htm",
        "body": "The tutorial suits the learning needs of both a beginner or an advanced learner . The reader must have basic knowledge about HTML, CSS, and Java Script. He/she should also be aware about basic terminologies used in Web Technology along with Python programming concepts."
      }
    ],
    "scraped_results": [
      {
        "url": "https://www.scrapingdog.com/blog/web-scraping-with-python/",
        "raw_content": "Python Web Scraping Guide | Scrapingdog\nSkip to content\nWeb Scraping in Python (An Ultimate Guide)\nPublished Date\nAugust 27, 2024\nRead\n4min\nTable of Contents\nTL;DR\nStarts with\nheaders 101\n(request / response / representation) and why they matter for scraping.\nShows Python flow:\nrequests\nto fetch,\nBeautifulSoup\nto parse; adds\nXPath\nwith\nlxml\nfor precise selects;\npandas\nto\nCSV\n; full code provided.\nScrapy\nsection: project setup, selectors, items, and yielding results for\nAmazon\npages.\nFor scale / anti-bot reliability, use\nScrapingdog\n(proxies / JS / CAPTCHAs; 1k free credits).\nWelcome to our comprehensive guide on web scraping in Python!\nIf you\u2019ve ever wanted to learn web scraping with Python, you\u2019ve come to the right place.\nIn this extensive Python tutorial for web scraping, we\u2019ll cover everything you need to know, from the basics to more advanced techniques & we will build a web scraper of our own.\nAs a beginner, you may find the concept of\nweb scraping\na bit intimidating, but worry not! Our easy-to-understand tutorial is designed for learners of all levels, making it the perfect resource for those just starting out or experienced programmers looking to expand their skill set.\nWeb scraping is a valuable skill in today\u2019s digital age, as it allows you to extract data from websites and use it for various purposes, such as data analysis, research, or even building your own applications. With this Python tutorial for web scraping, you\u2019ll soon be able to navigate through the world of web data with ease.\nIt is a long post so fasten your seat belts and let\u2019s get started\n!!\nBefore we start to build our web scraper with Python, let us understand the importance of headers while scraping any web page. We will explore headers in-depth. You might be afraid of headers or you might get an uncomfortable feeling when you see headers like x hyphen or something.\nI might be wrong but when I started coding I was very intimidated by headers. But soon I realized that it is very simple to use headers while making requests.\nWhy learn web scraping with Python?\nLearning web scraping with Python is a skill highly sought after in numerous fields today, such as\ndata science\n,\ndigital marketing\n, competitive analysis, and machine learning.\nPython, with its simplicity and extensive library support (such as BeautifulSoup, Scrapy, and Selenium), makes web scraping easily approachable even for beginners.\nThis powerful skill allows you to extract, manipulate, and analyze data from the web, turning unstructured data into structured data ready for insights and decision-making.\nBy knowing how to automate these processes with Python, you can save considerable time and resources, opening up new opportunities for extracting value from the vast data landscape of the internet.\nHTTP Headers\nIn this section, I am going to cover the concept of headers with some examples. So, let\u2019s jump on it.\nYou might already know when you make API calls, you transfer a piece of information within that envelope. Let\u2019s say one person is a client and another person is a server and an envelope is getting transferred in the form of API and that is the mode of communication.\nThe contents inside that envelope are actually the data that is getting transferred from one person to another but you might also know that when such communications happen in real life on the top of the envelope there is also the address to whom this data has to go. But along with that address, there is another address that is used when the letter is not received by the receiver.\nThis is just an analogy but what I am trying to explain to you is that header also plays a similar kind of role.\nHeaders are a sort of indication for the metadata of what the response or requests consist of inside. Now, to understand this let me categorize headers for you. So, mainly they can be categorized into four different categories.\nRequest Headers\nResponse Headers\nPayload Headers\nRepresentation Headers\nIt does not mean that a request header cannot be a response header or vice-versa. Let\u2019s understand what each of these headers actually means.\nRequest Headers\nIt is a key value pair just like other headers and they are sent by the client who is requesting the data. It is sent so that the server can understand how it has to send the response. It also helps the server to identify the request sender.\nExamples of Request headers are\nHost: www.medium.com\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\nReferer:\u00a0https://medium.com\nConnection: close\nAccept-Language: en-us\nAccept-Encoding; gzip\nDo remember\nContent-Type\u00a0header is not a request header\n, it is a representation header. We will learn more about this but I just wanted to remove this confusion from your mind as the earliest.\nFrom the list of sample headers shown above, the\nHost\nand\nUser-Agent\nare holding the information that who is sending the request.\nAccept-Language tells the server that this is the language in which I can understand your response and similarly\nAccept-Encoding\ntells the server that even if you have compressed data I can understand it.\nRead More:\nWhat Are User-Agents in Web Scraping & How to Use Them Effectively\nResponse Headers\nThey are just like request headers but the transmission is in reverse. Actually, these headers are sent by the server to the client. It explains to the client what to do with the response. It provides additional information about the data it has sent.\nExample of Response headers:\nConnection: keep-alive\nDate: Mon, 08 Nov 2022\nServer: nginx\nContent-Type: text/html\nTransfer-Encoding: chunked\nEtag: W/\u201d0815\u201d\nEtag\nis the response header that is used for versioning and cache. The\nDate\nis telling the client the date at which the response was sent from server to client. But again\nContent-Type\nor\nContent-Encoding\nare representation headers which we are going to cover in a bit.\nRepresentation Headers\nRepresentation headers represent the type of data that has been transferred. The data that has been sent from the server to the client can be in any format like JSON, HTML, XML, chunked (if the data size is huge), etc. The server also tells the client about the range of the content.\nExamples of Representation headers:\nContent-Type: text/html\nContent-Encoding: gzip\nContent-Length: 3523\nContent-Range: bytes 50\u20131000/*\nContent-Location: /docs/fo.xml\nContent-Location tells the client about the alternate location of the resource or the data that is available for the client to retrieve the information. It can be a URL where that particular resource is stored.\nApart from these headers, there can be different headers like Trailer, Transfer-Encoding, Etag, if-Not-Match, Authorizations, etc.\nNow, what if you are writing APIs and you want to define your own custom headers? Can you do that? You can absolutely do that. The way in which you define the request and response structure of your API similarly you can implement custom headers that you or the server is going to accept.\nAn example of a custom header could be the\nAuthorization\nheader. This header can have any value. Further, a server can use the value to identify the client or it can be used for any other logic operations.\nRequests\nIn this section, we are going to learn about\npython library\u00a0requests\nand with the help of this library, we are going to scrape a website. So, why do we need this library and how can we use it?\nIt is the most popular library downloaded by everyone. It allows us to make an http request to different websites. It opens a socket to the target website and asks them for their permission to connect. This is how multiple applications can talk with each other.\nNow, let\u2019s understand how we can use it with a simple web scraping example. We will scrape\namazon\nfor this example.\nmkdir scraper pip install requests\nThen create a file scraper.py in this folder and then start coding with me.\nimport requests #This will import the requests library inside our file. Now, we can use it to create a web scraper. target_url = \"https://www.amazon.com/dp/B08WVVBWCN\" headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"} resp = requests.get(url, headers=headers).text print(resp.status_code)\nHere we have declared a\ntarget_url\nvariable that stores our target URL from amazon.com. Then we declared a header and then finally we made a GET request to our target URL. This is what happens when we run this code.\nWhen we print the status we get the status as 200 which means we were able to scrape amazon successfully. You can even print the HTML code we received from amazon by just replacing\nstatus_code\nwith\ntext\n.\nprint(resp.text)\nIt will look something like this.\nAs you can see this data is not readable at all. We need to parse the data out from this junk. For this, we will use\nBeautifulSoup\n.\nBeautifulSoup\nIt is also known as BS4. So, it is basically used for pulling data out of any HTML or XML files. It is used for searching and modifying any HTML or XML data.\nNow lets us understand how we can use it. We will use HTML data from our last section. But before anything, we have to import it into our file.\nfrom bs4 import BeautifulSoup\nFrom our target page, we will extract a few important data like name, price, and product rating. For extracting data we will need a parse tree.\nsoup=BeautifulSoup(resp.text, \u2019html.parser\u2019)\nWhen you inspect the\nname\nyou will see that it is stored inside a class\na-size-large product-title-word-break.\nname = soup.find(\"span\",{\"class\":\"a-size-large product-title-word-break\"}).text print(name)\nWhen we print the name we get this.\nAs you can see we got the name of the product. Now, we will extract the price.\nBy inspecting the price I can see that the price is stored inside\na-offscreen\nclass and this class is\nstored\ninside\npriceToPay\nclass.\nprice = soup.find(\"span\",{\"class\":\"priceToPay\"}).find(\"span\",{\"class\":\"a-offscreen\"}).text print(price)\nWhen we print it we get this.\nNow, the last part is to extract the rating of the product.\nAs you can see the rating is stored inside a class\na-icon-star\n.\nrating = soup.find(\u201ci\u201d,{\u201cclass\u201d:\u201da-icon-star\u201d}).text\nSo, when we print this we get this.\n>>> 4.9 out of 5 stars\nBut if you just need the 4.9 part and you want to remove all of the extra text then we will use the split function of python.\nrating = soup.find(\u201ci\u201d,{\u201cclass\u201d:\u201da-icon-star\u201d}).text.split(\u201c \u201c)[0]\nThis will provide us with just the rating part.\n>>> 4.9\nWe were able to parse out all the necessary data from the junk HTML we got in the first section by making a GET request through the requests library.\nNow, what if you have to store this data in a CSV file? We will require the\nPandas\nlibrary for this task.\nRead More:\nBeautifulSoup to extract data from HTML\nXPath\nXPath stands for\nXML path language\nwhich is actually a query language for selecting nodes from an XML document. Now, if you do not know about XML documents then\nweb scraping with XPath\ncovers everything for you.\nXML stands for\nExtensible Markup Language\nwhich is a bit like your hypertext markup language which is HTML but there is a very distinct difference between the two\n. HTML\nhas a predefined set of tags that have a special meaning for example you have a body tag or you have a head tag or a paragraph tag. So, all these tags have a special meaning to your browser, right? But for XML there is no such thing. In fact, you can give any name to your tags and they do not have any special meaning there.\nThe design goal of XML documents is that they emphasize simplicity, generality, and usability across the internet. That\u2019s why you can use any name for your tags and nowadays XML is generally used for the transfer of data from one web service to another. So, that is another main use of XML.\nComing back to Xpath, well it is a query language for XML documents and the special thing to note here is that it is used for selecting nodes. Now, you might be thinking what are these nodes or this node terminal, right? Well, you can think of any XML document or even any HTML document like a tree.\nNow, why I am saying that is because if you try to see this particular XML document you have a tag called \u201cMovie Database\u201d in which you have multiple movie tags then in each movie you have a title tag, year tag, directed by tag, and so on.\nSo, in this way, we are creating a nested structure, and if you try to visualize a tree we can. We have a movie database tag in which we can have multiple movies in each movie we have a title, year, etc. Similarly, in the cast tag we have actors with different tags for first name and last name.\nSo, this nesting of the tags allows you to visualize the XML or HTML documents like trees. That\u2019s why we have the concept of nodes in the trees. So, all these tag elements are the nodes of your tree. Similarly, HTML can be visualized and then parsed like a tree.\nFor parsing, we can use libraries like Beautifulsoup. So, HTML documents or XML documents can be visualized like a tree, and XML parts in a text can be used for querying and selecting some particular nodes which follow the pattern specified by the Xpath syntax to select some particular nodes.\nThis is the concept behind Xpath and now let me show you some examples so that we can understand Xpath syntax a bit.\nExample\nWe are not going to go into much detail about the Xpath syntax itself because in this video our main aim is to learn how to use Xpath for web scraping.\nSo, let\u2019s say I have an XML document in which this is the code. I have a bookstore tag at the root in which I have multiple book tags and inside that, I have title and price tags.\nYou can find this Xpath tester on this\nwebsite\n. This is where I am testing this XML and Xpath expression.\nNow, if I type \u201c/\u201d in that then it means I want to search from the root of your tree and I will write\nbookstore\n. So, what it will do is it will search from the root for the bookstore. So, now if I click\nTEST XPATH\nI will get this.\nThis is the complete bookstore. Now, let\u2019s say in the bookstore I want to get all the books that we have. So, for that, you will do this.\nAnd then I will get this result. I got all the books inside the bookstore.\nNow, let\u2019s say you want to get only that book whose ID is 2. So, you will just put a square bracket, and inside that, you will pass \u2018@id=\u201d2\u201d\u2019.\nWhen you use @ with some attribute then you are referring to a particular attribute inside your book tag in this case and you are saying hey! find all those book tags whose ID is 2. When we run it we get this.\nLook at this, we are getting only that book whose ID is 2. Now, let\u2019s say I want to get the price of that book whose ID is 2. For that, I will simply do this.\nAnd in response, I get this.\nSo, this is how Xpath works. Now, if you want to learn more about Xpath syntax then you can just visit\nw3schools\nfor more details. Other than that this is all we need to know in order to create a web scraper using it.\nLXML\nIt is a third-party library for working with XML. We have learned enough about XML in the previous section.\nLXML provides full XPath support and nice\nfactory functions\nthat make it a better choice. The goal of LXML is to work with XML using the element tree API stored in lxml etree.\nLXML can read from files or string objects of XML and parse them into etree elements.\nNow, let\u2019s understand how we can use lxml while web scraping. First, create a folder and install this library.\nmkdir scraper pip install lxml\nOnce that is done, create a scraper.py file inside your folder scraper and start coding with me.\nfrom lxml import html import requests\nWe have imported the requests library to request because we have to get the HTML data of that web page as well.\nurl=\u201dhttps://en.wikipedia.org/wiki/Outline_of_the_Marvel_Cinematic_Universe\u201d\nand then we will send an HTTP request to our URL.\nurl=\u201dhttps://en.wikipedia.org/wiki/Outline_of_the_Marvel_Cinematic_Universe\u201d\nNow, if you will run it you will get\n200\ncode which means we have successfully scraped our target URL.\nNow, let\u2019s create a parse tree for our HTML document.\ntree = html.fromstring(resp.content)\nhtml.fromstring\nis a function that takes your HTML content and creates a tree out of it and it will return you the root of that tree. Now, if you print the tree you will get this\n<Element html at 0x1e18439ff10>.\nSo, it says we have got HTML elements at some position, and as you know HTML tag is the root of any HTML document.\nNow, I want to search certain elements using Xpath. We have already discovered the Xpath earlier in this article. Xpath of our target element is\n//*[\n@id\n=\u201dmw-content-text\u201d]/div[1]/table[2]/tbody/tr[3]/th/i/a\nelements = tree.xpath(\u2018//*[@id=\u201dmw-content-text\u201d]/div[1]/table[2]/tbody/tr[3]/th/i/a\u2019)\nWe have passed our Xpath inside the tree function. Do remember to use single or triple quotes while pasting your Xpath because python will give you an error for double quotes because our Xpath already has them.\nLet\u2019s print and run it and see what happens.\n[Element a at 0x1eaed41c220]\nOn running the code we got our target element which was matched with this particular Xpath.\nyou will get this\n<Element a at 0x1eaed41c220>.\nAs you can see it is an anchor tag. We have two options to get the data out of this tag.\n.text\nwill return the text the contains. Like\nelements[0].text\nwill return Iron Man\n.attrib\nwill return a dictionary\n{\u2018href\u2019: \u2018/wiki/Iron_Man_(2008_film)\u2019, \u2018title\u2019: \u2018Iron Man (2008 film)\u2019}.\nThis will provide you with the href tag which is actually the link and that is what we need. We also get the title of the movie.\nBut since we only need href tag value so we will do this\nelements[0].attrib[\u2018href\u2019]\nThis will return the target link.\nThis is what we wanted.\nPandas\nPandas\nis a Python library that provides flexible data structures and makes our interaction with data very easy. We will use it to save our data in a CSV file.\nobj={} arr=[] obj[\"name\"] = soup.find(\"span\",{\"class\":\"a-size-large product-title-word-break\"}).text.lstrip() obj[\"price\"] = soup.find(\"span\",{\"class\":\"priceToPay\"}).find(\"span\",{\"class\":\"a-offscreen\"}).text obj[\"rating\"] = soup.find(\"i\",{\"class\":\"a-icon-star\"}).text.split(\" \")[0] arr.append(obj)\nFirst, we declared an object and an array. Then we stored all our target data inside this object. Then we pushed this object inside an array. Now, we will create a data frame using pandas with this array, and then using that data frame we will create our CSV file.\ndf = pd.DataFrame(arr) df.to_csv('amazon_data.csv', index=False, encoding='utf-8')\nThis will create a CSV file by the name amazon_data.csv inside your folder.\nPandas made our job a lot easier. Using this technique you can scrape amazon pages at any scale.\nComplete code\nimport requests from bs4 import BeautifulSoup import pandas as pd obj={} arr=[] url = \"https://www.amazon.com/dp/B08WVVBWCN\" headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"} resp = requests.get(url, headers=headers) print(resp.status_code) soup=BeautifulSoup(resp.text,'html.parser') obj[\"name\"] = soup.find(\"span\",{\"class\":\"a-size-large product-title-word-break\"}).text.lstrip() obj[\"price\"] = soup.find(\"span\",{\"class\":\"priceToPay\"}).find(\"span\",{\"class\":\"a-offscreen\"}).text obj[\"rating\"] = soup.find(\"i\",{\"class\":\"a-icon-star\"}).text.split(\" \")[0] arr.append(obj) df = pd.DataFrame(arr) df.to_csv('amazon_data.csv', index=False, encoding='utf-8') print(arr)\nSummary\nAs you saw Requests, BS4, and pandas made our job of extracting data from Amazon a lot easier. Obviously, if you want to scrape millions of Amazon pages with a requests library then you will have to manage many things like proper headers, proxy rotation, and captcha handling.\nBut but but,\nif\nyou use Scrapingdog\u2019s Web Scraping API\nthen\nyou won\u2019t have\nto\nhandle those extra steps at your\nend\n. Scrapingdog will use its large pool\nof\nproxy\nand\nheaders\nto\nscrape amazon successfully.\nThis data extracting tool is not restricted to just amazon, you can scrape any website even if it requires JS rendering.\nScrapingdog is the fastest and the most reliable web scraping API and of course, we provide 1000 free API credits to our new users.\nIf you want to learn to scrape other websites like Google, yelp, etc using requests and BS4 then read the following articles:\nWeb scraping Google search results with Python\nScrape website behind authentication with Python\nScrape Yelp with Python\nScrape LinkedIn Jobs using Python\nScrapy\nIt is a powerful Python framework that is used to extract data from any website in a very flexible manner. It uses Xpath to search and extract data. It is lightweight and very easy for beginners to understand.\nNow, to understand how Scrapy works we are going to scrape\nAmazon\nwith this framework. We are going to scrape the book section of Amazon, more specifically we are going to scrape books that were released in the last 30 days.\nI have also written a guide on\nWeb scraping Amazon with Python\ndo check that out.\nWe will start with creating a folder and installing Scrapy.\nmkdir scraper pip install scrapy\nNow, before we start coding we have to create a project. Just type the below command in your terminal.\nscrapy startproject amazonscraper\nThis command will create a project folder inside\nscraper\nfolder by the name\namazonscraper\n.\nThe above command also returns some messages on the terminal where it is telling you how you can start writing your own scraper. We will use both of these commands.\nLet\u2019s go inside this\namazonscraper\nfolder first.\ncd amazonscraper scrapy genspider amazon_spider amazon.com\nThis will create a general spider for us so that we don\u2019t have to create our own spider by going inside the spider folder, this will automatically create it for us. Then we name the spider and then we type the domain of our target website.\nWhen you press enter you will have a file by the name amazon_spider.py inside your folder. When you open that file you will find that a parse function and an Amazonspider class have been automatically created.\nimport scrapy class AmazonSpiderSpider(scrapy.Spider): name = \u2018amazon_spider\u2019 allowed_domains = [\u2018amazon.com\u2019] start_urls = [\u2018http://amazon.com/'] def parse(self, response): pass\nWe will remove the allowed_domains variable as we do not need that and along with that, we will declare start_urls to our target URL.\n//amazon_spider.py import scrapy class AmazonSpiderSpider(scrapy.Spider): name = \u2018amazon_spider\u2019 allowed_domains = [\u2018amazon.com\u2019] start_urls = [\u2018https://www.amazon.com/s?k=books&i=stripbooks-intl-ship&__mk_es_US=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=11NL2VKJ00J&sprefix=bo%2Cstripbooks-intl-ship%2C443&ref=nb_sb_noss_2'] def parse(self, response): pass\nBefore we begin with our scraper we need to create some items in our items.py file which are temporary containers. We will scrape the title, price, author, and image link from the Amazon page.\nSince we need four items from Amazon we will add four variables for storing the values.\n//items.py import scrapy class AmazonscraperItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() product_name = scrapy.Field() product_author = scrapy.Field() product_price = scrapy.Field() product_imagelink = scrapy.Field() pass\nNow, we will import this file into our amazon_spider.py file.\n//amazon_spider.py from ..items import AmazonscraperItem\nJust type it at the top of the file. Now, inside our parse method, we are going to declare a variable which will be the instance of\nAmazonscraperItem\nclass.\ndef parse(self, response): items = AmazonscraperItem() pass\nWe are now ready to scrape our target elements from Amazon. We will start with scraping the product name.\nWe will declare a variable product_name which will be equal to a CSS selector for the product name element.\ndef parse(self, response): items = AmazonscraperItem() product_name= response.css() pass\nHere I am going to use the\nSelectorGadget\nextension to get the element location on the target page.\nAt the bottom right you can see our CSS selector. I am just going to copy it from here and I will paste it into our code.\ndef parse(self, response): items = AmazonscraperItem() product_name= response.css(\u2018.a-size-medium\u2019).extract() pass\nI have used the\n.extract()\nfunction to get the HTML part of all those product elements. Similarly, we are going to use the same technique to extract product price, author, and image link.\nWhile finding CSS selectors for the author\nSelectorGadget\nwill select some of them and will leave many authors unselected. So, you have to select those authors as well.\ndef parse(self, response): items = AmazonscraperItem() product_name= response.css(\u2018.a-size-medium\u2019).extract() product_author = response.css(\u2018.a-color-secondary .a-row .a-size-base+ .a-size-base , .a-color-secondary .a-size-base.s-link-style , .a-color-secondary .a-size-base.s-link-style font\u2019).extract() pass\nNow, let\u2019s find the CSS selector for the price as well.\ndef parse(self, response): items = AmazonscraperItem() product_name= response.css(\u2018.a-size-medium\u2019).extract() product_author = response.css(\u2018.a-color-secondary .a-row .a-size-base+ .a-size-base , .a-color-secondary .a-size-base.s-link-style , .a-color-secondary .a-size-base.s-link-style font\u2019).extract() product_price = response.css(\u2018.s-price-instructions-style .a-price-fraction , .s-price-instructions-style .a-price-whole\u2019).extract() pass\nFinally, now we will find the CSS selector for the image.\n.s-image\nis the CSS selector for our images.\ndef parse(self, response): items = AmazonscraperItem() product_name= response.css(\u2018.a-size-medium\u2019).extract() product_author = response.css(\u2018.a-color-secondary .a-row .a-size-base+ .a-size-base , .a-color-secondary .a-size-base.s-link-style , .a-color-secondary .a-size-base.s-link-style font\u2019).extract() product_price = response.css(\u2018.s-price-instructions-style .a-price-fraction , .s-price-instructions-style .a-price-whole\u2019).extract() product_imagelink = response.css(\u2018.s-image\u2019).extract()\nNow, as I said earlier this will only provide us with the HTML code and we need to extract the name from it. So, for that, we will use the text feature of Scrapy.\nThis will make sure that the whole tag does not get extracted and that only the text from this tag gets extracted.\nproduct_name= response.css(\u2018.a-size-medium::text\u2019).extract()\nBut because we are using multiple classes for the CSS selector that is why we can\u2019t add this text at the end.\nWe have to use .css() function for product_price and product_author.\nproduct_author = response.css(\u2018.a-color-secondary .a-row .a-size-base+ .a-size-base , .a-color-secondary .a-size-base.s-link-style , .a-color-secondary .a-size-base.s-link-style font\u2019).css(\u2018::text\u2019).extract() product_price = response.css(\u2018.s-price-instructions-style .a-price-fraction , .s-price-instructions-style .a-price-whole\u2019).css(\u2018::text\u2019).extract()\nNow\nproduct_imagelink\nis just selecting the image so we will not use\n.css()\nfunction on it. Our image is stored inside the src tag and we need its value.\nWe will use the attr feature of Scrapy.\nproduct_imagelink = response.css(\u2018.s-image::attr(src)\u2019).extract()\nWe have managed to extract all the values. Now, we will store them in their individual temporary item containers, and this is how we do it.\nitems[\u2018product_name\u2019] = product_name\nThis product_name is actually the variable that we have declared in our items.py file. We are going to do this with all our other target elements.\nitems[\u2018product_name\u2019] = product_name items[\u2018product_author\u2019] = product_author items[\u2018product_price\u2019] = product_price items[\u2018product_imagelink\u2019] = product_imagelink\nNow, we just need to yield the items and this will complete our code. Our code might not at first but let\u2019s see what we have got.\nyield items\nNow, to run our code run the below command on your terminal.\nscrapy crawl amazon_spider\nAs you can see we got an empty array. This is due to the anti-bot mechanism of amazon. To overcome this we are going to set a\nUser-Agent\nin our settings.py file.\nUSER_AGENT = \u2018Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\u2019\nNow, let\u2019s try again.\nHurray!! we got the results. But as usual, this will not work for long as Amazon\u2019s anti-bot technique will kick in and your scraper will stop.\nFor scraping any number of pages you are advised to use a\nWeb Scraping API\n.\nComplete code\n//amazon_spider.py import scrapy from ..items import AmazonscraperItem class AmazonSpiderSpider(scrapy.Spider): name = \u2018amazon_spider\u2019 allowed_domains = [\u2018amazon.com\u2019] start_urls = [\u2018https://www.amazon.com/s?k=books&i=stripbooks-intl-ship&rh=n:283155,p_n_publication_date:1250226011&dc&language=es&ds=v1:0r+6Zb7Q60+15gaAfSXGzhcbIdyc5r/TuKQVY1NC/ew&__mk_es_US=\u00c5M\u00c5\u017d\u00d5\u00d1&crid=11NL2VKJ00J&qid=1662730061&rnid=1250225011&sprefix=bo,stripbooks-intl-ship,443&ref=sr_nr_p_n_publication_date_1'] def parse(self, response): items = AmazonscraperItem() product_name= response.css(\u2018.a-size-medium::text\u2019).extract() product_author = response.css(\u2018.a-color-secondary .a-row .a-size-base+ .a-size-base , .a-color-secondary .a-size-base.s-link-style , .a-color-secondary .a-size-base.s-link-style font\u2019).css(\u2018::text\u2019).extract() product_price = response.css(\u2018.s-price-instructions-style .a-price-fraction , .s-price-instructions-style .a-price-whole\u2019).css(\u2018::text\u2019).extract() product_imagelink = response.css(\u2018.s-image::attr(src)\u2019).extract() items[\u2018product_name\u2019] = product_name items[\u2018product_author\u2019] = product_author items[\u2018product_price\u2019] = product_price items[\u2018product_imagelink\u2019] = product_imagelink yield items\nand this is our items.py file\n//items.py import scrapy class AmazonscraperItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() product_name = scrapy.Field() product_author = scrapy.Field() product_price = scrapy.Field() product_imagelink = scrapy.Field() pass\nThe functionalities of Scrapy do not stop here!!\nYou can set a parallel request number in your settings.py file by changing the value of CONCURRENT_REQUESTS. This will help you to check how much load an API can handle.\nIt is faster than most of the HTTP libraries provided by Python.\nSelenium\nSelenium is a framework to test websites and other web applications. It supports multiple programming languages and on top of that, you get support from multiple browsers not just Chrome. It provides APIs to make connections with your driver.\nLet\u2019s understand this framework with a simple web scraping task. We are going to\u00a0scrape a dynamic website with selenium. Our\ntarget website will be\u00a0Walmart\n. The first step is to install selenium. Type the below command on your terminal to install Selenium.\nAlso, I have a dedicated article made on\nscraping walmart product details using Python\n. Do check that out too! (But, let us focus on this article first)\npip install selenium\nOur job would be to open this website and extract the HTML code and print it.\nSo, the first step is to import all the libraries in our file.\nfrom selenium import webdriver from selenium.webdriver.chrome.options import Options\nThen we are going to set the options which selenium provides. We will set the page size and we will run it in a headless format.\nThe reason behind running it in a headless form is to avoid extra usage of GUI resources. Even while using selenium in production on external servers, you are advised to use it with headless mode to avoid wasting CPU resources and reduce\nthrottling\nrisks. This will ultimately increase your cost because you will need to add more servers for load balancing.\noptions = Options() options.headless = True options.add_argument(\u201c \u2014 window-size=1920,1200\u201d)\nNow, we will declare our driver and you have to use the path where your chromium driver is installed.\nPATH_TO_DRIVER='YOUR_PATH_TO_CHROIUM_DRIVER' driver = webdriver.Chrome(options=options, executable_path=PATH_TO_DRIVER) url=\"https://www.walmart.com/search/?query=python%20books\"\nWe have also declared our target URL. Now, we just need to use it\u2019s .get() method to open the driver.\ndriver.get(url) time.sleep(4) print(driver.page_source)\nI used the sleep method to load the website completely before printing the HTML. I just want to make sure that the website is loaded completely before printing.\nWhile printing we have used\npage_source\nproperty of selenium. This will provide us with the source of the current page. This is what we get when we print the results.\nWe get the required HTML part. Now, Walmart also has an anti-bot detection method just like amazon but Walmart needs\u00a0JS rendering\u00a0also for scraping.\nTo scrape websites like Walmart you can always use Scrapingdog\u2019s Web Scraping Tool to avoid managing JS rendering and proxy rotation.\nI have created a separate blog on\nweb scraping with Selenium here\n. Do check it out!!\nThe reason behind using JS rendering for certain websites is:\nTo load all the javascript hooks, once all of them are loaded we can easily scrape it at once by just extracting the source after loading it completely on our browser.\nSome websites need lots of AJAX calls to load completely. So, in place of a normal GET HTTP call, we render JS for scraping. To verify whether a website needs a JS rendering or not you can always look at the network tab of that website.\nIt also provides certain properties which might help you in the future.\ndriver.title\n\u2014 This can be used for extracting the title of the page.\ndriver.orientation\n\u2014 This will provide the physical orientation of the device with respect to gravity.\nAdvantages of using Selenium\nThe best advantage I found is you can use it with any programming language.\nYou can find bugs at an earlier stage of your testing or production.\nIt has great community support.\nIt supports multiple browsers like Chrome, Mozilla, etc.\nVery handy when it comes to\u00a0data scraping.\nDisadvantages of Using Selenium\nImage comparison is absent in selenium.\nTime-consuming.\nThe setup of the test environment is not that easy for beginners.\nPlaywright\nPlaywright\nis a powerful automation framework developed by Microsoft that lets you control browsers programmatically. It supports multiple browsers (Chromium, Firefox, WebKit) and works with several programming languages, including Python. One of Playwright\u2019s strengths is\nbuilt-in support for handling dynamic, JavaScript-heavy pages\n, making it ideal for modern web scraping.\nLet\u2019s understand Playwright with a simple scraping example. We\u2019ll target Walmart again and extract the HTML of a search results page.\npip install playwright playwright install\nOur job will be to open the Walmart search page, wait for the JavaScript to load, and then print the HTML.\nStart by importing the library:\nfrom playwright.sync_api import sync_playwright import time\nNow, we\u2019ll launch the browser in\nheadless mode\nto save resources and avoid unnecessary GUI usage \u2014 this is recommended when running in production or on servers.\nwith sync_playwright() as p: browser = p.chromium.launch(headless=True) page = browser.new_page() url = \"https://www.walmart.com/search/?query=python%20books\" page.goto(url) time.sleep(4) # wait for JS and AJAX calls to complete print(page.content()) # prints the full rendered HTML browser.close()\nHere\u2019s what\u2019s happening:\nplaywright.install()\ndownloads the necessary browser binaries.\nWe use\nchromium.launch(headless=True)\nto run the browser in headless mode.\npage.goto(url)\nloads our target page.\ntime.sleep(4)\nensures all JavaScript and network requests are completed.\npage.content()\nreturns the fully rendered HTML.\nTip:\nInstead of a fixed\nsleep\n, you can use Playwright\u2019s\nwait_for_selector\nto wait for a specific element to appear \u2014 this is more reliable for dynamic content:\npage.wait_for_selector(\"div.search-result-gridview-items\")\nThis ensures you\u2019re scraping only after the target elements are loaded.\nAdvantages of Using Playwright\nSupports Chromium, Firefox, and WebKit out of the box.\nGreat for scraping JavaScript-heavy sites.\nEasier and faster setup compared to Selenium.\nOffers powerful features like auto-waiting, request interception, and screenshot capture.\nSupports both synchronous and asynchronous APIs in Python.\nDisadvantages of Using Playwright\nSlightly larger installation size because of bundled browsers.\nNot as old or battle-tested as Selenium (but catching up fast).\nRequires Node.js internally (automatically handled during installation, but still adds to the footprint).\n\u201cIf you want to skip the complexity of browser automation and avoid managing proxies or JS rendering yourself, you can use Scrapingdog\u2019s Web Scraping API \u2014 it handles all this in the background, so you can just focus on the data.\nSelenium vs Playwright\nRegular Expression\nRegular expression is a powerful tool to find patterns in text. They are like using Ctrl-F on a word document but much more powerful than them.\nThis is very helpful when you verify any type of user input and most importantly while scraping the web. The application of Regular expression is very big.\nThis can be challenging at first but once you are ready, believe me, it will make your job much more efficient.\nIts symbols and syntax are universal in all programming languages. To understand regular expression we are going to validate certain strings which you might face while web scraping in Python.\nLet\u2019s say you want to scrape emails from the web for the lead generation process of your company. The first part of the email can consist of:\nUppercase letters [A-Z]\nLower Case letters [a-z]\nnumbers [0\u20139]\nNow, if the email which is scraped does not follow this pattern then we can easily neglect that email and can move on to another email. We will write a simple code in python to identify emails like these and we are going to use\nre library of python\n.\nimport re pattern = \"[a-zA-Z0\u20139]+@\"\nBrackets allow us to specify that we are looking for the characters in a given string such as email. We are going to match the pattern till @ symbol and the plus sign after the bracket means we are looking for any combination of one or more of these characters.\nSince emails are provided by many domains then we have to specify that we are looking for one or more upper and lowercase letters.\npattern = \u201c[a-zA-Z0\u20139]+@[a-zA-Z]\u201d\nNow, let\u2019s check whether this can work with an if and else statement.\nemail = input() if(re.search(pattern,email)): print(\u201cValid email\u201d) else: print(\u201cinvalid email\u201d)\nRun this file on your terminal to check.\nNow, let\u2019s try\n[email\u00a0protected]\n.\nThis is how you can identify correct email strings. Now, we will learn how we can replace a character with another one using a regular expression\nReplacing String\nThis can come in handy when you are making changes to a large database where you might have thousands of strings to update.\nNow, let\u2019s say we need every phone number entered into a continuous string of numbers with no hyphens but we want to keep the hyphens which are in word form. We will write regular expressions for that.\nimport re pattern = \"(\\d\\d\\d)-(\\d\\d\\d)-(\\d\\d\\d\\d)\"\n\u201c\\d\u201d will match any single digit. Each set of parenthesis resembles a group.\nnew_pattern = r\"\\1\\2\\3\"\nSo, from left to right we have three different groups. But we need to write what we want this pattern to turn into. Let\u2019s preserve the group but remove the hyphens.\nEach backslash number represents a group so our new pattern is concatenating the three groups without the hyphen. We have put\nr\nbefore the string to consider it as the raw string.\nNow, let\u2019s take input from the user and check whether it works or not.\nimport re pattern = \u201c(\\d\\d\\d)-(\\d\\d\\d)-(\\d\\d\\d\\d)\u201d new_pattern = r\u201d\\1\\2\\3\" phoneNumber = input() final_output = re.sub(pattern, new_pattern, phoneNumber) print(final_output)\nThis was just a basic example of how regular expression can be used in data scraping with Python. Regular expression works with any language and the rate of response is pretty fast.\nYou can find tons of material on regular expression online. I found\nthis course\nvery helpful during my Python journey. Also, if you want to test your expression then this\nwebsite\ncan help you.\nUrllib3\nUrllib3 is an authentic python library for making HTTP requests to any web address. Now, why it is authentic is because unlike requests it is a built-in part of python. You can use this library if you want to reduce dependencies. This package contains\nfive modules\n:\nrequest\n\u2014 It is used to open URLs.\nresponse\n\u2014 This is used by the request module internally. You will not use it directly.\nerror\n\u2014 Provides error classes to request module.\nparse\n\u2013 It breaks URL into schema, host, port, path, etc.\nrobotparser\n\u2013 It is used to inspect the robots.txt file for permissions.\nNow, we will understand how urllib3 can be used through simple code.\nimport urllib3 http = urllib3.PoolManager() r = http.request(\u2018GET\u2019, \u2018https://www.scrapingdog.com/robots.txt') print(r.status) print(r.data)\nSteps will look similar to the requests library.\nPoolManager\nkeeps a track of a number of connections.\nThen we send a normal GET request to a robots.txt URL. We can even send POST and DELETE requests with urllib3.\n// POST request import urllib3 http = urllib3.PoolManager() r = http.request(\u2018POST\u2019, \u2018http://httpbin.org/post', fields={\u201cTitle\u201d: \u201cScrapingdog\u201d, \u201cPurpose\u201d: \u201cWeb Scraping API\u201d, \u201cFeature\u201d: \u201cFastest Web Scraper\u201d}) print(r.status) print(r.data)\nfields argument will send the data from the client to the server. We are sending a JSON object. The server will send a response to make the confirmation of data added to its database.\nThere are very high chances that as a beginner you might not use urllib3 for web scraping. Most probably you are going to use requests. But there are certain advantages of using urllib3 over requests.\nFor parsing data, you can use BS4 or RegEx.\nMechanicalSoup\nIt is like the child of BS4 because it takes the support of BS4 to mechanize everything. It allows us to do so much more with fewer lines of code. It automates website scraping and on top of that, it can follow redirects and can send and store cookies on its own.\nLet\u2019s understand MechanicalSoup a little with some Python code. You need to\ninstall\nit before we begin coding.\nimport mechanicalsoup browser = mechanicalsoup.StatefulBrowser()\nbrowser object will allow us to enter commands without the need of creating new variables. Now, we are going to open the target URL.\nurl=\"https://www.scrapingdog.com\" browser.open(url)\n.open()\nwill return an object of type requests. Response, this is due to the fact that Mechanical Soup is using the requests module to make the call.\nbrowser.get_current_page()\nwill provide you with the HTML code of the page. It also provides many arguments like\n.find_all()\nand\n.select_form()\nto search for any element or tag in our HTML data.\nAltogether it is a great library to try web scraping a little differently. If you want to learn more about this I would advise you to read this\narticle\n.\nHow to handle CAPTCHAs?\nOnce you start scraping a website at scale, you will start hitting a captcha. That captcha shows that you have been blocked from accessing the website as you were rate-limited. Web scraping with Python is great, but this approach will block your scraper and your data pipeline. You must add some power to your Python script using a\nWeb Scraping API\n.\nWeb Scraping APIs like Scrapingdog will help you bypass those limits. Scrapingdog will handle all the hassle of IP rotation to JS rendering on its own. You can start with a free trial by\nsigning up\n.\nConclusion\nWe discussed eight Python libraries that can help you scrape the web. Each library has its own advantage and disadvantage. Some are easy to use but not effective and some of them could be a little difficult to understand but once you have understood them fully it will help you to get things done in no time like RegEx.\nI have created a table to give you a brief idea of how all these libraries. I have rated them on the basis of difficulty, usage, and Application. I have given them numbers out of 5 so that you can understand how they can help in web scraping with Python.\nI hope you like this blog post, I have tried to mention all the popular Python libraries in this post.\nIf you think I have left some topics then please do let us know.\nAdditional Resources\nScrapy vs Beautifulsoup: Which is better?\nWeb Scraping Javascript vs Python\nDetailed Guide on Web Scraping with C sharp\nAutomating web scraping with Java\nHow to Use Proxy with Python Request\nFunctions in Python\ncURL web Scraping\nWeb Scraping with R\nWeb Scraping with Go\nWeb Scraping with Rust (Beginner-Friendly Tutorial)\nComplete Tutorial on Web Scraping with Java\nWeb Scraping with Nodejs\nNode Unblocker for Web Scraping\nFrequently Asked Questions\nIs Python good for web scraping?\nPython is the common language used in web scraping. It is an all round language and can handle web scraping smoothly. Therefore, python is recommended for web scraping.\nIs web scraping difficult?\nNo, basic scraping isn\u2019t difficult. However, to scale this process you would need an API.\nHow do I learn web scraping?\nThis tutorial here used all the libraries that are used in python and have extensively explained all of them.\nLearning web scraping with python is easy. Also, python is used world wide with ease and hence it is easy to learn web scraping with python.\nWhich is better Selenium or Beautiful Soup?\nBeautiful Soup is used for smaller projects while Selenium is used for a little complex projects. Hence, both have different advantages depending where we are using both libraries.\nCan I get sued for web scraping?\nNo, you can scrape any data that is available publicly on the web.\nWeb Scraping with Scrapingdog\nScrape the web without the hassle of getting blocked\nTry for Free\nContact sales\nMy name is Manthan Koolwal and I am the founder of scrapingdog.com. I love creating scraper and seamless data pipelines.\nManthan Koolwal\nRead More Blogs\nTwitter\nLinkedin-in\nMedium-m\nWeb Scraping with Scrapingdog\nScrape the web without the hassle of getting blocked\nTry for Free\nContact sales\nRecent Blogs\nHow to Scrape Amazon Data into Google Sheets Using the Scrapingdog Add-on\nLearn how to extract Amazon data directly into Google Sheets using our Scrapingdog add-on. This detailed guide is perfect for both beginners and pros.\n2025-09-10\nRead More\nHow To Extract Data from Websites to Google Sheets\nIn this blog, I have illustrated how you can use google sheets for scraping data from a website. Further, there are some limitations to this process, I have listed ways to overcome them.\n2025-09-09\nRead More\nTry Scrapingdog for Free!\nGet 1000 free credits to spin the API. No credit card required!\nStart your Free Trial\nProduct\nScrapingdog vs Competitors\nLearn Web Scraping\nCompany\nCompany\nProduct\nScrapingdog vs Competitors\nLearn Web Scraping\n\u00a9 2020-2025 Scrapingdog. All rights reserved.",
        "image_urls": [
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/google_maps.png",
            "score": 2
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/image-4-for-python-blog.png",
            "score": 2
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/image-22-for-python-blog.jpg",
            "score": 2
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/image-45-for-python-blog-792x1024.jpg",
            "score": 2
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2025/09/How-to-Scrape-Amazon-Data-into-Google-Sheets.png",
            "score": 2
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/Google-Sheet-Scraping.png",
            "score": 2
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/dog.svg",
            "score": 2
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/image-2-for-python-blog.jpg",
            "score": 1
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/image-5-for-python-blog.jpg",
            "score": 1
          },
          {
            "url": "https://www.scrapingdog.com/wp-content/uploads/2024/08/image-6-for-python-blog.jpg",
            "score": 1
          }
        ],
        "title": "Python Web Scraping Guide | Scrapingdog"
      },
      {
        "url": "https://www.hostinger.com/tutorials/python-web-scraping",
        "raw_content": "Python Web Scraping Tutorial\nkeyboard_arrow_down\nCategories\nAll Tutorials\nWordPress\nVPS\nWebsite development\nEcommerce\nHostinger Horizons\nHow to make a website\nsearch\nclose\nVPS\nPython\nApr 23, 2025\nValentinas C.\n11min Read\nThe basics of Python web scraping\nCopy link\nCopied!\nWeb scraping is a valuable skill. It allows you to collect and analyze large amounts of data from web pages with almost no manual effort through automatic extraction. Python is a top choice for this task due to its beginner-friendly syntax and ready-to-use modules, which make it easy to write web scraping scripts.\nIn this article, we will share a step-by-step guide on Python web scraping using an Ubuntu VPS.\nPrerequisites\nTo follow along with this Python web scraping tutorial, you will need:\nAn Ubuntu VPS with\nPython pip\nand venv module installed.\nSecure Shell (SSH) access to the VPS.\nBasic knowledge of how to run commands on a terminal.\nWhile you can technically write Python code for web scraping without using a Virtual Private Server (VPS), We recommend using one, especially for beginners. With its dedicated resources, a\nVPS hosting plan\nwill provide more stability and better performance for web scraping, especially for large-scale tasks. For example, if your script is taking too long to execute on your local machine or consuming too much memory, you can switch to a VPS to ramp up your scraping power.\nHow to web scrape with Python\nFollow these steps to set up your first web scraping project.\nSetting up your environment for Python web scraping\nStart by logging in to your VPS via SSH. You can use a SSH client, like\nPuTTY\nfor this purpose.\nSimply download and install PuTTY, launch it, enter the IP address of your VPS, and then log in using your credentials. If you are a Hostinger user, you can find your VPS login credentials by navigating to\nhPanel\n\u2192\nVPS\n\u2192\nManage\n\u2192\nSSH access\n.\nOnce you are logged in, run these commands in order.\nThe first will create a new virtual environment for Python.\npython3 -m venv myenv\nThe below command activates the virtual environment. In other words, you are now inside your own virtual environment and ready to start.\nsource myenv/bin/activate\nThe last command installs\nBeautiful Soup\n, which is one of the most popular Python web scraping libraries. It will load the\nrequests\npackage for sending HTTP requests.\npip install requests beautifulsoup4\nMaking your first request\nPython\u2019s\nrequests\nlibrary provides a user-friendly interface ideal for interacting with web servers through HTTP requests. To make our first request, let\u2019s start with a simple Python script \u2013 a file containing Python code that can be executed to perform specific tasks.\nOur script will use the\nrequests\nlibrary to send an HTTP GET request and print the HTML response.\nYou can use the\ntouch command\nto do so:\ntouch temp.py\nOpen the file in your favorite editor, paste the following code into it, and then save it.\nimport requests\n# Send a GET request to the URL\nresponse = requests.get('https://www.hostinger.com/tutorials/how-to-run-a-python-script-in-linux')\n# Print the HTML content of the page\nprint(response.text)\nNow, run the script with this command:\npython3 temp.py\nAfter running the command, you should see a large amount of HTML content printed on your console.\nExtracting data with Beautiful Soup\nNow that we have a basic idea of how HTTP requests and responses work let\u2019s see how we can extract some data from the retrieved response object. For this purpose, we will use\nBeautiful Soup\n. This Python library parses HTML content and HTML data into a tree-like structure, making it easy to navigate and extract specific information.\nUse the following command to create a new script named\nscraping.py.\ntouch scraping.py\nOpen the file in your favorite editor and paste the following code to it:\nimport requests\nfrom bs4 import BeautifulSoup\n# Send a GET request to the URL\nresponse = requests.get('https://www.hostinger.com/tutorials/how-to-run-a-python-script-in-linux')\n# Parse the HTML content using BeautifulSoup\nsoup = BeautifulSoup(response.text, 'html.parser')\n# Find all elements with a specific tag (e.g. all h2 headings)\ntitles = soup.find_all('h2')\n# Extract text content from each H2 element\nfor title in titles:\nprint(title.text)\nIn this code, we are sending an HTTP GET request to the same URL and parsing the HTML content using\nBeautiful Soup\n. Then, we will use the\nfind_all\nfunction to retrieve all H2 headings from the parsed content. Finally, we need to print the text content for each H2 heading.\nRun this command to execute the script:\npython3 scraping.py\nOn your console, you should see a list of all H2 headings from the visited URL, like in the image below.\nParsing HTML and navigating the DOM tree\nWe\u2019ve now seen how\nBeautiful Soup\nextracts data by finding specific elements. However, websites often have complex structures, and you may need to navigate much deeper to reach the information you need. This is why it\u2019s important to understand how the Document Object Model (DOM) works, and how you can traverse it and retrieve data using\nBeautifulSoup\n.\nThe DOM represents an HTML document, the core of all web data, as a tree structure, where elements like\n<div>, <h1>,\nand\n<p>\nare nodes with parent-child relationships. We can use\nBeautiful Soup\nfunctions to traverse this tree and locate specific website data points.\nTo explore the concept in more depth, we will update our\nscraping.py\nscript to locate different structures inside the HTML. Replace the contents of the\nscraping.py\nfile with this code.\nBefore we run this code, however, let\u2019s explore what different parts of it are doing. This will help you better understand the fundamentals of web scraping in Python.\nThe below section of this code allows us to import the required libraries, send a GET request, and parse the HTML elements to respond to it:\nimport requests\nfrom bs4 import BeautifulSoup\n# Send a GET request to the URL\nresponse = requests.get('https://www.hostinger.com/tutorials/how-to-run-a-python-script-in-linux')\n# Parse the HTML content using BeautifulSoup\nsoup = BeautifulSoup(response.text, 'html.parser')\nNext, this portion is used to retrieve the first <h1> tag in the HTML document, and then print the text inside it:\n# Find the first <h1> tag\nfirst_header = soup.find('h1')\nprint('First <h1> tag text:', first_header.text)\nNow, we find all the\n<a>\ntags, i.e. links, in the HTML documents and store them in the\nall_links\nlist. Then, we run a\nfor loop\nto iterate through each link and print the\nhref\nattribute of each\n<a>\ntag.\n# Find all <a> tags (links)\nall_links = soup.find_all('a')\nprint('All <a> tag hrefs:')\nfor link in all_links:\nprint(link.get('href'))\nWe are ready to extract the\n<a>\nHTML tags from the list of links, and then print the text and href attribute together. This demonstrates how you can dig deep into a particular attribute, HTML string, or HTML element if you desire, perfectly demonstrating how web scraping can be of use for analyzing data.\n# Access attributes of an element\nfirst_link = all_links[0]\nprint('First link text:', first_link.text)\nprint('First link href:', first_link.get('href'))\nLastly, the\nif statement\nchecks if we were able to find the first header in part 2. Then, we get the parent HTML element of the first\n<h1>\ntag and print its name. Finally, we find the next sibling of the first\n<h1>\ntag and print its name. If there is no next sibling, \u201cno next sibling\u201d will be printed. This demonstrates how you can navigate through different levels of the DOM tree, such as moving to parent elements and sibling elements.\n# Navigate using parent and siblings\nif first_header:\nparent_element = first_header.parent\nprint('Parent of first <h1> tag:', parent_element.name)\nC div exists as an HTML element. If it does, it finds the first\n<span>\nchild element inside this\n<div>\nand prints its text. If the div is not found, it logs a message on the screen to indicate that. This demonstrates how you can navigate the DOM tree to locate specific elements and extract their content.\n# Navigate the DOM tree\n# Example: Find a div with a specific class, then find a child element\nspecific_div = soup.find('div', class_='d-flex')\nif specific_div:\nchild_element = specific_div.find('span')\nif child_element:\nprint('Text of child <span> in specific div:', child_element.text)\nelse:\nprint('Div with class \"d-flex\" n\nnext_sibling = first_header.find_next_sibling()\nprint('Next sibling of first <h1> tag:', next_sibling.name if next_sibling else 'No next sibling')\nNow, you execute the\n.py\nfile script via this command:\npython3 scraping.py\nExpect an output like this:\nThe output above shows:\nThe H1 tag.\nAll the <a> tags.\nThe text and link of the first <a> tag.\nText of the child element of a div with a specific class.\nThe parent and sibling of the first H1 tag.\nFor your reference, this is the complete code to paste over, with all functions included:\nimport requests\nfrom bs4 import BeautifulSoup\n# Send a GET request to the URL\nresponse = requests.get('https://www.hostinger.com/tutorials/how-to-run-a-python-script-in-linux')\n# Parse the HTML content using BeautifulSoup\nsoup = BeautifulSoup(response.text, 'html.parser')\n# Find the first <h1> tag\nfirst_header = soup.find('h1')\nprint('First <h1> tag text:', first_header.text)\n# Find all <a> tags (links)\nall_links = soup.find_all('a')\nprint('All <a> tag hrefs:')\nfor link in all_links:\nprint(link.get('href'))\n# Access attributes of an element\nfirst_link = all_links[0]\nprint('First link text:', first_link.text)\nprint('First link href:', first_link.get('href'))\n# Navigate the DOM tree\n# Example: Find a div with a specific class, then find a child element\nspecific_div = soup.find('div', class_='d-flex')\nif specific_div:\nchild_element = specific_div.find('span')\nif child_element:\nprint('Text of child <span> in specific div:', child_element.text)\nelse:\nprint('Div with class \"d-flex\" not found')\n# Navigate using parent and siblings\nif first_header:\nparent_element = first_header.parent\nprint('Parent of first <h1> tag:', parent_element.name)\nnext_sibling = first_header.find_next_sibling()\nprint('Next sibling of first <h1> tag:', next_sibling.name if next_sibling else 'No next sibling')\nStoring scraped data\nAfter scraping all the data you need, you\u2019ll often need to store it for later use. Two common ways to store scraped data are by saving it to a CSV file or a database, like\nMongoDB\n. We\u2019ll update our script to use both.\nFirst, install the\npymongo\nlibrary by running the following command. This library will be used to write the web scraping data you have collected to a MongoDB instance.\npip install pymongo\nNext, add the following code to the top of your\nscraping.py\nfile. This code imports the libraries we will use to write to a CSV file and a\nMongoDB\ninstance.\nimport csv\nfrom pymongo import MongoClient\nimport sys\nNow, add the following to the end of your\nscraping.py\nfile.\nIn the below Python code, we are creating an object\ndata_to_store\nthat contains all the data we want to store in a CSV file and a\nMongoDB\ndatabase.\nThen, we use the\nCSV\nlibrary to write the data over to a new CSV file. Finally, we use the\nMongoClient\nobject to connect to a local MongoDB database and write the data to the\nscraped_data\ncollection.\n# Extracting data for storing\ndata_to_store = {\n'First_h1_tag': first_header.text,\n'First_link_text': first_link.text,\n'First_link_href': first_link.get('href')\n}\n# Storing data to a CSV file\ncsv_file = 'scraped_data.csv'\nwith open(csv_file, 'w', newline='', encoding='utf-8') as file:\nwriter = csv.DictWriter(file, fieldnames=data_to_store.keys())\nwriter.writeheader()\nwriter.writerow(data_to_store)\nprint('Data saved to CSV file:', csv_file)\n# Storing data to MongoDB\ntry:\nclient = MongoClient('mongodb://localhost:27017/')\ndb = client['scraping_db']\ncollection = db['scraped_data']\ncollection.insert_one(data_to_store)\nprint('Data saved to MongoDB collection: scraped_data')\nexcept Exception as e:\nprint('Error:', e)\nprint('Failed to connect to MongoDB. Exiting...')\nsys.exit(1)\nNote that you can connect to a remote MongoDB instance too by replacing the URL above. You may also specify different names for the MongoDB database and collection.\nIf you don\u2019t have a running MongoDB instance, the code will still work because we have added a try-except block to handle errors.\nLastly, execute the script by running this command:\npython3 scraping.py\nUpon successful execution, you should see the following lines at the bottom:\nData saved to CSV file: scraped_data.csv\nData saved to MongoDB collection: scraped_data\nIf you don\u2019t have a MongoDB database running, you should see an error on the terminal indicating that the data couldn\u2019t be saved to the MongoDB database. However, the CSV file should still be generated. To display its contents, run the following command:\ncat scraped_data.csv\nThe output should look like this:\nUsing regular expressions to scrape data\nRegular expressions (regex) are a powerful tool for pattern matching and can be very useful in web scraping when you need to extract data that follows a specific pattern. Let\u2019s walk through an example to illustrate how you can combine\nBeautiful Soup\nand regular expressions to scrape data.\nCreate a new file named\nregex.py\nand paste the following code to it:\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\n# Send a GET request to the URL\nresponse = requests.get('https://webscraper.io/test-sites/e-commerce/static/phones')\n# Parse the HTML content using BeautifulSoup\nsoup = BeautifulSoup(response.text, 'html.parser')\n# Define a regex pattern for matching email addresses\nemail_pattern = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}')\n# Find all text in the HTML that matches the email pattern\nemails = soup.find_all(string=email_pattern)\n# Print all matched email addresses\nfor email in emails:\nprint(email)\n# Define a regex pattern for matching URLs containing 'commerce'\nurl_pattern = re.compile(r'.*commerce.*')\n# Find all <a> tags with href attributes matching the URL pattern\nlinks = soup.find_all('a', href=url_pattern)\n# Print all matched URLs\nfor link in links:\nprint(link['href'])\nIn the above code, we are defining a regular expression\n(r'[a-zA-Z0-9._%+-]\n+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\n\u2018)\nfor email addresses, and then using that regular expression to find all email addresses in the page.\nThen, we define another regular expression (\nr\u2019.*commerce.*\u2019)\nthat finds all\n<a>\ntags in the HTML containing the word\ncommerce.\nExecute the script by running this command:\npython3 regex.py\nThe output should show an email address, followed by all the links that contain\ncommerce.\nLike this:\nHandling dynamic content and Ajax calls\nWhen web scraping, you may notice dynamic content that\u2019s loaded via AJAX calls or JavaScript. This dynamic content may not be present in the initial HTML response, because it will only show after the page first loads. In this section, we\u2019ll explore how to handle these scenarios.\nHandling dynamic data using Selenium\nSelenium\nis an open-source tool for automating web browsers. It can execute JavaScript code, wait for content to load dynamically, and then scrape and retrieve the data you need. The Python library for Selenium can be downloaded by running this command:\npip install selenium\nHere\u2019s a sample Selenium script that waits for a specific element to load before extracting desired data:\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n# Define the URL to scrape\nurl = 'https://www.example.com' # Replace with the target website\n# Create a new WebDriver instance\ndriver = webdriver.Chrome('/path/to/chromedriver') # Replace with your WebDriver path\n# Navigate to the URL\ndriver.get(url)\n# Explicit wait for content to load (adjust wait time as needed)\nWebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'unique_element_id')))\n# Locate and extract the desired data using Selenium methods\nview_details_buttons = driver.find_elements(By.CLASS_NAME, 'view_details_button')\n# Close the browser window\ndriver.quit()\nHandling dynamic data by analyzing network requests\nAnother way to manage dynamic data is by inspecting network requests in your browser\u2019s developer tools to identify the AJAX requests used. You can then mimic these requests in your scraping script using the\nrequests\nlibrary.\nError handling and logging\nError handling and logging techniques are crucial for writing effective scraping scripts. Websites are dynamic and will change their structure or behavior over time. Additionally, network issues, server-side errors, and unexpected data formats can all lead to unexpected behavior in your scraping script.\nWhen you implement proper error handling and logging, you will be able to gracefully handle errors or exceptions and prevent your script from crashing. Moreover, your code becomes more readable and easier to maintain. You can also quickly identify potential problem areas and adjust your script as needed.\nHere\u2019s how you can go about implementing error handling and logging during web scraping:\nImport the logging module by adding the following line to the top of your script:\nimport logging\nSet up logging by adding this line:\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nWrap network requests within try-except blocks. This ensures that if an HTTP request fails, the proper error is logged and the script gracefully exits (instead of crashing).\ntry:\n# Send a GET request to the URL\nresponse = requests.get('https://www.hostinger.com/tutorials/how-to-run-a-python-script-in-linux')\nresponse.raise_for_status() # Raise HTTPError for bad responses\nexcept requests.RequestException as e:\nlogging.error(f\"Request failed: {e}\")\nsys.exit(1)\n# Parse the HTML content using BeautifulSoup\nsoup = BeautifulSoup(response.text, 'html.parser')\nHandle potential errors and exceptions in parsing and data extraction. This will help you identify the tags/elements the script was unable to fetch.\ntry:\n# Find the first <h1> tag\nfirst_header = soup.find('h1')\nif first_header:\nprint('First <h1> tag text:', first_header.text)\nelse:\nlogging.warning('No <h1> tag found')\nexcept Exception as e:\nlogging.error(f\"Error finding first <h1> tag: {e}\")\ntry:\n# Find all <a> tags (links)\nall_links = soup.find_all('a')\nif all_links:\nprint('All <a> tag hrefs:')\nfor link in all_links:\nprint(link.get('href'))\nelse:\nlogging.warning('No <a> tags found')\nexcept Exception as e:\nlogging.error(f\"Error finding <a> tags: {e}\")\nIf ever you are unable to find the root cause of an issue, you can enable interactive debugging via Python\u2019s built-in debugger,\npdb\n.\nimport pdb; pdb.set_trace()\n# Your code here\nCreating a simple web scraper application\nNow that we have explored how to extract data, navigate a DOM, use regular expressions to retrieve filtered data, and implement error handling, let\u2019s create a simple web scraper application in Python. Here\u2019s how it will work:\nIt will take a keyword and a URL as input.\nIt will calculate the number of times the keyword exists in the page text.\nIt will also display all the internal links present in the text.\nIn our code, we will create functions for getting the HTML (\nget_html\n), counting keywords (\ncount_keyword\n), finding all external links (\nfind_external_links\n), and a main function that prompts the user for inputs and calls all the other functions. The code will also implement proper error handling, so if anything fails in your web scraping efforts, the user will be shown the exact error on their terminal.\nUse the following command to create a new file named\napp.py:\ntouch app.py\nThen, open it in your favorite editor and paste the following code to it.\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nfrom urllib.parse import urlparse\n# Function to get HTML content from a URL\ndef get_html(url):\ntry:\nresponse = requests.get(url)\nresponse.raise_for_status()\nreturn response.text\nexcept requests.exceptions.RequestException as e:\nprint('Error fetching the URL:', e)\nreturn None\n# Function to count keyword occurrences\ndef count_keyword(html, keyword):\nkeyword = keyword.lower()\ntext = BeautifulSoup(html, 'html.parser').get_text().lower()\nreturn text.count(keyword)\n# Function to find all external links\ndef find_external_links(html, base_url):\nsoup = BeautifulSoup(html, 'html.parser')\nlinks = soup.find_all('a', href=True)\nexternal_links = []\nparsed_base_url = urlparse(base_url)\nbase_domain = parsed_base_url.netloc\nfor link in links:\nhref = link.get('href')\nparsed_href = urlparse(href)\n# If the link is external (different domain)\nif parsed_href.netloc and parsed_href.netloc != base_domain:\nexternal_links.append(href)\nreturn external_links\n# Main function\ndef main():\nkeyword = input(\"Enter the keyword: \")\nurl = input(\"Enter the URL: \")\nhtml = get_html(url)\nif html is None:\nprint('Failed to retrieve HTML content.')\nreturn\nkeyword_count = count_keyword(html, keyword)\nexternal_links = find_external_links(html, url)\nprint(f\"\\nKeyword '{keyword}' found {keyword_count} times in the page.\")\nprint(\"\\nExternal Links:\")\nfor link in external_links:\nprint(link)\nif __name__ == \"__main__\":\nmain()\nUse the following command to run the script:\npython3 app.py\nWhen prompted, enter the keyword and the URL you want to use. Here\u2019s the output we got after passing\npython\nand\nhttps://www.hostinger.com/tutorials/how-to-run-a-python-script-in-linux\nas the input parameters:\nConclusion\nWeb scraping is a great way to process, analyze, and aggregate large volumes of online data. In this article, we learnt how to make your first request in Python, use\nBeautifulSoup\nto extract data, parse HTML and navigate the DOM tree, leverage regular expressions to scrape data, handle dynamic content, and store scraped data in a file and database. We hope you have found it useful.\nPython web scraping FAQ\nWhich Python libraries are commonly used for web scraping?\nThe Python libraries most commonly used for web scraping are\nBeautiful Soup, requests,\nand\nScrapy.\nIs it possible to scrape websites that require login credentials using Python?\nIt is technically possible to scrape websites that require login credentials using web scraping. However, you may need to replicate the login process, which can be complex. For example, you may need to handle CAPTCHAs, multi-factor authentication, or other security measures. Before you proceed, make sure that web scraping doesn\u2019t violate the website\u2019s terms of service.\nCan I extract images or media files with Python web scraping?\nYes, you can extract multimedia files from websites using Python web scraping. Here\u2019s a simplified overview of the process:\n1. Retrieve the HTML of the relevant page.\n2. Use\nBeautifulSoup\nto find the appropriate HTML tag, e.g.\n<img>\nfor images.\n3. Extract the URL of the image/media file from the tag.\n4. Use the\nrequests\nlibrary to download the image/media file using its URL.\nWeb scraping vs. API: which is better?\nBoth web scraping and APIs have their merits, and the better choice depends on your specific needs. If an API is available, and offers the data you need in a structured format, it\u2019s generally the preferred option due to its ease of use and standardization. However, if you need specific data, and the website doesn\u2019t offer an API, web scraping may be your only option.\nAll of the tutorial content on this website is subject to\nHostinger's rigorous editorial standards and values.\nThe author\nValentinas C.\nValentinas \u010cirba, Hostinger's Head of VPS, is a seasoned product leader specializing in VPS products with over ten years of experience. He's an expert at setting product strategy, leading cross-functional teams, and making smart decisions to deliver innovative solutions. Valentinas is committed to creating products that not only meet business objectives but also truly serve the customer. Follow him on\nLinkedIn\n.\nMore from Valentinas C.\nCopy link\nCopied!\nRelated tutorials\n10 Sep \u2022\nVPS\n\u2022\nAutomation\n\u2022\nHow to automate WordPress with n8n\nWordPress provides a graphical admin dashboard that lets you build, deploy, and manage websites easily without coding. While already efficient by...\nBy Aris Sentika\n10 Sep \u2022\nVPS\n\u2022\nAutomation\n\u2022\nHow to use the n8n WordPress node to create posts with AI\nn8n is a low-code platform that enables you to create automation workflows for various tasks by connecting various tools or applications, including...\nBy Aris Sentika\n21 Aug \u2022\nVPS\n\u2022\nAutomation\n\u2022\nHow to integrate WhatsApp with n8n?\nIntegrating n8n with WhatsApp enables you to create an automation workflow for various tasks, including creating a chatbot that responds to user...\nBy Aris Sentika\nWhat our customers say\nTrustpilot\nLeave a reply\nCancel reply\nPlease fill the required fields.\nPlease accept the privacy checkbox.\nPlease fill the required fields and accept the privacy checkbox.\nBy using this form you agree that your personal data would be processed in accordance with our\nPrivacy Policy\n.\n\u0394\nThank you! Your comment has been successfully submitted. It will be approved within the next 24 hours.",
        "image_urls": [
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2023/02/VPS-hosting-banner-1024x300.png",
            "score": 1
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/07/image2.png",
            "score": 1
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/07/image3-1.png",
            "score": 1
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/07/image4-1.png",
            "score": 0
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/07/Image-2-1.png",
            "score": 0
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/07/image1.png",
            "score": 0
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2023/09/Screenshot-2023-09-29-at-12.50.18-150x146.png",
            "score": 0
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/11/VPS-alt-1-4.jpg",
            "score": 0
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/11/VPS-alt-1-4.jpg",
            "score": 0
          },
          {
            "url": "https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2024/11/VPS-alt-1-4.jpg",
            "score": 0
          }
        ],
        "title": "Python Web Scraping Tutorial"
      },
      {
        "url": "https://www.tutorialspoint.com/python_web_scraping/index.htm",
        "raw_content": "Python Web Scraping Tutorial\nPython Web Scraping - Home\nIntroduction\nGetting Started with Python\nPython Modules for Web Scraping\nLegality of Web Scraping\nData Extraction\nData Processing\nProcessing Images and Videos\nDealing with Text\nScraping Dynamic Websites\nScraping Form based Websites\nProcessing CAPTCHA\nTesting with Scrapers\nPython Web Scraping - Quick Guide\nPython Web Scraping - Resources\nPython Web Scraping - Discussion\nSelected Reading\nUPSC IAS Exams Notes\nDeveloper's Best Practices\nQuestions and Answers\nEffective Resume Writing\nAI Based Resume Builder\nPersonal AI Study Assistant\nGenerate Coding Logic\nHR Interview Questions\nComputer Glossary\nWho is Who\nPython Web Scraping Tutorial\nJob Search\nPDF Version\nQuick Guide\nResources\nDiscussion\nWeb scraping, also called web data mining or web harvesting, is the process of constructing an agent which can extract, parse, download and organize useful information from the web automatically.\nThis tutorial will teach you various concepts of web scraping and makes you comfortable with scraping various types of websites and their data.\nAudience\nThis tutorial will be useful for graduates, post graduates, and research students who either have an interest in this subject or have this subject as a part of their curriculum. The tutorial suits the learning needs of both a beginner or an advanced learner.\nPrerequisites\nThe reader must have basic knowledge about HTML, CSS, and Java Script. He/she should also be aware about basic terminologies used in Web Technology along with Python programming concepts. If you do not have knowledge on these concepts, we suggest you to go through tutorials on these concepts first.\nPrint Page\nPrevious\nNext\nAdvertisements",
        "image_urls": [
          {
            "url": "https://www.tutorialspoint.com/python_web_scraping/images/python-web-scraping-mini-logo.jpg",
            "score": 0
          },
          {
            "url": "https://www.tutorialspoint.com/python_web_scraping/images/python-web-scraping.jpg",
            "score": 0
          }
        ],
        "title": "Python Web Scraping Tutorial"
      }
    ]
  }
}